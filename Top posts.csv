,title,score,url,num_comments,body
0,"Weekly Entering & Transitioning - Thread 30 Oct, 2023 - 06 Nov, 2023",7,https://www.reddit.com/r/datascience/comments/17jkxjp/weekly_entering_transitioning_thread_30_oct_2023/,43," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new)."
1,[Meta] New Automod Rule - Minimum Comment Karma before Submissions,45,https://www.reddit.com/r/datascience/comments/17igak2/meta_new_automod_rule_minimum_comment_karma/,19,"After feedback from many members and discussions within the mod team, we have decided to implement a new Automod rule:

**Rule:** Effective immediately, **users must have at least 10 comment karma** **within** r/datascience **before they can make a top-level submission.**

The desired outcomes are:

1. Reduce pure self-promotion botspam
2. Reduce the number of top-level submissions that belong to the Weekly Sticky thread.

**Please let us know if it appears to be working incorrectly or causing unwanted side effects.**"
2,"qq - if I receive ""thanks but no thanks"" email months after application...",6,https://www.reddit.com/r/datascience/comments/17lsxof/qq_if_i_receive_thanks_but_no_thanks_email_months/,6,"Does that mean my resume made it farther along in the decision process? That maybe I wasn't immediately auto-filtered out? Or does it mean nothing? 

I'm trying to understand how my resume faired against the algorithms... If anyone has tips on that or a library of the latest ""greenlight"" resume algorithm parser buzzwords, please, do share. 

Thanks!"
3,[SERIOUS] What do you not like about your boss or big bosses and how does that affect progress of your organization?,7,https://www.reddit.com/r/datascience/comments/17ltjt8/serious_what_do_you_not_like_about_your_boss_or/,7,Curious about the DS arena
4,How to be Competitive for a Product Data Scientist Role?,34,https://www.reddit.com/r/datascience/comments/17le04v/how_to_be_competitive_for_a_product_data/,19,"I'm a mid level data scientist with 3 yoe as a data scientist for the US Air Force and 1 yoe of prior experience as a data analyst at a major bank. I have a MS in Data Science from a Top 10 program and MBA in Business Analytics from Top 50. A lot of the roles at tech companies/large startups that I'm targeting appeared geared towards product data science. I'd like to hear from data scientists currently working in product roles:

\- How to stand out in terms of past experience, projects, resume, interview, etc?

\- What does a ""product"" data scientist do day to day? Is this customer analytics, pricing, A/B testing, forecasting, data mining, etc?

\- What type of specific skills are you looking for outside of the core data science skillset?

I was think of trying to leverage my MBA and experience working with modelling costs for fighter jets as a ""product"", but I'm not sure if it's directly applicable, especially with regards to customer behavior."
5,Help me understand if my approach is correct please!,5,https://www.reddit.com/r/datascience/comments/17lrtkx/help_me_understand_if_my_approach_is_correct/,4,"Hi all, I'm an junior data analyst. I'm currently learning all sorts of stats and techniques on my way to improving my skills.

Currently I'm investigating a dataset full of invoices and there are a few questions I'm trying to answer. 

For example how many orders are on time/late based on xyz checks which I've coded.
I've also found cost discrepancies between what was actually done and what was invoiced.

One task I've been assigned is to see what teams are ordering what services and I wanted to approach it with potentially a more nuanced approach.
I have recently been learning the theory and application of Association rules to do the following : 
 
I would like to know if I could split all the orders by teams and then code an association rule algorithm which would mean my results are specific to teams. 
E.g X team order y item and with y item z was also often ordered.


Outside of that is there any other kind of ""fun"" statistically backed learning I could do from invoices? 

Thanks for any advice!"
6,"Why some data science interviews suck, as an interviewer...",201,https://www.reddit.com/r/datascience/comments/17kvjmp/why_some_data_science_interviews_suck_as_an/,53,"I know a number of people express annoyance at interviews on this sub. I was raked over the coals a few months ago for apparently bad interview questions but my latest experience blows that out the water. I thought I'd give my experience from the other side of the desk which may go some way to showing why it can be so bad.

I received a message last week saying that an online assessor for a Graduate Data Scientist role had dropped out and they needed volunteers to stand in. I volunteered to help.

Someone from HR sent me an email with a link to a training video and the interview platform. I watched the 30 min video at 1.5 speed which was mostly stuff like which buttons to press.

The day before I logged onto the assessment portal I reviewed the questions. I noticed that the questions were very generic but thought there might be some 'calibration' briefing before the interviews; it was too late to speak to HR.

Before the assessment day there was a HR call 30 mins before. It turned out to be just to check if anyone had technical issues. There was no 'calibration' brief. The call ended after 10 mins as the HR rep had to leave to chase no shows.

I was dropped straight into a 'technical' interview 1 on 1 with the candidate. Although it was apparently technical most of the questions were very generic. E.g. Walk me through a project where you had to solve a problem.

There were criteria associated with the questions but there was no way you would answer them as the interviewee unless prompted. E.g in the above question a criterion might be 'The candidate readily accepts new ideas'. Given the short time (5 mins per question) it was not really possible to prompt for every criterion but I did try to enable the candidate to score highly but it meant the questioning was very disjointed.

After a few of these there was the 'technical' section. These questions seemed to be totally left-field. E.g. you have two identical-size metal cubes how could you differentiate the material they are made of? Obviously this question is useless for the role and the CS-background interviewee needed lots of coaching to answer this.

Next I had a soft skills interview with a different candidate. The questions again were vague and sensible answers would not meet the criteria.

Finally there was a group activity and we were supposed to observe the 'teamwork' but the team just split the tasks and got on with them individually so there was hardly anything to observe.

After this the HR bod asked us to complete all the assessments and submit them. Then we'd have a 'wash up'. The wash up was basically the place where scoring could be calibrated by discussing with the other assessors. Of course, the scores had already been submitted by then so this was entirely pointless.

I also asked about the inappropriate technical questions and they said they didn't get the DS questions in time so had just used other technical questions (we were hiring other engineers/scientists at the same time).

So, as you can see, HR ruin everything they touch and hiring is a HR process so it's terrible. Sorry if you had to go through this."
7,Data folks of Reddit: How do you choose a random seed?,95,https://www.reddit.com/r/datascience/comments/17kxd5s/data_folks_of_reddit_how_do_you_choose_a_random/,113,"From classwork, it seems like a lot of people choose the same number for input into a sample() or set.seed() function. 

I always assumed that it was 'bad form' to use the same number for multiple applications of a random seed.  So I actually use dice to generate random seeds, just to be over-detailed.  But is that necessary?  If I just use ""42"" or ""365"" or ""1234"" all the time, am I missing something?  Is there a cultural issue or tradition in communities to use a given number? "
8,Working on improving the process of converting documents into Embeddings (for vectorStores) for LLM applications but i need some ideas and complaints from you!,2,https://www.reddit.com/r/datascience/comments/17lffnz/working_on_improving_the_process_of_converting/,0,"I am CS undergrad interested in NLP, building LLM applications and uses of embeddings in professional settings.

I have been thinking about researching better ways to extract, transform and load (ETL pipelines) data from several formats into text embeddings for the aforementioned applications.

But it seens my initial ideas of contribution were already done...

First i thought about a better way to load CSV and tabular data files into embeddings, but PostGresVector DB was launched a month or so ago, so i guess i cant really do much better than they have already lol

I have been thinking about other data types such as JSON or XML and how to treat them and load them into vectorDBs but i am not sure.

Do you guys have more ideas? Maybe one complaint you have when using such tools and data sources? I am curious and excited to hear these problems so maybe i could work on them"
9,Why should I learn LangChain? It’s like learning a whole new tool set on top of LLM/Transformer models…,29,https://www.reddit.com/r/datascience/comments/17l11nx/why_should_i_learn_langchain_its_like_learning_a/,25,If I don’t use LangChain or HuggingFace how can I build a chat box trained on my local data but using LLM like turbo etc..
10,Anyone else find time series work a little dull?,90,https://www.reddit.com/r/datascience/comments/17koo01/anyone_else_find_time_series_work_a_little_dull/,60,"Got assigned some TS projects at work and now have kind of carved out this niche at my company. It’s great career-wise but I feel like I’d enjoy working with other ML approaches more. 

Time series at the scale I’m doing it is basically just lightweight software development; at the end of the day all we do is train a bunch of transformers and models and see which is best for each time series, then use that to make a forecast. 

It also seems that the simplest models (ETS, Theta) perform at least on par with fancy unexplainable models, so there is not much reason to use or even learn about them in depth. 

Anyone else find time series somewhat uninteresting? What can I do to get more interested it in?"
11,"Metabase, PowerBI and Gooddata capabilities: A comparison",0,https://www.reddit.com/r/datascience/comments/17l8xdt/metabase_powerbi_and_gooddata_capabilities_a/,0,"Hello folks

For the ones of you who manage dashboards or semantic models in UI tools, here's an article describing 3 popular tools and their capabilities at doing this work

[https://dlthub.com/docs/blog/semantic-modeling-tools-comparison](https://dlthub.com/docs/blog/semantic-modeling-tools-comparison)

hope you enjoy the read and if you'd like to see more comparisons, other tools or verticals, or to focus on particular aspects, then let us know which!"
12,"If you did an online MSc in Stats and/or DS or something in that area & liked it, what program was it and what did you like about it?",12,https://www.reddit.com/r/datascience/comments/17ktlc5/if_you_did_an_online_msc_in_stats_andor_ds_or/,11,"My company offers tuition assistance and I'm thinking about going back for a formal degree, but it'd need to be online in a way I can do while working. I have a Bsc in statistics and an MSc in an unrelated field that I lucked out in being able to take quant-ier courses and leverage an internship into a job, but I feel like there's gaps in my math and experience with some of the newer ML methods & neural networks in particular. 

I'm thinking of the Georgia Tech one but would be curious to hear about others."
13,How do you analyze your models?,11,https://www.reddit.com/r/datascience/comments/17kp0nu/how_do_you_analyze_your_models/,30,"Sorry if this is a dumb question. But how are you all analyzing your models after fitting it with the training? Or in general? 

My coworkers only use GLR for binomial type data. And that allows you to print out a full statistical summary from there. They use the pvalues from this summary to pick the features that are most significant to go into the final model and then test the data. I like this method for GLR but other algorithms aren’t able to print summaries like this and I don’t think we should limit ourselves to GLR only for future projects. 

So how are you all analyzing the data to get insight on what features to use into these types of models? Most of my courses in school taught us to use the correlation matrix against the target. So I am a bit lost on this. I’m not even sure how I would suggest using other algorithms for future business projects if they don’t agree with using a correlation matrix or features of importance to pick the features."
14,Resources for technical interviews with focus on cleaning unstructured data?,3,https://www.reddit.com/r/datascience/comments/17kvm37/resources_for_technical_interviews_with_focus_on/,5,I have a technical interview coming up. The focus will be cleaning unstructured data with Pandas. Are there specific resources for this type of interviews other than just practicing with Kaggle?
15,Thoughts on Krish Naik?,0,https://www.reddit.com/r/datascience/comments/17l3gak/thoughts_on_krish_naik/,13,"I've been watching his videos for a while now and being a beginner, I assumed he was pretty good.

However, I've seen a few people criticise him for not knowing what he's talking about, and that he's only good for absolute beginners."
16,automating ad-hoc SQL requests from stakeholders,6,https://www.reddit.com/r/datascience/comments/17kpxml/automating_adhoc_sql_requests_from_stakeholders/,29,"Hey y'all, I made a [post](https://www.reddit.com/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/) here last month about my team spending too much time on ad-hoc SQL requests.

So I partnered up with a friend created an AI data assistant to automate ad-hoc SQL requests. It's basically a text to SQL interface for your users. We're looking for a design partner to use our product for free in exchange for feedback.

In the original [post](https://www.reddit.com/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/) there were concerns with trusting an LLM to produce accurate queries. We think there are too, it's not perfect yet. That's why we'd love to partner up with you guys to figure out a way to design a system that can be trusted and reliable, and at the very least, automates the 80% of ad-hoc questions that should be self-served

DM or comment if you're interested and we'll set something up! Would love to hear some feedback, positive or negative, from y'all"
17,Is Upwork a good place to find data science freelance gigs in the UK ?,7,https://www.reddit.com/r/datascience/comments/17kmu0e/is_upwork_a_good_place_to_find_data_science/,11,Would appreciate other website suggestions too.
18,Describe the analytics tool of your dreams…,2,https://www.reddit.com/r/datascience/comments/17kvn2f/describe_the_analytics_tool_of_your_dreams/,22,I’ll compile answers and write an article with the summary
19,What are the possible reasons for validation loss to fluctuate so much?,3,https://www.reddit.com/r/datascience/comments/17kmxnc/what_are_the_possible_reasons_for_validation_loss/,2,"Is it right to assume that the reason, the validation loss (inside the purple box) is fluctuating so much is due to small batch size? What are other reasons due to which loss validation could be fluctuating so much? All hyperparameter values are given in the bottom left of the image.

I'm using BinaryCrossentropy loss function. The problem I'm trying to  solve is from the kaggle's titanic competition. Basically, it's tabular  structured data that has features 'TicketClass', 'Name', 'Sex', 'Age',  'SiblingsBoarded', 'ParentsBoarded', 'Fare', 'Embarked' and target is  'Survived'(1/0). Let me know if you need more info.

https://preview.redd.it/gerrkzyzxjxb1.png?width=1087&format=png&auto=webp&s=b20530593f527d138a190a33740e752692d984aa"
20,Are all higher level data science jobs like this?,205,https://www.reddit.com/r/datascience/comments/17jtkgv/are_all_higher_level_data_science_jobs_like_this/,101,"I'm really not sure how to summarize this concisely in a neat title, so just let me explain.

At previous lower level jobs, we were organized. We had ticketing tracking systems, step-by-step procedures for all of the commonly done work, we had checklists that people could sign off on as they completed work. And most importantly, even for one-off requests, the primary mode of communication was email. That way, I had the project specifications and/or updates spelled out in front of me that I could refer back to whenever needed.

As I get higher up in the field at different companies, I'm finding the primary mode of communication is virtual meetings. All of the background, specifications, and next steps are given verbally, and I'm sitting here in these meetings furiously trying to write everything down that is being said. What's worse is that the ideas for the projects often aren't fully developed and we have to figure them out so I get a lot of ""do this, actually no, let's do it this way, but I'm actually thinking it would be better to approach it this way....."". AS you can imagine it makes fully understanding the next steps of a given projects difficult. If I use my judgement and approach it the way I feel is best, half the time it's end up not being what management wants and I have to waste their time and mine on rework. 

One of the ways I tried to work around management's brain dumps on me was to recap back to them what the next steps they wanted from me were, but they're ***super busy*** so they always join the meetings late, and as a result we frequently run out of time.  75% of the time I try to message or email them with questions they just don't respond, so the only way I can get any info out of them is via virtual meetings. This is creating an environment for me that makes mistakes easier to happen, and it's turning into a situation where I can do 9 things right, but if I missed or misunderstood the 10th thing, I'm getting crucified for it (meanwhile this is a common occurrence for management but that's a different rant.....) I'm being made to feel like it's a shortcoming of mine for not being able to take down everything accurately.

I know some people can thrive in these conditions. For me, it's tough. I'm definitely a scatterbrain and I try to compensate for this by being as organized as humanly possible, but it's just easier said than done when most everything is being given ONLY verbally. I understand that the higher you go in data science, the less routine and the more exploratory and R&D your work becomes, so having clearly documented procedures becomes less realistic. But if this is the way most of these positions are going to be, I really don't feel like this field is for me."
21,Is there any utility in using SHAP values for feature attribution in cases of Linear models and GLMs?,5,https://www.reddit.com/r/datascience/comments/17kfjr0/is_there_any_utility_in_using_shap_values_for/,2," So I have been reading up on SHAP values. I get that it works on the principle of game theory . Basically, just like we would want to allocate a payoff among the participants fairly, the same could be done to a statistical model.

For e.g. if we have a Linear regression model and we have ice cream sales as dependent variable. The independent variables are weather, location of the ice cream store, cost of the ice creams, some marketing efforts (pamphlets, bill boards, sales person etc.) . The SHAP value would ideally attribute the sales to the IVs cited above in varying order of importance.

Now we already get a coefficient associated with each IV through linear regression. Thus giving us the importance of that particular variable.

My question is : Would a SHAP value applied on top of the Linear regression model discover the same 'truth'. That is, would the SHAP value identify the magnitude of importance of variables exactly like the regression coefficients?

What has been your experience? Has SHAP worked for you in case LM or GLM models?

What are the pitfalls of using SHAP?"
22,Favorite ML Example?,102,https://www.reddit.com/r/datascience/comments/17jst3u/favorite_ml_example/,40,"I feel like a lot of kaggle examples use really simple data sets that you don’t ever find in the real world scenarios(like the Titanic data set for instance).

Does anyone know any notebooks/examples that start with really messy data? I really want to see someone go through the process of EDA/Feature engineering with data sets that have more than 20 variables."
23,How does one find freelance or contract work? Short or long term would be fine.,22,https://www.reddit.com/r/datascience/comments/17jxqm8/how_does_one_find_freelance_or_contract_work/,18,"I work full time as a data scientist and I have 3 years experience now.  I've become significantly more efficient and experienced and I feel that I could take on more work than my company gives me.  My boss wouldn't mind if I took some extra work on the side, he's very flexible and I was wondering how people find contracts for short term gigs?  Are there any sites in particular people have had success with?  What do you typically bill at?  


Edit:  General vibe I'm getting is that this is a waste of time and after scrolling through the options on Upwork I'm coming to see it that way as well."
24,Maintaining a work life balance,66,https://www.reddit.com/r/datascience/comments/17jmq2n/maintaining_a_work_life_balance/,54,"How is everyone keeping a good work life balance in this industry? Or work in general. 

I am currently doing my masters as a full time DS and also doing certifications as requested by my managers. 

I am forcing myself to sleep earlier, but the daily screen time is just too draining for my eyes to keep up."
25,Has anyone tried Cursor.sh AI editor for data science?,2,https://www.reddit.com/r/datascience/comments/17k3svb/has_anyone_tried_cursorsh_ai_editor_for_data/,3,I've seen a few people talk cursor [https://cursor.sh/](https://cursor.sh/) for software saying that it was good. Has anyone tried it for data science?  
26,Recommendation for measuring similarity of paragraphs,4,https://www.reddit.com/r/datascience/comments/17jrbh7/recommendation_for_measuring_similarity_of/,14,"I’m doing some analysis and part of my data, possibly a very important part, is a text description of a product. I want to determine if there’s a correlation between the product description and performance, but to do this I need to cluster the descriptions into similar groups. I’m thinking text embeddings could be useful, but I’m unsure of which ones to use. Can anyone provide some advice?

Possibly more important, if I’m completely barking up the wrong tree, please let me know. "
27,Where to Draw the Line between Proof of Concept and Deployment?,1,https://www.reddit.com/r/datascience/comments/17jygyq/where_to_draw_the_line_between_proof_of_concept/,8,"Are you currently involved in a project that revolves around fulfilling customer requirements? As part of your responsibilities, are you tasked with deploying a functional data science project?

I'm referring to the point at which you determine that the project is prepared for delivery. Is it sufficient to provide a functional model based on a script or notebook, accompanied by a presentation that includes relevant metrics? Or do you also engage in the deployment phase? I'm somewhat perplexed because there is often a request for a ""proof of concept,"" but is functional code alone sufficient to satisfy this requirement?

I am a part of a small team and my team seldom deals with external clients, so I'm unsure about the boundaries between what should be accomplished before transitioning to a production-level stage. "
28,How have you approached training yourself to become better at business acumen/context for your DS work?,19,https://www.reddit.com/r/datascience/comments/17jgck2/how_have_you_approached_training_yourself_to/,22,"This is the thing I'm struggling most with. Coming from an academic background, the concerns seem to be different but I'm still having trouble articulating exactly how, or what to do to get better at training myself to be more business-ybif that makes sense"
29,The job market is so frustrating,117,https://www.reddit.com/r/datascience/comments/17j3qc7/the_job_market_is_so_frustrating/,54,"Graduated 5 months ago with a MS in CS. Before I came to the US to pursue my masters, heard from a boat load of people that getting jobs after graduation was easy and that hardly anyone graduated without a couple offers in hand. That sentiment was echoed by other recent grads I met when I got here.

I always wanted to get into DS, so when everyone started looking for internships, I started looking for DS/DA/DE internships specifically. Gave a bunch of interviews, landed an offer in April of 2022. Just an unfortunate decision. The company had a new data science practice with no clear definition of what a Data Scientist does. Being a consulting firm, we basically jump from one case to another and use whatever tech is needed on a case to case basis.
Spent all summer just doing web scraping and OCR extractions. Also, my manager is super condescending and outright rude. He’s told me multiple times that he “can’t believe I have two degrees in Comp. Sci” and at team gatherings and social events, wouldn’t even look me in the eye or acknowledge my existence lol. On the last day of my summer internship, he was in my office literally laughing at my code which btw was based off a snippet he sent me.

Anyway, once this ordeal was done, the world went into a recession and I had to accept a return internship offer. Return internship because I hadn’t proven myself enough to land a full time role yet. Went through another 3 months of abuse and got a full time offer, been working FT for about 4-5 months now. 

At this point I can’t take it anymore. Every day at work I’m putting out fires with the fear that if I fuck up, I’ll either be publicly ridiculed or fired. Consulting being consulting, work life balance is non existent and I had to move to a city where I have no friends and no social life to at least escape the stress.

To all seniors and hiring managers etc, do you think the job market is going to get better? What’s the trend at your company?

EDIT: Thanks for all the support everyone, it’s a tough spot to be in mentally, but I’m thankful for at least have a job. I know so many people who don’t, so complaining sucks. Hopefully things improve for us all soon."
30,Python library to interactively filter a dataframe?,17,https://www.reddit.com/r/datascience/comments/17jg57k/python_library_to_interactively_filter_a_dataframe/,18,"For all intents and purposes its basically a Power BI table with slicers/filters, or a GUI approach of df[(mask1) & (mask2) & (mask3)].sort_values(by='col1') where you can interact with which columns to mask, how to mask them, and how to sort, resulting in a perfectly tailored table.

I have scraped a list of every game on Steam and I have a dataframe of like 180k games and 470+ columns and was thinking how cool it would be if I could make 
every a table as granular as I want it. e.g. find me games from 2008 that have 1000 total ratings and more than 95% steam review with the tag ""FPS"" sorted by the date it came out, and hide the majority of columns.

If something like this doesnt exist but is able to exist in something like Flask (that I have NO knowledge on), let me know. I just wanted to check if the wheel exists before rebuilding it. If what I want really is difficult to do, let me know and I can just make the same thing in Power BI. This will also make me appreciate Power BI as a tool."
31,What's your educational background,52,https://www.reddit.com/r/datascience/comments/17j80cj/whats_your_educational_background/,173,Hi r/datascience. I am interested to know the educational qualifications/background of the members of the group. Personally I have a Bachelor's degree in Maths + an MBA. Have been working in Banking + Analytics for the last 12 years. I know we have CS graduates in this group and those who have done MS in data science and Analytics. Would be good to know the diverse educational background of others as well.
32,"What is the best way to access computation power for a pet project on small LMMs and BERT fine-tuning, without spending a fortune?",1,https://www.reddit.com/r/datascience/comments/17ju0z8/what_is_the_best_way_to_access_computation_power/,8,"I'm a data scientist with a pet project that could turn into something more, but I need more computation power. I have a PC with an RTX 2060 SUPER, but it's getting old. I'm considering Colab Pro+, but I prefer to work with VS Code and build my projects as folders rather than notebooks. I've also explored cloud options, but they seem expensive. My last resort is to buy a refurbished 16GB V100, but I'm hoping to find a more affordable solution."
33,Python package for statistical data animations,167,https://www.reddit.com/r/datascience/comments/17iztuz/python_package_for_statistical_data_animations/,23," 

Hi everyone, I wrote a python package for statistical data animations, currently only bar chart race and lineplot are available but I am planning to add other plots as well like choropleths, temporal graphs, etc.

Also please let me know if you find any issue.

**Pynimate** is available on [pypi](https://pypi.org/project/pynimate/).

[github](https://github.com/julkaar9/pynimate), [documentation](https://julkaar9.github.io/pynimate/)

Quick usage

    import pandas as pd
    from matplotlib import pyplot as plt
    
    import pynimate as nim
    
    df = pd.DataFrame(
        {
            ""time"": [""1960-01-01"", ""1961-01-01"", ""1962-01-01""],
            ""Afghanistan"": [1, 2, 3],
            ""Angola"": [2, 3, 4],
            ""Albania"": [1, 2, 5],
            ""USA"": [5, 3, 4],
            ""Argentina"": [1, 4, 5],
        }
    ).set_index(""time"")
    
    cnv = nim.Canvas()
    bar = nim.Barhplot.from_df(df, ""%Y-%m-%d"", ""2d"")
    bar.set_time(callback=lambda i, datafier: datafier.data.index[i].strftime(""%b, %Y""))
    cnv.add_plot(bar)
    cnv.animate()
    plt.show()

&#x200B;

https://i.redd.it/27xu9yip74xb1.gif

A little more complex example

&#x200B;

https://i.redd.it/kycvoy4u74xb1.gif

(note: I am aware that animating line plots generally doesn't make any sense)"
34,Identifying time series patterns advice,1,https://www.reddit.com/r/datascience/comments/17jg3hh/identifying_time_series_patterns_advice/,9,"Hey you guys, I have something I am stuck at and need your advice.

Long story shirt in example:
Customer A: likes to buy at the beginning of the month only
Customer B: likes to buy at the end of each week when visited by an agent because he stocks
Customer C: likes to buy at the beginning, middle and end of the month.

And so on, you kinda get the problem.

I want to be able to identify this and I was thinking of a possible solution but I think it lacks experience: Decompose the seasonal component of each retailer’s time series and then cluster retailers whom purchasing seasonal components are similar with kmeans?

If you think this approach is invalid, please feel free to suggest something I could read.

Thanks."
35,PSA: Don’t become DS. Be a DA instead.,452,https://www.reddit.com/r/datascience/comments/17ie7f0/psa_dont_become_ds_be_a_da_instead/,202,"I’ve been on this board for a few years and noticed a trend. Many people saying they got a MS in DS and complain they only do excel or simple models. Recently, I see a lot of people saying they can’t get DS jobs. Here is the thing, most businesses need a lot more DA then DS. There are so many more basic data needs then complex ones. Most companies I’ve worked for have a ratio of about 5:1 DA to DS. Unless you’re a really strong and savvy DS candidate (smarter then me) you’re probably better off doing DA or SWE. I am a DS director and I spend 80% of my time doing DE and DA because that’s what the business needs."
36,How’s the DA job market looking for people with experience?,25,https://www.reddit.com/r/datascience/comments/17isfkx/hows_the_da_job_market_looking_for_people_with/,33,"I’ve started applying around for data analyst roles this week and was wondering how people with 1-3 years experience are doing with their job searches

Asking since most posts on here are either like “no experience how do I break in” posts or like PhD data scientists with not much in between"
37,Taking over new role as DS manager,7,https://www.reddit.com/r/datascience/comments/17ivru4/taking_over_new_role_as_ds_manager/,13,"Not sure if the topic is allowed, but I would like to take opinions from senior data scientists and Analytics managers.

I work in finance as data scientist and work involves preparing data in required format,
Doing analysis and building models for products that we have in market , like propensity models for credit cards , credit risk models etc. 
I have worked as an individual contributor till now and have 5 years of experience. I have never managed anyone but have mentored and led few projects individually. 
I have a new offer for an analytics manager with a well known bank and I'll have to manage 6-7 data analysts/scientists and be responsible for the team’s performance. 

The pay jump is decent (40 percent higher than I currently make) and location is much closer to my home.
I don't have any problems with my current job and people I work with are also great. 

I was thinking if anyone else made that jump. 
Is the transition too steep from not managing anyone to 6-7 people?"
38,"What would you classify my job as? DS, DA, DE, Glorified Excel Monkey",85,https://www.reddit.com/r/datascience/comments/17ih595/what_would_you_classify_my_job_as_ds_da_de/,68,"Officially I am a Data Scientist. I try to understand my value or worth outside of the government.

What I don't do:
AI, ML, modeling. 

What I do:
Develop new data pipelines,
Data exploration,
Produce data and dashboards from policy and new concepts,
Python, R, SQL, Databricks.


I feel a DS should be doing ML at minimum but our business needs are fast and dirty and the data is dirty. Dirty data = Dirty results is how I view ML stuff.

Edit: Punctuation because I forgot about Reddits mobile formats lol"
39,Guesstimates,3,https://www.reddit.com/r/datascience/comments/17ixgz7/guesstimates/,3,"Is there any book , podcast y'all can recommend  to study guesstimatation problem"
40,Didn't realize how insane the market is,697,https://www.reddit.com/r/datascience/comments/17huxxq/didnt_realize_how_insane_the_market_is/,240,"I work at FAANG as a DS manager. Opened up a Data Science position. Less than 24 hours later there were 1000+ applicants. 

I advertised the position on LinkedIn 

It's absolutely crazy. People have managed to get a hold of my personal and professional email address (I don't have these as public but they're a logical combination of first/last name).

I hired in the past, I have never seen anything like this."
41,Learning resources for a new DS manager?,5,https://www.reddit.com/r/datascience/comments/17ih45v/learning_resources_for_a_new_ds_manager/,5,"**Tl;dr -** Soon to be transferring over to a DS manager role from an analytics manager, and I do NOT want to be *that* leader. What are some recommended MOOCs, videos, books that can boost my technical knowledge over the next 2-3 months.

I have been on the analytics side for ~10 years, and have a strong foundation of SQL, python, data viz, and analysis, and a solid knowledge of math/stats (can still be improved). I’m lacking in the ML and deployment space, and have a couple months to study up here. Any strong recommendations of courses, videos, or problem sets to work through? (Books are also great, but I am painfully slow and may be more efficient with another medium). Thanks in advance."
42,"D.S. / Analytics Directors, What Tools Do You Use to Organize Your Work & Knowledge?",1,https://www.reddit.com/r/datascience/comments/17imqvk/ds_analytics_directors_what_tools_do_you_use_to/,11,Curious what people are using to keep track of projects and general data/process documentation
43,When do you select features to use for your model?,13,https://www.reddit.com/r/datascience/comments/17i4ikr/when_do_you_select_features_to_use_for_your_model/,22,"My issue is about doing EDA before or after feature selection. For example. say I have a dataset with tons and tons of features. Am I expected to analyze each and every feature in the dataset before choosing features or can I choose features that ""may"" matter based on logic and examine them there?"
44,What skills should Data Scientist with 1 YOE is expected to know?,31,https://www.reddit.com/r/datascience/comments/17htzx6/what_skills_should_data_scientist_with_1_yoe_is/,12,"I have completed over one year at my company as a Data Scientist. As a data scientist with master’s degree( in electrical and computer engineering) and 1 YOE, I was thinking about my career progress and was wondering if  my learning curve is good or bad. 

My experience so far at my company has been

 - developing a ML model( text classification model ) 
- lot of data manipulation and exploratory data analysis using sql , python and excel 
- using visualization tools like tableau 
- working with clustering algos and neural networks ( these models are existing and I haven’t developed).

But I don’t know model deployment, automation, parallelization and a lot more.

From the conversations in my team, I really feel overwhelmed by the amount of expertise and inputs they have and I do think it is with experience. But sometimes I wonder if I’m just underprepared and I have to improve but don’t know what resources to look at since from the experience I had so far, the code structure and everything is different. 

What was your experience ? Any tips and resources anyone can guide to?

Thanks!"
45,How to get better at PowerPoint?,41,https://www.reddit.com/r/datascience/comments/17hlvki/how_to_get_better_at_powerpoint/,40,"Unfortunately I have realised that at most jobs 80 percent of my time is spent on Ppt and 5 percent on the actual analysis. I was working in consulting and the best associates were the ones who could make the best presentations. Even at McKinsey, Bain etc my friends seem to mostly involved in making decks all day long. How do I get better at ppt? 
I used to feel that ppt would get redundant and hence didn’t really focus on it. Is it worth it to devote time in learning how to make beautiful ppts or is it a dying software and even investment banking and consulting will shift to something more sane/ AI will make it easy to make excellent ppts?"
46,Has anyone successfully used Chernoff faces in any type of analysis (not including what they are and how they convey information)?,3,https://www.reddit.com/r/datascience/comments/17i2wn6/has_anyone_successfully_used_chernoff_faces_in/,0,"I was reading through the supplemental material at the end of Blindsight and discovered that Chernoff faces are real. The in-story explanation that human brains are hardwired to read faces and the amount of information that can be encoded into them is suitable for higher dimensional (~18) data, especially given that the subconscious is more adept at processing complex problems than the conscious mind, is interesting enough of a concept, so discovering that it's real makes it even better.

I'm interested to see if they have been utilized before and if they still are in certain industries or niches (outside of customer satisfaction surveys and Wong-Baker scales). The fact that it can encode a high number of dimensions has piqued my interest to see if they can be used successfully and how difficult they are to interpret, for both analysts/statisticians and non-technical parties (stakeholders)."
47,How much time do you guys spend in PowerPoint?,71,https://www.reddit.com/r/datascience/comments/17hicpp/how_much_time_do_you_guys_spend_in_powerpoint/,105,"I know this question might be a bit controversial to some but lately I've found myself spending an ungodly amount of time creating slides instead of doing other tasks.

Management wants each new project or idea laid out in meticolous detail in a PowerPoint before signing off on it and granting any type of access to data. Which means I need to create some really good looking PPT decks to even get the chance to explore our available data, it's quite frustrating and I'd rather spend the time doing something else.

By detail I mean like, budget, development timeline, target audience, documentation, blabla, before I even get a chance to look at the data and determine if it's useable in the first place.

Anyone else have this problem?"
48,"What is considered a ""high-value"" data scientist and how do you become one?",240,https://www.reddit.com/r/datascience/comments/17h9xpo/what_is_considered_a_highvalue_data_scientist_and/,95,"I'm a data scientist with a 2 years of experience. I've realised recently that all of my projects in industry follow the same basic blueprint which I learnt years ago:

1. Think of how to best frame the problem so it can be solved using data science.
2. Clean and process the data.
3. Extract features which give the highest accuracy
4. Sticking it into an sklearn algorithm and hoping it has good accuracy (or whatever metric is important for that specific problem).
5. If it has bad accuracy, redo step 3 or get more data. If it has good metrics, done.

My issue is: anyone who has done a data science boot camp can easily reproduce these steps. Coding in R and Python is super easy, especially nowadays with libraries like sklearn.

* Is a data scientist considered ""high-value"" because of step 1? Or is it the fact that they have lots of ideas about how something can be modelled which goes beyond the ""traditional"" models? 
* If it is the latter, is the only way to create more complex models to just gain more experience with a variety of problems, and coming across new techniques whilst researching? I find that I don't even know about the existence of many techniques unless it's pointed out to me by colleagues.

By ""complex"" model. I don't mean complicating the algorithm a model uses for the sake of it. I'm referring to a more robust model that takes more variables into account.

As data scientists get more experienced, in which ways can they provide more value to a business compared to say, an intern, who could probably do all the steps listed above relatively easily?"
49,What are your duties as a Data Scientist?,5,https://www.reddit.com/r/datascience/comments/17hwt1l/what_are_your_duties_as_a_data_scientist/,6,"Please elaborate on this. 

Including your role at the company, your day to day tasks, tools and languages you’re using. 

Thank you in advance!"
50,Been put to investigate bugs for new project but no prior exp,3,https://www.reddit.com/r/datascience/comments/17hy5hl/been_put_to_investigate_bugs_for_new_project_but/,10,"Hi there!

I’m working as a Data Analyst in my company and in my team we mostly use SQL and Tableau. I’ve mostly just used these two and Python (via Jupyter notebooks) on occasion to perform data cleaning /transformation for adhoc data sets.

So recently been covering for some other employee and have seemingly gotten myself into potentially being the one having to fix some potential bugs in a ML based Flask application that predicts product prices based on different conditions.

This is made up of 3 GitHub repos:
The model, the data pipelines and a Jupyter notebook containing code related to KMeans.


The data pipeline and model repos contain lots of Python source files with around 1000-1500 lines per file. All in all there could be easily more than 20,000 lines of code. I know this is not a lot but I don’t have experience in dealing with such large code bases.


I don’t have background in ML or product development (I previously worked as a IT BA 2-3 years back before transitioning to a DA role after having used SQL/Tableau for a few years, there is a separate BI team in the company but I’m in a data analyst specific team). 

My question is would it be common for DAs to be called to debug large complex ML web apps? I haven’t seen this in other companies previously. I would have thought this would fall on the product development teams or ML Engineers etc.

And what is the best way for me to start off getting used to the code base and understanding what everything does? The project certainly looks interesting and would make a good entry for me to a ML engineer role in the future or product development role but I’m nervous especially since my probation is ending in 2 weeks and I really don’t wanna f up. There’s no documentation or requirements documented except for a high level architecture diagram of the system.

Looking for advice thanks!



TL:DR;
A data analyst with no experience in product development put in charge to fix bugs for a large ML web app, looking for tips on how best to understand the code base and perform testing especially when there’s no documentation available for this app besides a high level architecture diagram. Also, wondering if it’s common for a data analysts to be asked to debug large ML web applications (flask based)."
51,Good book on Bayesian statistics?,3,https://www.reddit.com/r/datascience/comments/17hvuft/good_book_on_bayesian_statistics/,19,"From the perspective of someone who has absorbed the frequentist approach pretty well, and is comfortable with it, could you recommend a good book on Bayesian statistics?

Ideally with a focus on A/B testing.

Thanks!"
52,Usefulness of Six-Sigma,32,https://www.reddit.com/r/datascience/comments/17hj3ea/usefulness_of_sixsigma/,48,How useful would y'all rate a Six-Sigma certification?
53,Where I can find projects to contribute in?,3,https://www.reddit.com/r/datascience/comments/17ht5l1/where_i_can_find_projects_to_contribute_in/,2,"I took courses about pentaho,tableau and machine learning ...where I can find projects with open issues so I can solve it and increase my ability to solve problems in this career ..like open source android or web projects on github with open issues ....is there a specific website for data that I can contribute in and this contribution will have a positive effect in my c.v?"
54,Finally!,71,https://www.reddit.com/r/datascience/comments/17h7eav/finally/,20,"Hey fellow data folks - Finally, after 17 months of applying for jobs, I’ve found one. The job title is strange, the pay is nothing to brag about (thanks Canada!) but I’m 100% certain of the positive impact it is going to have in my mental health. 

I’m so relieved and nervous and scared but also excited. 

It is tough out there but nothing else to be done other than try! 

Thanks for hearing me out."
55,Why Gradient Boosted Decision Trees are so underappreciated in the industry?,98,https://www.reddit.com/r/datascience/comments/17h40ok/why_gradient_boosted_decision_trees_are_so/,115,"GBDT allow you to iterate very fast, they require no data preprocessing, enable you to incorporate business heuristics directly as features, and immediately show if there is explanatory power in features in relation to the target.

On tabular data problems, they outperform Neural Networks, and many use cases in the industry have tabular datasets.

Because of those characteristics, [they are winning solutions to all tabular competitions on Kaggle](https://jobs-in-data.com/blog/data-science-skills#sota-ml-models).

And yet, somehow they are not very popular.

On the chart below, I summarized learnings from 9,261 job descriptions crawled from 1605 companies in Jun-Sep 2023 (source: [https://jobs-in-data.com/blog/machine-learning-vs-data-scientist](https://jobs-in-data.com/blog/machine-learning-vs-data-scientist))

LGBM, XGboost, Catboost (combined together) are the 19th mentioned skill, e.g. with Tensorflow being x10 more popular.

It seems to me Neural Networks caught the attention of everyone, because of the deep-learning hype, which is justified for image, text, or speech data, but not justified for tabular data, which still represents many use - cases.

https://preview.redd.it/zavuf0qnhlwb1.png?width=2560&format=png&auto=webp&s=b06cd263e22eb229a6be2df890faba7639d895d7

EDIT \[Answering the main lines of critique\]:

1/ ""Job posting descriptions are written by random people and hence meaningless"":

Granted, there is for sure some noise in the data generation process of writing job descriptions.

But why do those random people know so much more about deep learning, keras, tensorflow, pytorch than GBDT? In other words, why is there a systematic trend in the noise? When the noise has a trend, it ceases to be noise.

Very few people actually did try to answer this, and I am grateful to them, but none of the explanations seem to be more credible than the statement that GBDTs are indeed underappreciated in the industry.

2/ ""I myself use GBDT all the time so the headline is wrong""This is availability bias. The single person's opinion (or 20 people opinion) vs 10.000 data points.

3/ ""This is more the bias of the Academia""

The job postings are scraped from the industry.

However, I personally think this is the root cause of the phenomenon. Academia shapes the minds of industry practitioners. GBDTs are not interesting enough for Academia because they do not lead to AGI. Doesn't matter if they are super efficient and create lots of value in real life."
56,Frontend in data science,1,https://www.reddit.com/r/datascience/comments/17hw9k3/frontend_in_data_science/,7,"Hello, I've been wondering if we need to learn html css and javascript as part of being a data scientist, because honestly I think that the data science field is so broad and there is so much to learn than focusing on frontend dev, so tell me if we really need it in the job. If so what are other alternatives that data scientists use for visualisation?"
57,"I'm a 'data analyst' who in practice is actually just a software engineer. Was I bamboozled, or did I misunderstand the role",168,https://www.reddit.com/r/datascience/comments/17gyevz/im_a_data_analyst_who_in_practice_is_actually/,89,"my first job was as a consultant, doing a mix of implementation and data analytics. 

then i switched to a new job with the data analyst title, but I'm building production R scripts almost exclusively now; not a huge fan of wrangling with my team's complex/sparsely commented codebase and designing 'systems' (our scripts have to integrate with a variety of outside data sources).

I miss doing 'investigations', eg how do we better optimize this product, make more revenue, etc. now it feels like I'm an underpaid backend software engineer (making 85k but seems most SWEs are earning 100k+).

is data analytics in 2023 more similar to SWE? should I have expected this?"
58,What are some good examples of catastrophic AI failures?,85,https://www.reddit.com/r/datascience/comments/17gujdu/what_are_some_good_examples_of_catastrophic_ai/,66,"I've recently did some searches about AI failures, the most catastrophic failure I read about was when [Zillow had to fire 2000 employees](https://www.geekwire.com/2021/zillow-shutter-home-buying-business-lay-off-2k-employees-big-real-estate-bet-falters/). 

I also saw some articles like this [one](https://www.science.org/doi/10.1126/science.aax2342), about biases in health algorithms, but all in all I didn't see much examples that had a measure of how much damage was actually done.

Are there more examples of AI failures on a large scale?"
59,Streaming Data Observability & Quality,2,https://www.reddit.com/r/datascience/comments/17hh6i7/streaming_data_observability_quality/,0,"We have been exploring the space of ""Streaming Data Observability & Quality"". We do have some thoughts and questions and would love to get members view on them. 

**Q1.** Many vendors are shifting left by moving data quality checks from the warehouse to Kafka / messaging systems. What are the benefits of shifting-left ?

**Q2.** Can you rank the feature set by importance (according to you) ? What other features would you like to see in a streaming data quality tool ?

* Broker observability & pipeline monitoring (events per second, consumer lag etc.)
* Schema checks and Dead Letter Queues (with replayability)
* Validation on data values (numeric distributions & profiling, volume, freshness, segmentation etc.)
* Stream lineage to perform RCA

**Q3.** Who would be an ideal candidate (industry, streaming scale, team size) where there is an urgent need to monitor, observe and validate data in streaming pipelines?  


https://preview.redd.it/8f1mo89ouowb1.jpg?width=6998&format=pjpg&auto=webp&s=c1b368112465cfa5be67258dd2a52313cdb4cdb6"
60,What is the worst case of PHDitis that you have seen?,0,https://www.reddit.com/r/datascience/comments/17hv82d/what_is_the_worst_case_of_phditis_that_you_have/,26,Title
61,Machine Learning projects on jupyter,4,https://www.reddit.com/r/datascience/comments/17h8k9y/machine_learning_projects_on_jupyter/,13,"Hello everyone,

Im a recent Data Science graduate and experimenting with different machine learning models on a various datasets from kaggle. The idea is to be more comfortable with tensorflow (& other libaries) and different datasets. 

Im doing all this on jupyter notebook, is there a tool data scientist use to publish their work. I want to create a online portfolio which i can showcase the different ML implementations in interviews and to recruiters. 

Im using github but was wondering if there specific tools or practices of data scientists which i might aswell implement in my workflow

Thanks"
62,"What is the most unique, out of the box, or exciting application of DS you’ve used/thought of?",21,https://www.reddit.com/r/datascience/comments/17gx6q4/what_is_the_most_unique_out_of_the_box_or/,16,"Can be in work, as a passion project/academic project, or just an idea. Was it successful? If not, why not? Would love to be inspired & motivated by all of your experiences, and who knows, maybe it’ll help someone think about a current project in a new way."
63,"What skills should I gain to be a ""Full Stack Data Scientist""?",1,https://www.reddit.com/r/datascience/comments/17hfao4/what_skills_should_i_gain_to_be_a_full_stack_data/,3,
64,A/B test in real life,75,https://www.reddit.com/r/datascience/comments/17go3pk/ab_test_in_real_life/,39,"My employer ran a rather expensive A/B test in its operations. The issue is that they failed to check for SRM and also didn't conduct A/A test beforehand. Now I inherited a test result that is poised with SRM. Due to their test setup, I could run a back A/A test, the result showed no significant difference between control and treatment. We tried to debug the SRM for a few weeks with no luck. I suppose with such SRM, the test results are not reliable. 

Now I am stuck between a rock and a hard place. Should we spend more time debugging the SRM or should we accept the cost and redesign and rerun the experiment. Is there a middle ground here?"
65,Data science student advice,3,https://www.reddit.com/r/datascience/comments/17h7ri5/data_science_student_advice/,3,"Hey guys so I was told that as a data science student I should do things like leetcode as a hobby to help me out to land internships and to make it look better when looking for jobs, I currently have 0 experience in the field, 0 internships, so what could I do to make me stand out in this market? I’m set to graduate may 2024."
66,What website do I use to make a portfolio?,4,https://www.reddit.com/r/datascience/comments/17h0uio/what_website_do_i_use_to_make_a_portfolio/,5,Hi! I’m applying to data science/ analytics jobs and internships right now. I have extensive personal and academic projects that I need to put in an online portfolio for hiring managers to see. What do you all recommend for this? Thanks!
67,"Severance for US-based data science manager, director?",2,https://www.reddit.com/r/datascience/comments/17h5xor/severance_for_usbased_data_science_manager/,10,What is a typical severance package for manager or director of data science (or data engineering) for US companies. How many weeks severance per years tenure? What did yours look like?
68,How to survive at nightmare employer?,136,https://www.reddit.com/r/datascience/comments/17gfqqp/how_to_survive_at_nightmare_employer/,72,"I was laid off from my startup in January so I took a job as a principal data scientist at a huge corporation. They exhibit every major red flag I can think of and I'm slowly losing my mind - any tips on how to survive long enough that it looks ok on my resume to leave?

Red flags include:

* No data / inaccessible data / data flying around in Excel
* Management is not ""ML literate""
* More work dealing with red tape than actual work
* 2x more managers than workers driving projects
* Business consumers of our ML output do not trust it, and do not want it. They only like linear regression because they understand it
* No version control. We run everything manually in prod. There is no dev/qa/prod separation. There is no deployment. There is no automation.
* Because we work directly in prod, we don't have permission to save our processed data to tables or csv's - it must be done in memory every single day
* No access to basic tools of the trade. We had to beg for basic file storage (s3) for 9 weeks. We can't download unapproved libraries or pre-trained models without security review (even just for exploration)

My career is jumpy recently - my first few roles were 3-4 years, but my last 2 roles were 1 year-ish, so trying to make it to Feb 2025"
69,"Intro to Statistical Learning, With Applications in Python (ISLP) How long could it take to study this book?",4,https://www.reddit.com/r/datascience/comments/17gxa3v/intro_to_statistical_learning_with_applications/,13,"Sorry if this is a weird question I just need what people with more experience think about my situation. For some context. I am doing a Master in Data Science but finished my degree in biology. I study full time but I have two other classes at the same time this semester. And one of my class is blasting through this book by giving a little over an hr lecture per chapter and plan to finish the book in a semester. It is clear to me the lectures don’t cover all the contents either does not cover some details or leave some parts out.  While you could absolutely give lectures like this, it does take some time to fully grasp all the concepts, especially when I have to do 2 other classes. I feel like I can’t keep up so just wondering how long people here take to study it if they did or if they are familiar with it, hopefully can tell me if what I am feeling is natural within the context I provided or if it is because of my lack of experience in programming. Do I need to get more of my shit together? Or should I feel less shit about having to catch up slower and investing more time hopefully during holidays and stuff."
70,How are data science interviews for entry level different from senior level (L5-L6). How is the interview preparation different?,8,https://www.reddit.com/r/datascience/comments/17gtqqz/how_are_data_science_interviews_for_entry_level/,9,
71,"Is it just me, or is the requirements / specifications process a complete nightmare?",2,https://www.reddit.com/r/datascience/comments/17h23wx/is_it_just_me_or_is_the_requirements/,1,"I find the data specifications / requirements process to be awful. It's legit one of my least favorite aspects of this job.

For context, I work in an academia-adjacent industry, and I'm typically working with subject matter research experts. They are responsible for writing programming specifications for our projects, which are supposed to serve as an outline for programming and development for the data science team. Sometimes PMs will write them as well. For ex. something like:


    1. Load data from [data source]
    2. Confirm variables `x`, `y`, and `z` are correct data types
    3. Merge data (outer join) with [other dataset]
    	a. output a table of merge %
    4. Deduplicate on ID variable
    5. Filter by ...
    6. etc.
    7. export files to [server location]

As a data scientist, I am supposed to generally follow these steps to produce the result we are looking for. If I disagree with a step, or need to add some logic, I'll go in to the document and edit it. So it's a shared responsibility between my team and the research / project management team. The above steps are a very simplified example - sometimes these types of requirement documents can be like 15 pages long, with a ton of rules and nested logic / requests.

These documents tend to be written in Microsoft Word, which is messy and hard to version control when working across large teams. It's very easy to miss updates and lose track of which specifications have changed.

I can't help but think this process could be so much cleaner and efficient."
72,Need guidance to publish a paper,3,https://www.reddit.com/r/datascience/comments/17gyvk2/need_guidance_to_publish_a_paper/,3,"Hello All,

I am a student pursuing an MS in data science. I have done a few projects involving EDA and implemented a few ML algorithms. I am very enthusiastic about researching something and publishing a paper on it. However, I have no idea where to start or how to choose a research topic. Can someone among you guide me on this? At this point, I do not want to pursue a PhD but want to conduct independent research on a topic."
73,Aspiring Data scientist who needs some guidance on a career path,0,https://www.reddit.com/r/datascience/comments/17h6bty/aspiring_data_scientist_who_needs_some_guidance/,4,"So I am currently a junior in school working towards a degree in applied and computational mathematics with a minor in cs, and I was wondering what type of opportunities I should be actively looking for and seeking out in order to be successful. I am trying to apply to data science internships but it is a bit harder this year and I'm not really getting any interviews.   
I am also kind of struggling on understanding what projects I should be doing because a lot of the requirements I see on job postings are very high level topics I just haven't learned yet. For example here is a list of common requirements I have seen:  


* Expertise in statistical methods and experimental design and analysis  
* Background in advanced statistical modeling (e.g. GLM, mixed effects) and/or machine learning
* Deployment of microservices and data pipeline and monitoring the performance of Kubernetes application and Data infrastructure.
* Hands-on experience with experimentation design, A/B testing, or probabilistic modeling are a plus!
* Experience with mathematical modeling techniques (e.g., linear and integer programming, statistical modeling, system dynamics modeling) 
* Experience with quantitative analysis of complex systems, probability and statistics  
* Strong background/interest in experimentation, recommendation systems, & data visualization   


I haven't really taken courses on these, and getting started with projects using these high level topics is also pretty challenging since theres a learning curve. I'm just not sure what I should actively be doing since my applications are going nowhere and there's so many topics to learn and study on my own. Just looking for some guidance, any advice is welcome."
74,Freelance Data Science in small businesses,4,https://www.reddit.com/r/datascience/comments/17gwjgc/freelance_data_science_in_small_businesses/,7,"My brother-in-law(call him James) co-owns a small business with two of his colleagues who provide services to small businesses. These services include website design, marketing(everything from SEO optimization to email lists to whatever), and graphic design. James recently reached out to me to ask if I would do part-time work for them as a data analyst/data scientist. My background is in quantitative political science. I know how to do pretty much everything data scientists do at a low level (ML algorithms, acquiring data, cleaning data, etc.) but I don't know very well how to apply these techniques to a business. So from that, I have two questions: 

1. How are ML algorithms used for businesses? I'll give some examples of how I imagine it working. K-means clustering can be used for targeted advertisements based on the groups customers are put in. Linear regression can be used to predict sales based on some other independent variable. Decision trees can be used to determine what factors might lead to a customer discontinuing the use of a service. Am I on the correct track? Are these incorrect or are there others I am missing? I would love to hear about ways you guys use ML in your job. I know how to do A/B testing conceptually and do a ton of hypothesis testing in my work so that part of the job I am not worried about (and honestly looking at these two methods it seems they will be used more often than ML). 
2. Can data science even be done with small businesses? My main concern is about the quality of the data. It may require me to organize the data which could take a considerable amount of time and might venture into some data engineering spheres in which I really don't have experience. And then will there even be enough data? Is there some critical mass of sales that is needed before one can begin analyzing a company's metrics? I believe most of the people this service works with a smaller companies that might not have the robust data that F500 companies do. 

I hope these two questions make sense. I'm not trying to get quick and dirty information about data science. If I'm pointed in the direction of how to use these algorithms I can research them on my own. I just wanted some advice from people in the field. For reference, I use mostly Stata in my poli sci work, but I can do most of it in Python as well. Stata is just better for the small studies I do lol. "
75,"If you really want to practice data science with real-world projects, then check out DataWars.",4,https://www.reddit.com/r/datascience/comments/17gum8s/if_you_really_want_to_practice_data_science_with/,2,"**Data science community, I'm here to tell you about a new platform that's going to revolutionize the way you learn data science: DataWars**

I've been using it for a few weeks now, and I'm absolutely blown away. It's the most immersive and hands-on way to learn data science that I've ever experienced.

With DataWars Live Labs, you can:

* Write code in real time and get immediate feedback on your progress.
* Validate your understanding of key concepts.
* Check the correctness of your code.
* Work on interactive projects that are designed to help you learn and practice.

If you're serious about learning data science, I highly recommend checking out DataWars Live Labs. It's the best way to learn quickly and master the skills you need to succeed.

**Here are a few specific things that I love about DataWars Live Labs:**

* The projects are really well-designed and engaging. They cover a wide range of topics, from Python, data cleaning, and wrangling to machine learning and much more.
* The feedback loop is instant. As you write code, you can see immediately whether it's working correctly. This makes it easy to learn from your mistakes and improve your skills quickly.
* Their Discord server is great.

Overall, I'm extremely impressed with DataWars. It's the best way to learn data science that I've ever used. I highly recommend it to anyone who wants to learn data science quickly and master the skills they need to succeed."
76,Question,0,https://www.reddit.com/r/datascience/comments/17hbxka/question/,0,"Hello, g12 student here looking to apply to a university program, im an Ontario student wanting to apply to a Data Science program and I was wondering if the program and degree is worth it, or whether I should choose something else. What jobs would a bachelor's in Data Science degree open me up to? (ofc I will do my masters). What salary ranges typically are those jobs (Canada and US) and how much do you make as a Data Scientist/ML engineer etc. Is a comp sci program better than a Data Science program? can I get into ML engineering with a data sci degree?"
77,Can anyone tell me if the machine learning workflow is correct or not? Could anyone please refer to tutorials or blogs to learn the proper workflow? Any suggestions are welcome.,0,/r/u_Samia_Tisha/comments/17h3xve/can_anyone_tell_me_if_the_machine_learning/,0,
78,data science upskilling,0,https://www.reddit.com/r/datascience/comments/17h3hj7/data_science_upskilling/,1," **How to upskill for data science in 2023, I have 3 years of relevant work experience, plus 7 years total but learning has almost stopped. Could you suggest resources/websites to take profile** "
79,Help! Cloud services on the Data Science field,1,https://www.reddit.com/r/datascience/comments/17h37bq/help_cloud_services_on_the_data_science_field/,0,"Hello all, I want to ask to you some questions about Cloud services on the Data Science field.

&#x200B;

Currently I´m working on a marketing agency with around 80 employees, and my team is in charge of the data management, we have been working on an ETL process that cleans data coming from APIs and upload it in Big Query. We scheduled the daily ETL process with Pythonanywhere, but now our client want us to implement a top notch platform to absorb the work of Pythonanywhere. I know that there are some options that I can use as Azure or AWS but my self and my team is complete ignorant of the topic, for those of you that already worked in projects that use this technolgies, which is the best approach to start learn it? are there any courses or certifications that you recomment? for scheduling the run of python code is there a specific module of Azure or AWS that I have to learn?

&#x200B;

Thank you!

&#x200B;

&#x200B;"
80,Learning programming!,1,https://www.reddit.com/r/datascience/comments/17h2z94/learning_programming/,6,"I am a student getting my masters in applied statistics. I’ve never experienced much with programming but have now found a major passion for it. I have a little over a year left till I finish up my masters. What different programs should I focus on? I am using R with my school and will get great practice with it. I want to be proficient in 2-3 programs when applying for next job when I graduate? What languages do you recommend and where do you recommend learning it from? I love futuristic/forecasting  modeling and looking to get into that type of work. 

Thank you for any help/advice!"
81,How to predict office relocation,1,https://www.reddit.com/r/datascience/comments/17h2gwb/how_to_predict_office_relocation/,3,"Does anyone have a good feel of how to formulate the task of predicting if a company will have to relocate in following X months? Say I can construct a dataset with info on employees, area, building details and some financial numbers. I know the months in which they move or not. So zeros and ones here for the label. I haven't managed to find any relevant literature or code or blog post on a similar topic. Is this a binary classification problem? What algorithms to use? How to account for class imbalance that case? Any pointers would be much appreciated."
82,Suggestions for my internship project,0,https://www.reddit.com/r/datascience/comments/17h2bxq/suggestions_for_my_internship_project/,0,"Hello guys,

I am currently doing a project for my internship. It involves image detection which I have more or less dealt with. The main thing now for me to do is that I have to compare the mass or brightness of each of the blue holes with the reference chart circled red. The blue dots in the red circle have varying uniform opacity and I have to see how the outside blue dots compare with the reference dots. I cannot seem to figure out how to go about doing this. I was thinking of a graph, but it does not seem convenient or maybe a 3d graph(?). I would be grateful if you guys can give me suggestions.

&#x200B;

https://preview.redd.it/jaefgmgh4lwb1.png?width=717&format=png&auto=webp&s=8c03ed5cc6732c8748f548c5742824c952815156"
83,"We are the founders of Cursor Insight, the human motion experts. AMA!",2,/r/IAmA/comments/17gv9im/we_are_the_founders_of_cursor_insight_the_human/,0,
84,I created a shiny app for data scientists,1,https://github.com/AdrianAntico/Quantico,0,
85,Feature Pyramid Network vs U-Net,2,https://www.reddit.com/r/datascience/comments/17gwwlp/feature_pyramid_network_vs_unet/,1,"Hi everyone, 

I was working on my thesis research when I encountered the concept of Feature Pyramid Network, i have read something about it but still i have some doubts. My main question is: ""What is (or are) the difference(s) with respect to the U-Net architecture?"""
86,Is the future of data science drag and drop?,117,https://www.reddit.com/r/datascience/comments/17g7kqf/is_the_future_of_data_science_drag_and_drop/,146,"I see more and more companies requiring drag and drop solutions such as Power BI, Tableau, Alteryx, etc. rather than Python/R/SQL. I don’t know it makes me a bit sad because I feel like drag and drop takes all of the joy out of programming, but I just can’t help but thinking this is the future of many data jobs. Of course companies like OpenAI will be using Python and R and such, but I feel like the majority of data jobs it will be standard to use these drag and drop enterprise solutions. What is everyone’s thoughts?"
87,Data Strategy Mastery: Valuable Tips for Data Pros and Companies Aiming to Level Up,1,https://meysamraz.medium.com/data-strategy-mastery-valuable-tips-for-data-pros-and-companies-aiming-to-level-up-69b17606e7e4,0,"Hi folks, I just published an article where I shared some of the tips I've learned based on my research and experience for building a data strategy and leveling up your business. Curious to learn more? Dive in here"
88,How to Apply What I Learn in Data Science and Find a Job?,0,https://www.reddit.com/r/datascience/comments/17h56j2/how_to_apply_what_i_learn_in_data_science_and/,5,"Hello All. Just looking to tap into your expertise and experience 😊

I’m a non-technical Project Management Officer with robust Excel skills and some knowledge about IT Systems. Now, I’m highly interested in becoming a Data Scientist as well and have taken some online courses to get up to speed.

Here’s my dilemma. I don’t have much experience yet with creating PowerBI reports and using Python language. I’m intimidated (yet intrigued) with this complex field.

How can I take on projects to properly apply what I’ve been learning so far? Also, how can I apply for jobs related to this field while still being a beginner (but willing to learn in the job)?

Many thanks in advance for your advices. Thank you 😊"
89,Convert Stata(.DTA) files to .csv,1,https://www.reddit.com/r/datascience/comments/17gzyzp/convert_statadta_files_to_csv/,6,"Hello, can anyone help me out. I want to convert a huge .dta file(~3GB) to .csv file but I am not able to do so using python due to its large size. I also tried on kaggle but it said memory limit exceeded. Can anyone help me out?"
90,Thoughts about MS in Data Intelligence (MSDI) in University of South Florida?,0,https://www.reddit.com/r/datascience/comments/17gya2d/thoughts_about_ms_in_data_intelligence_msdi_in/,0,"USF accepted my application for the [MSDI program](https://www.usf.edu/engineering/imse/graduate/ms-data-intelligence.aspx). I'm here considering if I accept the acceptance letter and join in January, or wait until August 2024 to join Georgia Tech's Online Master of Science in Analytics."
91,Are data science answering frameworks helpful?,2,https://www.reddit.com/r/datascience/comments/17gtvwl/are_data_science_answering_frameworks_helpful/,2,"Context: I have been looking at learning resources for data science interview preparations. Most are targeted at entry level and contains SQL/Coding questions as preparation guide. But then often interviews are asking questions like:  **Say you work at a major credit card company and are given a dataset of 600,000 credit card transactions. Use this dataset to build a fraud detection model.**   


I have seen and found this framework for answering such questions:  


Step1: Ask clarifying questions on problems and constraints 

Step 2: Establish Metrics 

Step 3: Understand your data sources 

Step 4: Explore your data 

Step 5: Data Cleanup 

Step 6: Feature Engineering 

Step 7: Model Selection and training 

Step 8: Deployment 

Step 9: Iterate 

I would love to get inputs on need and usefulness of such frameworks?

&#x200B;"
92,Dealing with features of questionable predictive power and confounding variables,2,https://www.reddit.com/r/datascience/comments/17gtslo/dealing_with_features_of_questionable_predictive/,4,"Hello all, I encountered this data analytics / data science challenge at work, wondering how y’all would have solved it.

**Background:**

I was working for an online platform that showcased products from various vendors, and our objective was to pinpoint which features contribute to user engagement (likes, shares, purchases, etc.) with a product listing.

Given that we weren't producing the product descriptions ourselves, our focus was on **features we could influence**. We **did not include** aspects such as:

* brand reputation, 
* type of product, 
* price

, even if they were vital factors driving user engagement.

Our attention was instead directed at a few controllable features:

* whether or not the descriptions exceeded a certain length (we could provide feedback on these to vendors)
* whether or not our in-house ML model could categorize the product (affecting its searchability)
* the presence of vendor ratings,
* etc.

To clarify, every feature we identified was binary. That is, the listing either met the criteria or it didn't. So, my dataset consisted of all product listings from a 6 month period, around 10 feature columns with binary values, and an engagement metric.

**Approach:**

My next steps? I initiated numerous student t-tests. 

For instance, how do product listings with names shorter than 80 characters fare against those longer than 80 characters? What's the engagement disparity between products that had vendor ratings va those that didn’t? 

Given the presence of three distinct engagement metrics and three different product listing styles, each significance test focused on a single feature, metric, and style. I conducted over 100 tests, applying the Bonferroni correction to address the multiple comparisons problem. 

Note: while A/B testing was on my mind, I did not see an easy possibility of performing A/B testing on short vs. long product descriptions and titles, since every additional word also influences the content and meaning (adding certain words could have a beneficial effect, others a detrimental one). Some features (like presence of vendor ratings) likely could have been A/B tested, but weren't for UX / political reasons.

**Results:**

With extensive data at hand, I observed significant differences in engagement for nearly all features for the primary engagement metric, which was encouraging.

Yet, the findings weren't consistent. While some features demonstrated consistent engagement patterns across all listing styles, most varied. Without the structure of an A/B testing framework, it became evident that multiple confounding variables were in action. For instance, certain products and vendors were more prevalent in specific listing styles than others.

My next idea was to devise a regression model to predict engagement based on these diverse features. However, I was unsure what type of model to use considering that the features were binary, and I was also aware that multi-collinearity would impact the coefficients for a linear regression model. Also, my ultimate goal was not to develop a predictive model, but rather to have a solid understanding of the extent to which each feature influenced engagement.

I never was able to fully explore this avenue because the project was called off -  the achievable bottom-line impact seemed less than that which could be achieved through other means.

**What could I have done differently?**

In retrospect, I wonder what I could have done differently / better. Given the lack of an A/B testing environment, was it even possible to draw any conclusions? If yes, what kind of methods or approaches could have been better? Were the significance tests the correct way to go? Should I have tried a certain predictive model type? How and at what point do I determine that this is an avenue worth / not worth exploring further?

I would love to hear your thoughts!"
93,How to qualify for a job in Data Science,1,https://www.reddit.com/r/datascience/comments/17gtgb0/how_to_qualify_for_a_job_in_data_science/,3,"I am currently working as a Research Specialist at a private company where I conduct trials and experimental data analysis. I have a biological science background with experience in R and JMP and thinking of jumping careers in Data Science. 

Any additional skills I need to learn?"
94,Is a Convex Optimization class good for Data Science?,32,https://www.reddit.com/r/datascience/comments/17gc0b4/is_a_convex_optimization_class_good_for_data/,22," For context, I am a Master's student in CS and lurking in sub has made me realize that CS guys need more statistical background regarding DS positions. Hence, the motivation. However, I am already taking a course called Foundations course which feels like a quick Statistics walkthrough. I am also taking an Automated Learning course which basically follows the ISL contents. This course would be the third one? or the fourth one if I plan to audit this one.

This is what the course page says : 

Student Learning Outcomes: 

Master the essential tools of convex analysis, ability to characterize solutions to convex optimization problems, ability to formulate standard data science problems as convex optimization problems, and understanding the structure and implementation of the main classes of algorithms for solving optimization problems in data science.

Detailed Content: 

Iteration principles, fixed-point algorithms, convex sets and convex cones, best approximation paradigms, projection methods in convex feasibility problems – applications to data fusion and image recovery, convex functions, conjugation of convex functions, duality in convex optimization, subdifferential calculus, subgradient algorithms for convex feasibility and best approximation – applications in inverse problems, proximity operators, proximal calculus, forward-backward splitting and variants (Dykstra-like methods, Chambolle-Pock algorithm, dual ascent method, etc.), Douglas-Rachford splitting and variants (parallel proximal algorithm, alternating direction method of multipliers, composite primal-dual method, etc.), the monotone + skew decomposition principle – primal-dual algorithms, proximal modeling of statistical information, proximal information extraction, proximal sparsity enforcement, proximal data classification, proximal principal component analysis, proximal image reconstruction, proximal learning, proximal methods for matrix-based learning, scalability: proximal methods in big data problems, special topics.  


  
I was wondering if this would be something that could help with the day-to-day computations as a DS. I feel like real-world DS is more about optimization and less about using high-end ML/DL techniques. Any thoughts or suggestions?"
95,Git Version Controlled Datasets in your own S3,1,https://i.redd.it/pkoix1xasjwb1.jpg,5,"I’m building Underhive, a collaboration platform for ML Teams. I’ve just put out the first product up which helps you use your own storage backend for Git-LFS.

Please email me at: support@underhive.in.
If you want to help and be one of the first beta clients.
We’re also giving free usage for upto 200GBs for the next 6 months to beta clients.  
Try out: https://underhive.in (please use on Desktop, the mobile version is broken right now)"
96,Residuals,0,https://i.redd.it/4f064j4bukwb1.jpg,7,"I am trying to get the residuals to white noise but there are two different behaviors on residuals. Any ideas on how I should transform this? Or what should I do. I tried log/sqrt. Doesn’t really do shit. Dataset is a hourly data for a couple years. The graph behavior is seasonal yearly, and daily aswell. But right now I just care about the yearly. Any advice?"
97,Questions for KNIME Users,1,https://www.reddit.com/r/datascience/comments/17gvhga/questions_for_knime_users/,0,"Hey everybody,  
I started to use KNIME fpr work, but have some issues with it. I am currently taking the DW1 Exam, but I dont have any idea on how to do that. Can someone please help me? using ChatGPT feels like cheating.  
Thanks in advance "
98,having a second job on 1099,3,https://www.reddit.com/r/datascience/comments/17goc84/having_a_second_job_on_1099/,5,"I currently work for a government contractor. I have an opportunity to take a job with a technology consulting company as a consultant. I am on W2 at the first job and would be on a 1099 for the second. Could the first job still be able to find out about the second?  If I'm doing 20 hrs/wk at the second job, would that still be a problem for employers since I would be able to do it after hours?"
99,I am intern and i hate Tableau. Can u give some copium?,101,https://www.reddit.com/r/datascience/comments/17fzssg/i_am_intern_and_i_hate_tableau_can_u_give_some/,82,I used to work in R markdown. My new job require me to switch to Tableau. I feel like i am downgrade myself from Mercedes Benz to Trabant.  I know because i am intern i should do whatever my company tells me. Just give me reasons why Tableau is good to ease my anxiety
100,Imputation of multiple missing values,1,https://www.reddit.com/r/datascience/comments/17gqxzh/imputation_of_multiple_missing_values/,1,"I have a dataset of values for a set of variables that are all complete and I want to build a model to impute any missing values in future observations. A typical use case might be healthcare records where I have weight, height, blood pressure, cholesterol levels, etc. for a set of patients.

The tricky part is that there will be different combinations of missing values for each of the future observations, e.g. one patient misssing weight and height, another patient missing cholesterol and blood pressure. In my dataset I have about 2000 variables for each observation, and in future observations, 90% or more values could be missing, but the data is homogenous so it should be predictable.

I'm looking to compile possible models that can fill in a set of missing values, and have ideally been implemented in Python. So far I have been looking at using GANS ([Missing Data Imputation using Generative Adversarial Nets](https://arxiv.org/abs/1806.02920)) and [MissForest](https://academic.oup.com/bioinformatics/article/28/1/112/219101). Does anybody have any other suggestions of imputers that might work?"
101,"Evaluation Metric Flowchart (possibly handy, interested in feedback!)",2,https://www.reddit.com/r/datascience/comments/17gn08a/evaluation_metric_flowchart_possibly_handy/,0,"&#x200B;

I made this little doodle below as a good-faith effort at trying to lay out a reasonable decision tree for choosing an appropriate model evaluation metric for the sort of basic cases of predictive analytics. I'm ignoring numerous more complex cases of like like NLP, Computer Vision, and even arguably some simpler cases like forecasting, but trying to still cover the bulk of the entry gauntlet. There's obviously innumerable choices one could make for metrics, so the bias here is picking ones that are ""less wrong"" (avoid as many pitfalls as possible), fairly interpretable (e.g. a value of 1 or 0 ""means something""), and have some popular acceptance. Sharing here in case it's helpful, and also I'm interested in others poking holes in the choices I made (if something seems egregious enough)!

My motivation here was mostly out of internal frustration of often seeing folks (online, friends, colleagues) fall into fairly rough pitfalls in their eval choices, and just seeing whether something like this could be reasonably written out. Not for anything else in a sense than the jollies.

https://preview.redd.it/7nplhw2npgwb1.png?width=7162&format=png&auto=webp&s=9bf42afad02bccdb791e88016a78862c7d7faa32"
102,How can you learn to find the insights,1,https://www.reddit.com/r/datascience/comments/17gpxlq/how_can_you_learn_to_find_the_insights/,6,I already know enough technical stuff I believe. But how one can learn to find insights or trends from the data. And then suggest product improvements?
103,How do you maintain motivation in your data role?,17,https://www.reddit.com/r/datascience/comments/17g6gbt/how_do_you_maintain_motivation_in_your_data_role/,8,"Beyond salary which almost everyone requires to survive, how do you maintain motivation in a data role? Specifically when your function is repeatedly called into question and educating the business seems to be an uphill battle? How do you keep going when you have to constantly perform in the corporate popularity contest?

Additionally, how do you maintain motivation when you're working with a domain that you don't like? Not tolerate, generally don't like. "
104,"Tired of armchair coworker and armchair manager saying ""Analysis paralysis""",183,https://www.reddit.com/r/datascience/comments/17fsjf2/tired_of_armchair_coworker_and_armchair_manager/,106," I have an older coworker and a manager both from the same culture who doesn't have much experience in data science. They've been focused on dashboarding but have been given the title of 'data scientist.' They often mention 'analysis paralysis' when discussions about strategy arise. When I speak about ML feasibility analysis, or when I insist on spending time studying the data to understand the problem, or when I emphasize asking what the stakeholder actually wants instead of just creating something and trying to sell it to them, there's resistance. They typically aren't the ones doing the hands-on work. They seem to prefer just doing things. Even when there's a data quality issue, they just plow through. Has that been your experience? People who say ""analysis paralysis"" often don't actually do things; they just sit on the side or take credit when things work out."
105,What is the most suitable model for my problem?,10,https://www.reddit.com/r/datascience/comments/17g8cbj/what_is_the_most_suitable_model_for_my_problem/,9,"I know you would have heard so many people asking this question, but please bear with me.

I had worked on a college project where we just implemented 6 different machine learning models (RF, XGB, GLM, DT, Naive Bayes & GBM) on a health care fraud detection dataset to predict fraud. While interacting with an experienced working professional, he told that this is the stupiedest way to go about a problem. He said we have to choose a model which suits our data the most. But I don't know how to go about selelcting a model that suits the data the most because I don't have enough experience to just select any model based on experience and I didn't find any ""algorithm"" which tells me how to do it. I would like to hear from you about how to go on about this silly problem of mine."
106,How to proceed…,0,https://www.reddit.com/r/datascience/comments/17gn7d8/how_to_proceed/,3,I’m right now coming to the end of my post graduation in data science and how can I proceed from now in order to get a job or an internship? What can be the different methods I can apply. My institute where I’m pursuing right now also promised placement opportunities but I do not want to wait till the end…
107,Learning Cloud Platforms,6,https://www.reddit.com/r/datascience/comments/17g8iu2/learning_cloud_platforms/,0,"I am currently doing some side work for a client that requires creating custom apis and having them run on a server. I am doing it in Google Console. But I noticed that there are so many different features within google console, I was curious if this is essentially a data engineer's life. Learning the  the ins and outs of AWS/Azure/GCS. I feel like it's so different from data science where we focus on concepts vs tools. 

One reason Im curious is if you're the head of an analytics department how do you manage all of this? How would you know how much work something is?"
108,Reducing Goals Using Dats,0,https://www.reddit.com/r/datascience/comments/17gkbw1/reducing_goals_using_dats/,0,We work in an items per hr setting with 100's of various goals used to get a performance rate per worker. Some items can be worked at 4 per hr while some can be worked at 30 per hr.  The different goals are scattered between 2 to 60 per hr.  We want to reduce these hundreds down to maybe 5 to 10 goals with the workers still being able to reach the goals.  Any ideas how that can be accomplished with data?  Is there some sort of percentage difference that would help categorize them?  Any ideas would be appreciated.
109,Do you ever feel dumb when you see data scientists doing exceptional stuff when you are just there doing mundane data-stuff?,270,https://www.reddit.com/r/datascience/comments/17fjgzu/do_you_ever_feel_dumb_when_you_see_data/,72,"Please don't take this post seriously, but I can't help but think that those guys who work at OpenAI, Midjourney,  Google, whatever, despite being Data Scientists just like me (for 6 years, not someone trying to break in), are delivering stuff that I would never be able to, even though we have the same titles on LinkedIn? 

I mean, I'm totally okay with with calling myself a mediocre data Scientist as it is pretty much a choice that I made by enjoying my free time instead of studying my ass off and going for a PhD, but still. Saying that OpenAI staff and myself both are data Scientist feels like saying Messi and some player from a local amateur team are both soccer players."
110,Tech Stack,46,https://www.reddit.com/r/datascience/comments/17fw3zm/tech_stack/,52,"Data Scientists of Reddit, what’s the tech Stack do you use? If you are working in MAANG companies or dealing with huge huge amounts of data, does normal machine learning algorithms work? Is Big Data stack( Hadoop, Spark..) part of your daily drive ? Do you use any other programming language, except Python/R for day to day usage? Are there any tools or technologies that are very useful but major part of the data people don’t know?

I’m Masters in Data Science student, I’m just wondering how real world works, all my projects/assignments just involve python, sklearn library and a famous dataset from kaggle."
111,Need help understanding if the model here is overfitting or not.,7,https://www.reddit.com/r/datascience/comments/17g55zm/need_help_understanding_if_the_model_here_is/,13,"&#x200B;

[ ](https://preview.redd.it/4cikjimrrcwb1.png?width=1546&format=png&auto=webp&s=8aac443256e5e5f18497718aa7d928d143a41b9b)

I've been training this model and what I'm seeing is that after around 100 epochs, the loss of training data goes down, whereas the loss of validation data goes up, which indicates overfitting. However, the accuracy metric for both training and validation data keeps on increasing after around 100 epochs, which indicates that the model is not overfitting.  I've never encountered this before. I assumed that the loss and accuracy metric behaved in somewhat similar manner, but they are not behaving like that in this case. Can anyone explain why this is happening. Is the model overfitting or not?

Edit: I'm using BinaryCrossentropy loss function. The problem I'm trying to solve is from the kaggle's titanic competition. Basically, it's tabular structured data that has features 'TicketClass', 'Name', 'Sex', 'Age', 'SiblingsBoarded', 'ParentsBoarded', 'Fare', 'Embarked' and target is 'Survived'(1/0). Let me know if you need more info."
112,How to get into data science entry level position with an engineering degree?,0,https://www.reddit.com/r/datascience/comments/17gnj7i/how_to_get_into_data_science_entry_level_position/,7,
113,"Data scientists reporting to CTO/equivalent (1 step below CEO), what's your job title?",6,https://www.reddit.com/r/datascience/comments/17g41qs/data_scientists_reporting_to_ctoequivalent_1_step/,23,Any company size (please include in response if possible).
114,Vector DB directory structuring - ideal?,1,https://www.reddit.com/r/datascience/comments/17gej5o/vector_db_directory_structuring_ideal/,0,"Vector DB offerings today are structured in such a way that the user is expected to have all files/file embeddings in the same place, and every time a search is effected, the entirety of that pool is queried through.

If so prepared, a user can do some filtering through metadata tags. However, this feels like a limited and clunky way to reduce the scope of what's queried.

Am I missing something here? Do most use cases call for all files/vectors being kept in the same bucket, as opposed to some other arrangement? What use cases work best with a ""big bucket"" structure in which everything is kept in the same place?"
115,Worthwhile to post personal and pro-bono projects under my company page in order to list experience?,2,https://www.reddit.com/r/datascience/comments/17g7vsr/worthwhile_to_post_personal_and_probono_projects/,0,"I have a company page and branding package set up on LinkedIn – is it in bad taste to list actual personal and pro-bono projects as experience in order to not have a huge employment gap?

Some details: I'm a Data Analyst with CRM consulting experience but currently unemployed since June (layoffs). I have professional work I've created but not yet published (ie. dashboards, architecture frameworks, wireframes, etc.) that I would be publishing under my profile and tagging my company. Some of this work involves working with real-world businesses for free."
116,Cloud computing trends in data science,1,https://www.reddit.com/r/datascience/comments/17g9mzj/cloud_computing_trends_in_data_science/,1," Hey there, fellow data science people,

I'm reaching out for a little help and some advice in my quest to jump into the data science world. I come from a biotech background and have been devouring data science content for the past year, but I'm having a bit of a struggle finding my first gig.

Here's where I need advice. I'm curious about which cloud computing system is currently the talk of the town in the data science universe. With tech evolving fast, I want to make sure I'm learning a cloud platform that'll give me some edge in the job market. I guess the battle is between Azure and AWS, but between those two I dont know what would best to learn if you dont know any.

And last but not least, I'm all eyes for recommendations on these cloud computing systems certifications that could beef up my skillset and make me more hireable. 

Thank you a lot in advance"
117,"[P][R] Test-Val scores, how much difference isn't problematic.",3,https://www.reddit.com/r/datascience/comments/17g01rn/pr_testval_scores_how_much_difference_isnt/,0,"Hello folks, I'm working on a medical image dataset using EM loss and asymmetric pseudo labelling for single positive multi-label learning (only training using 1 positive label). I'm using a densenet121 and on a chest x-ray dataset.

1. I see a difference of 10% in my validation vs test score (score = mAP: mean average precision). The score seems okay and was expected but the difference is bothering me. I understand that it's obvious but any visual insights from your side? (Attaching plot below)
2. The validation set consist less than half of test set samples. (It is the official split; I have nothing to do with it). I feel it is the reason, as ofcourse more the randomness in a set, poorer the convergence.

&#x200B;

https://preview.redd.it/nseqy1mw5bwb1.png?width=577&format=png&auto=webp&s=fbd63e8a5f4920a8109b6a75aeb039a3965bba58

Do share any experiences or suggestions!"
118,Choosing between google data studio (Looker studio now I guess) and Tableau.,1,https://www.reddit.com/r/datascience/comments/17g1rz7/choosing_between_google_data_studio_looker_studio/,3,"Hey there. 
We are going to start working with Google sheets and podio.
We wanted to know which tool would be easier to learn and start working with. 
We are still beginners and we don't have access to paid versions and I got confused searching online.

What would be the pros and cons of using each tool. 

Thanks in advance."
119,keras tuner vs keras classifier vs neural network search,3,https://www.reddit.com/r/datascience/comments/17fthoj/keras_tuner_vs_keras_classifier_vs_neural_network/,2,"i know this technique called keras tuner for tuning the model's hyperparameters . and then i also found that using for loop we can also select number of layers . and then i heard of this keras classifier that is used to search optimum number of layers and one more technique i head of is NAS Neural Network Search .   


keras tuner vs ( keras classifier ) keras.wrappers.scikit-learn.kerasClassifier vs neural network search (NAS)

can someone please help me with the difference among these three and what cases each can be considered ?"
120,The role of data scientists in NLP,0,https://www.reddit.com/r/datascience/comments/17fytrb/the_role_of_data_scientists_in_nlp/,22,"As data scientists some of us used to do a lot of work wrangling masses of unstructured text data (like tweets for example) into insights through various NLP, topic modelling, sentiment analysis, clustering approaches etc. However, ChatGPT seems to perform miles better than any of those older methods with just a UI. So my question is, what is the role of data scientists in insight-driven NLP projects these days if it's not ""advanced prompt engineering""?"
121,Contractors who are called Data Scientists but can't do what I'd expect. What to do next.,208,https://www.reddit.com/r/datascience/comments/17eu3rm/contractors_who_are_called_data_scientists_but/,198,"Ok so, I was hired as a senior member of a pre-existing data science team. I now manage a few other team members (who were there before me). They are all contractors and their day rate is HIGH. They are all 'Data Scientists' and graduates.

I'm older. I've done lots of technical roles and I'm not really sure what my official title is. I can do data science but I really just build stuff. I've done Data Engineering in the past, MLOps, DevOps, Cloud etc. I'm a jack of all trades, master of none.

Now, I know what ***I think*** a 'Data Scientist' should be able to do:

1. Pandas, Numpy, Scikit learn, matplotlib blah blah blah
2. Version control (Git)
3. Managing virtual environments
4. Debugging within an IDE
5. Scoping out a project, ideation, exploration
6. Report writing skills/communication skills
7. Some exposure to clean code conventions (PEP-8)
8. Some exposure to SQL like syntax
9. bit of linux would be cool (I can teach them)
10. bit of cloud would be cool (I can teach them)

I've had to mentor the team HARD. Most of the team did not know what Git was, most of the team had never debugged their code, never made a venv. In fact I have had to teach them steps 1-5. That would be fine if they were now hitting the ground running, but the moment I stop mentoring them, the productivity stops. No initiative.

And yet, I want to hire externally. I want to give them the opportunity to apply but I just know they won't measure up against the talent pool out there. I've hired Data Scientists before and I know how good people are out there.

Am I totally wrong? Do I need to cut them some slack? Anyone got any comments?

edit: spelling"
122,Human behaviour is more complex than too much shallow analysis (why you need to dig deeper),0,https://www.customerinsightleader.com/opinion/human-behaviour-is-more-complex-than-too-much-shallow-analysis/,2,
123,Consulting for coffee shops,5,https://www.reddit.com/r/datascience/comments/17ffp2f/consulting_for_coffee_shops/,10,Does anyone have experience consulting for small businesses like coffee shops or even smaller stores? There's a store near me that I would love to offer my services to for free -- but not sure how I can present myself as being useful to them and wanting them to actually work with me.
124,"Mysql to ""Big Data""",4,https://www.reddit.com/r/datascience/comments/17fdltj/mysql_to_big_data/,19,"Hi Folks,

Looking for some advice, have an ecommerce store, decent volume of data in 10m orders over the past few years etc. \~ 10GB of data.

Was looking to get the data into data studio (looker), crashed. Then looked at power bi, crashed on publishing just the order data (\~1GB)

Are there alternatives? What would the best sync to a reporting tool be?"
125,"In the context of topic modeling, what should be done when the highest coherence value, given a specific 'k' value and a particular metric, does not result in interpretable topics?",1,https://www.reddit.com/r/datascience/comments/17fjeyw/in_the_context_of_topic_modeling_what_should_be/,2,"Hi everyone,

I'm currently working on an LDA Topic Modeling project applied to a specific field. Essentially, I want to label different subcategories within this field. The data I'm dealing with is relatively complex and messy.

While I'm aware of the ongoing challenge of automatic topic modeling, which still requires human judgment and supervision after topics have been generated, I've read that certain metrics attempt to replace human judgment when it comes to evaluating the coherence of words within a topic (like C\_V metric). Thus, they need to be maximized (I suppose?).

However, I've also read that the most crucial consideration, in the end, is to create topics that are understandable to humans.

I find myself in a situation where I have a larger number of topics, let's say 7 < k < 10, where the Coherence metric (C\_V) peaks at 0.48, which, based on what I've read, seems like a good score. However, what happens is that, for the most, the topics themselves do not make sense at all. 

In contrast, when I set my number of topics to 3-4, I have much more interpretable topics. This might be because of the implication of summarization, which means fewer topics that gather more latent topics within the same topic.

Considering that this project is being revised by a professor, how can I justify what is going on? I know that there's specific literature out there stating that Coherence is not an entirely reliable judgement parameter, but haven't managed to find anything consistent. 

Thank you."
126,"Outside of Generative AI, what are the big advances currently happening in Data Science?",48,https://www.reddit.com/r/datascience/comments/17esy03/outside_of_generative_ai_what_are_the_big/,34,"There's been a lot of chatter about AI, specifically things like LLAMA 2, GPT-4, etc. But, what have been some recent advancements not in the AI sphere that are important in Data Science?"
127,What do you do in SQL vs Pandas?,60,https://www.reddit.com/r/datascience/comments/17eot80/what_do_you_do_in_sql_vs_pandas/,64,"My work primarily stores data in a full databases. Pandas has a lot of similar functionality to SQL in regards to the ability to group data and preform calculations, even being able to take full on SQL queries to import data. Do you guys do all your calculations in the query itself, or in python after the data has been imported? What about with grouping data?"
128,What do fellow Data Science Directors do?,82,https://www.reddit.com/r/datascience/comments/17el93s/what_do_fellow_data_science_directors_do/,41,"I am a director and I feel like I barely do ""Data Science"" any more. My job is mostly about working with engineers and architects to facilitate data collection and data tools (python, spark) for my team. Is this relevant for career advancement or do I need to refocus more on hard skills and learning new stuff."
129,ConnectorX + Arrow + dlt loading: Up to 30x speed gains in test,1,https://www.reddit.com/r/datascience/comments/17fbj3u/connectorx_arrow_dlt_loading_up_to_30x_speed/,0,"Hey folks

over at [https://pypi.org/project/dlt/](https://pypi.org/project/dlt/) we added a very cool feature for copying production databases. By using ConnectorX and arrow, the sql -> analytics copying can go up to 30x faster over a classic sqlite connector.

Read about the benchmark comparison and the underlying technology here: [https://dlthub.com/docs/blog/dlt-arrow-loading](https://dlthub.com/docs/blog/dlt-arrow-loading)

One disclaimer is that since this method does not do row by row processing, we cannot microbatch the data through small buffers - so pay attention to the memory size on your extraction machine or batch on extraction. Code example how to use: [https://dlthub.com/docs/examples/connector\_x\_arrow/](https://dlthub.com/docs/examples/connector_x_arrow/)

By adding this support, we also enable these sources:[https://dlthub.com/docs/dlt-ecosystem/verified-sources/arrow-pandas](https://dlthub.com/docs/dlt-ecosystem/verified-sources/arrow-pandas)

If you need help, don't miss the gpt helper link at the bottom of our docs or the slack link at the top.

Feedback is very welcome!

&#x200B;"
130,"Besides FAANG, what other companies out there are doing actual DS or MLE work?",19,https://www.reddit.com/r/datascience/comments/17er8bt/besides_faang_what_other_companies_out_there_are/,17,"In my present company we are just chasing ad hoc analytical  work - these never gets into production. The processes are very ad hoc, not streamlined, no structure to it, running from personal notebooks. It’s very demoralizing to see models developed from 2017 that are in production and have not been refreshed thought the data it used for inference is constantly changing as my company looks at market finance data. 

I’m wondering what are other good companies to look out for that are either applying best practices in DS/ML and not just the talk or building product/services. 

I understand recent news in GenAI is sparking lot of conversations but which companies out there are grabbing it by the horns and taking the lead? Perhaps if you are fortunate to work for one such company you may want to share your story. Appreciate your insights very much!"
131,Pandas-based library for graphing emotion events with LMs for in-depth sentiment analysis,49,https://i.redd.it/hdls4kgrzxvb1.jpg,6,
132,Machine learning for Asset Allocation and long/short decisions in a Tactical Asset Allocation Strategy,1,https://www.reddit.com/r/datascience/comments/17f7jo6/machine_learning_for_asset_allocation_and/,0,"&#x200B;

I'd love to hear your guys thoughts on next steps to improve this, maybe deeper layers and more nodes, maybe a random forest is more appropriate? I'd love to hear any thoughts on Machine Learning directly applicable to time-series data specifically here I am applying machine learning to drive asset allocation in an investmen portfolio

[https://www.quantitativefinancialadvisory.com/post/asset-allocation-in-a-post-modern-portfolio-theory-world-part-1-the-single-layer-taarp-ml-model](https://www.quantitativefinancialadvisory.com/post/asset-allocation-in-a-post-modern-portfolio-theory-world-part-1-the-single-layer-taarp-ml-model)

&#x200B;"
133,What are the non-data scientist tasks that you still do in your data scientist role?,66,https://www.reddit.com/r/datascience/comments/17efkcz/what_are_the_nondata_scientist_tasks_that_you/,69,
134,Data science in floriculture/horticulture,1,https://www.reddit.com/r/datascience/comments/17f6c47/data_science_in_floriculturehorticulture/,1,Anyone having experience in this sector? Looking for a seasoned data scientist in this sector
135,[Discussion] Paraphrase for Writing Tone,0,https://www.reddit.com/r/datascience/comments/17f3whi/discussion_paraphrase_for_writing_tone/,0,"Hi Everyone,

Recently, I have been doing a task related to paraphrasing in writing tones. Specifically, I'm trying to fine-tune the pre-trained model (text generation model) to create a model capable of rewriting according to the transmitted tone.

Currently, I am trying to crawl data (about 1500 samples) for training. However, the results were not as good as I thought. I'm currently quite stuck, can you guys suggest to me some research or open-source or pre-trained models that you've tried?

Thank you

P/s: model I have tried

[https://huggingface.co/llm-toys/falcon-7b-paraphrase-tone-dialogue-summary-topic](https://huggingface.co/llm-toys/falcon-7b-paraphrase-tone-dialogue-summary-topic)

[https://huggingface.co/Vamsi/T5\_Paraphrase\_Paws](https://huggingface.co/Vamsi/T5_Paraphrase_Paws)

[https://huggingface.co/humarin/chatgpt\_paraphraser\_on\_T5\_base](https://huggingface.co/humarin/chatgpt_paraphraser_on_T5_base)"
136,Anyone have a good blog or resource on Product-led experimentation?,1,https://www.reddit.com/r/datascience/comments/17f02jx/anyone_have_a_good_blog_or_resource_on_productled/,8,"Would be nice to understand frameworks , experiment types, how to determine what experiment to use , and where and when to apply them to a saas company and help them prioritize a roadmap against it. 
"
137,Any pointers / resources on how one would implement a ML model for product demand transference and substititabilty,2,https://www.reddit.com/r/datascience/comments/17eug5a/any_pointers_resources_on_how_one_would_implement/,2,"I am currently undergoing Apprenticeships programme for ML, and looking for projects in our organization.

""Demand Transference and Substititabilty"" in retail food stores is one of the ideas that came up. So i am trying to find on how to implement it and if we have all the required data before finalising the project selection. 

Any resources or information would be great :)"
138,Why would anyone start to use Hex? What’s the need or situation?,3,https://www.reddit.com/r/datascience/comments/17eu7oy/why_would_anyone_start_to_use_hex_whats_the_need/,15,
139,Estimating sales of a new store,1,https://www.reddit.com/r/datascience/comments/17ew2w4/estimating_sales_of_a_new_store/,3,"I've got the task to estimate the sales level of a store in a place near a mall and a office area. Would like to know if somebody here has made a similar task reacently or has any idea of how can i get an estimation.

I have data of 6 more stores of the same company (sales, transactions, area fo the store, #people near a 15 minute isochrone, if the stores are near offices, colleges, residential areas, etc).

I've been planning to run a regression model or a decision tree and later use trained model to estimate the sales level of the new position, but just having 6 stores makes it hard to have a consistent estimation.

What other options could i do to have a good estimation of this new position? what other things i have to consider o look for to have as data in my model? is there any framework for this kind of task?

Thanks!"
140,Best way to go about showing progress as work is done to a dataset,1,https://www.reddit.com/r/datascience/comments/17euytw/best_way_to_go_about_showing_progress_as_work_is/,7,"Hello there,

I'm an undergrad student that is currently working on a Kaggle dataset and I want to document my progression and be able to share it as I go. In addition, I'd really want to get involved with the DS community. Now, I do have deficiency in certain tools like GitHub which is a place I could post my work. However, I do also want to be able to include it in my resume as I think it would make it more appealing for recruiters in the future. What is the best way to go about this? Just create a reddit or LinkedIn Post (like a progress post) or simply just have it up on GitHub and learn how to use the tool ? Thank you in advance for your suggestions."
141,PG extension (Apache AGE) for adding graph analytics functionality,1,https://www.reddit.com/r/datascience/comments/17eriso/pg_extension_apache_age_for_adding_graph/,0,"I have talked this previously, that like, I am working as a data analyst but is it worth to learn graph database. I got some comments that saying master SQL first, then learn other tools. For me, learning a new fun tool is for my free time so I thought, OK, I will just try it. It is been a month almost and came back to think like,,, I don't feel the graph database is that much worth to learn especially if I consider the size of the market.

However, maybe, if there's a PG extension that adds graph analytics to PG database, which I use everyday, it would be fun because I can actually utilize it with my PG data. Apache AGE is an open-source PG extension that really solves the problem that I'm having right now. I will leave the [github link](https://github.com/apache/age) and a [webinar link](https://us06web.zoom.us/webinar/register/2516980853755/WN_mzhlCggCQ_ytIxiGb9ioTg) that they (I guess Apache Foundation?) organize like bi-weekly. For those who are having same thought process with me, I think you guys also can just try? What do you think?"
142,Relational database to graph database using NLP/LLM?,1,https://www.reddit.com/r/datascience/comments/17erhca/relational_database_to_graph_database_using_nlpllm/,0,I’m looking to discover new relationships that exist in the relational database and then generate ingestion script to populate a graph database. Are there tools already exhausting for this and what are their limitations? Can we he new LLMs come to rescue?
143,Good survey of predictive techniques?,0,https://www.reddit.com/r/datascience/comments/17epzut/good_survey_of_predictive_techniques/,5,"Currently on a job search, and of course many DS roles are seeking prediction/forecasting skills. Can anyone recommend an overview of different predictive techniques? It could be an article, video, book, or even your own explanation.

There are so many things one could learn about regression, machine learning, etc. and I would find it useful to have some sort of organizing framework for various methods of prediction.

Thanks!"
144,How do you guys practise using MySQL,149,https://www.reddit.com/r/datascience/comments/17dtmqe/how_do_you_guys_practise_using_mysql/,74,Hi I'm fairly new to Data Science and I'm only now learning about MySQL. I have only previous experience on R and MySQL is really causing me problems. I understand everything when studying and watching content on the language but I get stuck when trying examples with real dataset. How do I get better on MySQL?
145,Address parsing with NLP or with regex,0,https://www.reddit.com/r/datascience/comments/17enm4q/address_parsing_with_nlp_or_with_regex/,11,"Hi i am working on this a project and its a module of a huge project where i have to write code  to parse address provided.

I was first using Libpostal but for the provided data, libpostal is not effiecient and i want to create my custom parsing.

I am trying to use regex but it seems very complicated. Can anyone help me if there’s any other way .

I found it is possible using NLP with spaCy.

Please guide"
146,Project Interface.,1,https://www.reddit.com/r/datascience/comments/17en64n/project_interface/,2,"Hello,

I'm updating my Portfolio to get back to DS. Working on a project I'd like to put the algorithm into an interface. Is it better to try and do it using other programming languages like JavaScript or Python is sufficient using Flask or Streamlit ? "
147,Just read the fascinating article about deployment of website using streamlit.How easy it has become to deploy and develop any website using this tool,0,https://medium.com/@harshsmj1504/ipl-win-predictor-easy-streamlit-development-and-deployment-guide-bce15bce99b1,3,
148,Looking for a Data Science Program,0,https://www.reddit.com/r/datascience/comments/17em9tn/looking_for_a_data_science_program/,2,I am a software engineer with 10yo experience. Can someone recommend a good Data Science program? I am willing to spend 3-6 months to get a deep understanding of the fundamentals.
149,Do you remember the syntax of the tools you use?,38,https://www.reddit.com/r/datascience/comments/17e01li/do_you_remember_the_syntax_of_the_tools_you_use/,36,"To all the data science professionals, enthusiasts and learners, do y'all remember the syntax of the libraries, languages and other tools most of the time? Or do you always have a reference resource that you use to code up the problems? 

I have just begun with data science through courses in mathematics, stochastics and machine learning at the uni. The basic Python syntax is fine. But using libraries like pandas, scikit learn and tensorflow, all vary in their syntax. Furthermore, there's also R, C++ and other languages that sometimes come into the picture. 

This made me think about this question whether the professionals remember the syntax or they just keep the key steps in their mind. Later, when they need, they use resources to use the syntax. 

Also, if you use any resources which are popular, please share in the comments."
150,Productivity help,1,https://www.reddit.com/r/datascience/comments/17eh6kb/productivity_help/,6,"Happy monday guys! 

Quick question – what do you do on light days where you don’t have much(or any) work and want to maintain your productivity, especially when working from home? 

I would love to increase my theory/stress on learning new skills! So if you’re one who reads books/blogs would love to know what you guys read or any book recommendations

Cheers guys, have a great week!"
151,What problems would you like to be solved?,9,https://www.reddit.com/r/datascience/comments/17eafwm/what_problems_would_you_like_to_be_solved/,43,"I'm a data scientist looking to solve a problem that you have. My experience is on regressions, classification and scores for credit. Could it be somehing that exist and its expensive, something that it's not out there, etc. Looking to help :)"
152,"Weekly Entering & Transitioning - Thread 23 Oct, 2023 - 30 Oct, 2023",5,https://www.reddit.com/r/datascience/comments/17eboh0/weekly_entering_transitioning_thread_23_oct_2023/,107," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new)."
153,Native Linux Users: How do you setup your DS Environment?,10,https://www.reddit.com/r/datascience/comments/17e7m1p/native_linux_users_how_do_you_setup_your_ds/,19,"Not talking folks who work off linux servers or VMs, I'm talking about those of us who work on a linux install running on our local hardware that might also run other things (games, media, etc)

I do all my work through windows (corporate laptop) but sometimes I want to try out toy problems and other things on a personal machine.

I was using Anaconda, but something about the conda shell caused Arch to try to compile system packages within the conda environment and things went haywire.

Rolling my own python virtual env just feels like work, and again, I broke my window manager (qtile, runs on python) by setting it up.

Not against going back to Anaconda, but I'm curious what other folks in my situation (daily drive linux on their primary personal machine, on which they also do some data work) do to keep a working data science environment going."
154,How many hours do other data analysts work?,0,https://www.reddit.com/r/datascience/comments/17erxid/how_many_hours_do_other_data_analysts_work/,8,"Separating things like meetings and actually sitting down and writing code/working through problems, what's your workload like?

I work for an academic department and I can't tell if things are...off lol. It's my first real job btw. "
155,The obsession/hate for DS undergrad degrees,24,https://www.reddit.com/r/datascience/comments/17e02jy/the_obsessionhate_for_ds_undergrad_degrees/,109,"I understand ALOT of online DS degrees are a cash grab with maybe a handful of conceptual courses that aren't technical in the slightest or give good real-world skills like writing efficient SQL queries or otherwise.

That being said, a ton of programs for DS out there including the one I'm taking currently are more or less a mix between CS and Stats with a few database or data science code or math-specific courses mixed in. Before my university had a DS degree path it was considered a specialty focus on data science but the main degree was CS until they swapped it to a full-on path.

&#x200B;

Just a rant, I've been considering switching to CS in light of finding out people strongly dislike DS degrees but I enjoy my DS courses way more than a CS or Stats-focused degree that only covers those domains. Can a solid project on github overcome these objections?

Edit: most people are assuming I want to immediately jump into a DS role. I do not. I plan on being an analyst or some other entry level adjacent role before for a few years before switching to DS or DE.

I think most any undergraduate would fall flat on their face besides the most technical and self taught alongside their classes if they jumped into DS from the getgo, assuming someone with even a year more experience doesn't beat you to the punch first.


If you disagree with something I, or anyone else says in here, instead of down voting to all oblivion tell myself or that person you disagree with *why* they're wrong and need to switch their viewpoint. I'll be making a summary of the points I've seen in here in a few days for people to look through in the future.

----------------------------------------------------------------------------------

Here's the summary of points I've seen made here that have convinced me to switch to CS/Stats minor for anyone in the future who might also have the same question whether or not to choose or switch away from a DS undergrad degree. If I missed anything shoot me a message.

1. CS/Stats is a much more flexible degree path, if the landscape of data as a whole changes, this degree structure is going to be vastly more resistant to changes in what a ""Data Scientist"" even is in the labor market. This choice will also set you up much post for grad school.

2. DS degree graduates, no matter how quality the program is, will be passed in comparison to a CS major. Pre-conceived notions are hard to change and DS degrees are very new / lack a generalized structure compared to CS and Stats majors that more or less have an expected outcome quality in graduates.

3. DS degree graduates as a result of the lack of a single path / consistent course training, *will have gaps in basic skills/knowledge CS/Stats minor graduates won't*. It's best to embrace the filter classes of CS degrees to make sure you aren't falling flat on your face if you get into a DS role.

4. Whether you're choosing something more programming focused like Data Engineering, or something more research / statistically focused like a Data Scientist, CS/Stats will just flat out prepare you better for those jobs while keeping your options open for other roles in CompSci if you end up changing your mind.

5. DS degrees are fine if you plan on being an Analyst, but then again, there are a lot of other non-technical degrees that can become analysts.

6. Projects are not weighted as heavily as people might think, recruiters most likely will not be looking at them unless in very specific scenarios which is why having a better base of CS/Stats tends to work out better.

7. Some aspects of CS degrees will suck but in the grand scheme of being more marketable, the difference in prestige and chances of landing a job vs a DS degree is significant enough to switch degrees or choose CS/Stats to begin with. 

8. In a summarized sense, getting a CS/Stats minor focus is a more pure form of what DS courses should be, but aren't.

Thanks to everyone who didn't just downvote the post and wrote their own perspective, I'll be talking with a counselor to switch to CS & Stats minor tomorrow.

And good luck to anyone in the future coming to this post for answers, it is worth choosing a CS degree and if you have any questions and you're coming through here months or years from now, read through the comments on here to make sure you're making the best decisions for your career."
156,Wondering whether the following problem is workable?,1,https://www.reddit.com/r/datascience/comments/17eirhz/wondering_whether_the_following_problem_is/,3,"So I need to explore an odd problem. We have an old dataset of interview sessions (its not our dataset). It works as follows.

The candidate comes in, goes through several rounds of interviews (from 1 - 5) each with its own interviewer. (We know the number of interviewers)

After each round, the candidate rates the interviewer (score from 0 to 5). (We do not have this data)

Finally, an overall score is calculated for the entire interview session based on the ratings for each round. (We know the overall score but we do not know how it was calculated)

So essentially, the dataset is roughly off the form:

session_id, score, [interviewer_id1, interviewer_id2, interviewer_id3 ...] (This list is unordered)

The question is: given a particular interviewer_id, is it possible to determine whether he generally got positive or negative ratings?

For context, I write software and don't know much beyond stats 101 so I would appreciate any and all pointers. I would ordinarily say no to the above question but I have met people who've been able to pull signals out of noise so it behoves me to ask.

Thanks."
157,How to Optimize Multidimensional Numpy Array Operations with Numexpr,1,https://www.reddit.com/r/datascience/comments/17egeux/how_to_optimize_multidimensional_numpy_array/,0,"# A real-world case study of performance optimization in Numpy

This article was originally published on my personal blog [Data Leads Future](https://www.dataleadsfuture.com/how-to-optimize-multidimensional-numpy-array-operations-with-numexpr/).

&#x200B;

[ How to Optimize Multidimensional Numpy Array Operations with Numexpr. Photo Credit: Created by Author, Canva. ](https://preview.redd.it/r24q1n674yvb1.png?width=1387&format=png&auto=webp&s=ab8950800797f55f538fdb1343df6d275bd07152)

This is a relatively brief article. In it, I will use a real-world scenario as an example to explain how to use [Numexpr expressions](https://numexpr.readthedocs.io/en/latest/user_guide.html?ref=dataleadsfuture.com#supported-functions) in multidimensional Numpy arrays to achieve substantial performance improvements.

There aren't many articles explaining how to use Numexpr in multidimensional Numpy arrays and how to use Numexpr expressions, so I hope this one will help you.

# Introduction

Recently, while reviewing some of my old work, I stumbled upon this piece of code:

    def predict(X, w, b):
        z = np.dot(X, w)
        y_hat = sigmoid(z)
        y_pred = np.zeros((y_hat.shape[0], 1))
    
        for i in range(y_hat.shape[0]):
            if y_hat[i, 0] < 0.5:
                y_pred[i, 0] = 0
            else:
                y_pred[i, 0] = 1
        return y_pred

This code transforms prediction results from probabilities to classification results of 0 or 1 in the logistic regression model of machine learning.

But heavens, who would use a `for loop` to iterate over Numpy ndarray?

You can foresee that when the data reaches a certain amount, it will not only occupy a lot of memory, but the performance will also be inferior.

That's right, the person who wrote this code was me when I was younger.

With a sense of responsibility, I plan to rewrite this code with the Numexpr library today.

Along the way, I will show you how to use Numexpr and Numexpr's `where` expression in multidimensional Numpy arrays to achieve significant performance improvements.

## Code Implementation

If you are not familiar with the basic usage of Numexpr, you can refer to this article:

[https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/](https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/)

This article uses a real-world example to demonstrate the specific usage of Numexpr's API and expressions in Numpy and Pandas.

*where(bool, number1, number2): number* *- number1 if the bool condition is true, number2 otherwise.*

The above is the usage of the where expression in Numpy.

When dealing with matrix data, you may used to using Pandas `DataFrame`. But since the `eval` method of Pandas does not support the `where` expression, you can only choose to use Numexpr in multidimensional Numpy ndarray.

Don't worry, I'll explain it to you right away.

Before starting, we need to import the necessary packages and implement a `generate_ndarray` method to generate a specific size ndarray for testing:

    from typing import Callable
    import time
    
    import numpy as np
    import numexpr as ne
    import matplotlib.pyplot as plt
    
    rng = np.random.default_rng(seed=4000)
    
    def generate_ndarray(rows: int) -> np.ndarray:
        result_array = rng.random((rows, 1))
        return result_array

First, we generate a matrix of 200 rows to see if it is the test data we want:

    In:  arr = generate_ndarray(200)
         print(f""The dimension of this array: {arr.ndim}"")
         print(f""The shape of this array: {arr.shape}"")
    
    
    Out: The dimension of this array: 2
         The shape of this array: (200, 1)

To be close to the actual situation of the logistic regression model, we generate an ndarray of the shape `(200, 1)` Of course, you can also test other shapes of ndarray according to your needs.

Then, we start writing the specific use of Numexpr in the `numexpr_to_binary` method:

* First, we use the index to separate the columns that need to be processed.
* Then, use the where expression of Numexpr to process the values.
* Finally, merge the processed columns with other columns to generate the required results.

Since the ndarray's shape here is `(200, 1)`, there is only one column, so I add a new dimension.

The code is as follows:

    def numexpr_to_binary(np_array: np.ndarray) -> np.ndarray:
        temp = np_array[:, 0]
        temp = ne.evaluate(""where(temp<0.5, 0, 1)"")
        return temp[:, np.newaxis]

We can test the result with an array of 10 rows to see if it is what I want:

    arr = generate_ndarray(10)
    result = numexpr_to_binary(arr)
    
    mapping = np.column_stack((arr, result))
    mapping

[ I test an array of 10 rows and the result is what I want. Image by Author ](https://preview.redd.it/o1h5bwdn8xvb1.png?width=351&format=png&auto=webp&s=d6977cc422be66a8c37980554c1478e76d2d326c)

Look, the match is correct. Our task is completed.

The entire process can be demonstrated with the following figure:

&#x200B;

[ The entire process of how Numexpr transforms the multidimensional ndarray. Image by Author ](https://preview.redd.it/aw26lp8q8xvb1.png?width=915&format=png&auto=webp&s=df44481e44b2dc48b3acd522b51327b9030e2335)

## Performance Comparison

After the code implementation, we need to compare the Numexpr implementation version with the previous `for each` implementation version to confirm that there has been a performance improvement.

First, we implement a `numexpr_example` method. This method is based on the implementation of Numexpr:

    def numexpr_example(rows: int) -> np.ndarray:
        orig_arr = generate_ndarray(rows)
        the_result = numexpr_to_binary(orig_arr)
        return the_result

Then, we need to supplement a `for_loop_example` method. This method refers to the original code I need to rewrite and is used as a performance benchmark:

    def for_loop_example(rows: int) -> np.ndarray:
        the_arr = generate_ndarray(rows)
        for i in range(the_arr.shape[0]):
            if the_arr[i][0] < 0.5:
                the_arr[i][0] = 0
            else:
                the_arr[i][0] = 1
        return the_arr

Then, I wrote a test method `time_method`. This method will generate data from 10 to 10 to the 9th power rows separately, call the corresponding method, and finally save the time required for different data amounts:

    def time_method(method: Callable):
        time_dict = dict()
        for i in range(9):
            begin = time.perf_counter()
            rows = 10 ** i
            method(rows)
            end = time.perf_counter()
            time_dict[i] = end - begin
        return time_dict

We test the numexpr version and the `for_loop` version separately, and use `matplotlib` to draw the time required for different amounts of data:

    t_m = time_method(for_loop_example)
    t_m_2 = time_method(numexpr_example)
    plt.plot(t_m.keys(), t_m.values(), c=""red"", linestyle=""solid"")
    plt.plot(t_m_2.keys(), t_m_2.values(), c=""green"", linestyle=""dashed"")
    plt.legend([""for loop"", ""numexpr""])
    plt.xlabel(""exponent"")
    plt.ylabel(""time"")
    plt.show()

[ The Numexpr version of the implementation has a huge performance improvement. Image by Author ](https://preview.redd.it/i5trs6h79xvb1.png?width=595&format=png&auto=webp&s=d508bddb500f8065c75921c1905f14e414ccf932)

It can be seen that when the number of rows of data is greater than 10 to the 6th power, the Numexpr version of the implementation has a huge performance improvement.

## Conclusion

After explaining the basic usage of Numexpr in the previous article, this article uses a specific example in actual work to explain how to use Numexpr to rewrite existing code to obtain performance improvement.

This article mainly uses two features of Numexpr:

1. Numexpr allows calculations to be performed in a vectorized manner.
2. During the calculation of Numexpr, no new arrays will be generated, thereby significantly reducing memory usage.

Thank you for reading. If you have other solutions, please feel free to leave a message and discuss them with me.

This article was originally published on my personal blog [Data Leads Future](https://www.dataleadsfuture.com/how-to-optimize-multidimensional-numpy-array-operations-with-numexpr/)."
158,How to do a time series forecast on sentiment?,0,https://i.redd.it/slcxmqkgqwvb1.jpg,9,"
I'm using the sentiment140 dataset from kaggle and have done average daily sentiment using Vader, nltk and textblob.

In all cases I can see a few problems:

* gaps with no data (tried filling in - red)
* a sudden drop in sentiment from 15th June

How would you go about doing a forecast on that data? What's advice can you give?"
159,The Changing Landscape of Data Science,33,https://www.reddit.com/r/datascience/comments/17dsyjh/the_changing_landscape_of_data_science/,27,"It's fascinating to see how the field of Data Science has evolved in recent years. Just a few years ago, there weren't many dedicated PhD programs in Data Science, and professionals from various STEM backgrounds often considered it as an alternative career option. However, today, we have a plethora of Master's and even a few PhD programs specializing in Data Science. This transformation has turned Data Science into a distinct field, encompassing everything from analytics to ethics.

Will candidates with PhDs in traditional STEM fields become less favored for Data Science jobs in the future, with Data Science program graduates taking the lead? 

Will the field place more emphasis on specialized education as it continues to mature?

What are your thoughts on this matter?"
160,"Title not matching tasks, am I making it a big deal?",1,https://www.reddit.com/r/datascience/comments/17eeucx/title_not_matching_tasks_am_i_making_it_a_big_deal/,11,"I am studying a master’s in data science and working as a “junior data scientist” as my first ever job at a start up. Problem is, even though I have ended the more “data science” part of my degree (ML, advanced math/statistics etc.), at work, I’m working more on reporting (power bi, excel, sql). I have never built or implemented any model, except for the finals I passed like 5 months ago. Sadly, I don’t remember anything from them. 

I’m approaching 1 year in experience, and my goal is to apply for junior/entry level jobs preferably in the UK or Netherlands. However, I fear that even if I land an interview, there’s no way I can make it past any of them because of the discrepency between my title and actual experience."
161,Which features/factors help determine the likelihood of developing tooth decay?,0,https://www.reddit.com/r/datascience/comments/17egh5m/which_featuresfactors_help_determine_the/,4,"I’m trying to model the probability of developing tooth decay for patients, which features do you think are relevant, and where can I find related datasets? Aside from the brushing frequency, brushing time, brushing quality, diet…"
162,Where do the data nerds hang out?,178,https://www.reddit.com/r/datascience/comments/17deo3d/where_do_the_data_nerds_hang_out/,93,"Drop the top subReddits and discord communities where the top data scientists and data analysts hang out. What content do they consume, what are the talking about, how do I sign up?"
163,Hey guys how is mongodb for analytics,0,https://www.reddit.com/r/datascience/comments/17ebi8s/hey_guys_how_is_mongodb_for_analytics/,1,"Like I am working in a startup and from what I have heard , mongodb should be used only when we want pictures or videos to store , so as long as the data is in text SQL works fine too . 
So the question is how different No SQL is from SQL . Like can anyone give me an idea how to get started and they use mongodb for analytical task ?"
164,Is pytorch not good for production,80,https://www.reddit.com/r/datascience/comments/17d3aze/is_pytorch_not_good_for_production/,62,"I have to write a ML algorithm from scratch and confused whether to use tensorflow or pytorch. I really like pytorch as it's more pythonic but I found articles and other things which suggests tensorflow is more suited for production environment than pytorch. So, I am confused what to use and why pytorch is not suitable for production environment and why tensorflow is suitable for production environment."
165,Is handling errors with Random Forest more superior compared to mean or zero imputation?,20,https://www.reddit.com/r/datascience/comments/17d6ufx/is_handling_errors_with_random_forest_more/,7,"Hi, I came upon [this post in Linkedin](https://www.linkedin.com/feed/update/urn:li:activity:7121482516829507584?utm_source=share&utm_medium=member_android), in which a guy talks about how handling errors with imputing means or zero have many flaws (changes distributions, alters summary statistics, inflates/deflates specific values), and instead suggests to use this library called ""MissForest"" imputer to handle errors using a random forest algorithm.

**My question is, are there any reasons to be skeptical about this post?** I believe there should be, since I have not really heard of other well established reference books talking about using Random Forest to handle errors over imputation using mean or zero.

My own speculation is that, unless your data has missing values that are in the hundreds or take up a significant portion of your entire dataset, using the mean/zero imputation is computationally cheaper while delivering similar results as the Random Forest algorithm.

I am more curious about whether this proposed solution has flaws in its methodology itself."
166,Why should I learn Java if Python have libraries offset it shortfall?,86,https://www.reddit.com/r/datascience/comments/17cv8nq/why_should_i_learn_java_if_python_have_libraries/,77,"I am studying Python and R to work in Data, and my mentor said that I should learn Java. I think it is regards to Machine Learning, but Python has an extensive libraries that helps offset it short fall. The problem that I can never finish a crash course book on Python is it's speed, but I read that NumPy and Pandas help make it faster. So my question is, what benefits are there to learn Java for Data Science if I see majority of people learn Python and most certification for data professions used Python and/or R?"
167,How often do companies outsource for entry-level data roles?,13,https://www.reddit.com/r/datascience/comments/17czsvd/how_often_do_companies_outsource_for_entrylevel/,14,"I've been studying for Data Analyst roles for a while now, and I'm really looking forward to working with data. I was just wondering how often companies outsource for entry-level data analyst roles? Because this role is usually remote or hybrid, I think that a lot of companies probably are, but they're hard to find or most likely prefer locals than to outsource.   
Before I started, I did my own research and met with 8 accomplished Data Analysts/ Scientists/ Engineers Mentors from US/Canada/Germany/UK in The Mentoring Club and confirmed how I would start and learn to transition to this role.  


I talked to them and confirmed that the best skills to acquire would be   
Excel, SQL, Python or R (or Both), Power BI or Tableau (or Both)  


I started with very basic SQL in Khan Academy and SQLZoo and I enjoyed it a lot and confirmed my love to transition to working with Data. 

After that, I took the IBM Data Analyst Professional Certificate (almost everyone I talked to was against taking the Google Data Analytics Certificate) which covered SQL, Python, IBM Cognos, and EDA.

Then I took DataCamp's Data Analyst in SQL to further hone my skills in SQL, I feel more confident with my SQL skills after taking this course.

Now, I'm currently taking DataCamp's Data Analyst in Power BI course and am about 70% done with it.

On every single course, I really love what I'm learning and enjoying it so far. I really love working with data. Whenever I solve a ""problem"" from my courses, I feel very satisfied like an itch in the brain is gone. Every time I make an amazing visual in Power BI, I actually smile and feel proud. Every time I learn something new I actually love it. When I first used ""Key Influencers"" in Power BI, I was so amazed and really wanted to work more with this feature.

&#x200B;

My current problem is, that I don't really want to work as a Data Analyst for a company in my country, but rather as a full-time remote for a company in the US, Canada, or Europe even without benefits, even at minimum wage, as long as they give me 40 hours per week, growth in skills, and opportunity to train/learn.

So I'm just wondering how viable would that be in your experience with your companies, do you work remotely with people from other countries in entry-level roles?"
168,I have never had a manager in my entire career that provided any value to me,258,https://www.reddit.com/r/datascience/comments/17cfb97/i_have_never_had_a_manager_in_my_entire_career/,131,"In my entire career, I have never had a single manager that provided any value to me personally. Here's a recap of all of the managers I've had in my career. 


1. Terrific manager. Hired me, made me feel welcome, immediately left the company two weeks after I started



2. Replaced first manager, and immediately put me on performance improvement plan to try and get rid of me. Would find formatting errors, any sort of mistake or human error at all to tell me that I was a sloppy employee. Completely ignored any benefit I provided, and had no interest in working with me. Just wanted to build their own team, and I was in their way because I was already there


3. Hired me, and instead letting me get oriented into my role, decided to do what she called ""trial by fire"", just throw me into the deep and and see if I sink or swim. I excelled in my position, did everything better than expected, received praise often, but passed up for a promotion because only one person can be promoted. 


4. Completely incompetent, never actually did any of the subject that they were managing a team for. Ended up being fired for sexual harassment against many women on our team 



5. Came from another team to replace previous manager, gave me mountains of work and impossible goals and expectations to achieve, and even when achieving them, made up a bunch of excuses as to why I can't be promoted that made no sense. Glass ceiling, basically, can't be promoted unless you tell me that you want to be promoted, and X amount of years have passed, need X amount of outstanding performance reviews, etc


6. Actually a really good manager and all around good person. For the first year, great to work under them, they let me get situated in the role, let me get exposure to many different teams and departments, let me explore and provided coaching. However, after the first year, became very lazy as a manager. Never at their desk, always driving somewhere, scheduling meetings and then being 15 plus minutes late to them because again, they are driving somewhere, or not doing their job. Became extremely lazy and let errors slip through their fingers, and blame team members for them. Began making excuses when people wanted to be promoted 


7. The director above the previous manager in bullet point above. Completely worthless leader who came aboard to replace another director, and their first mission was to interrogate everyone on the team, and determine if their career goals were to stay in their current position. Anyone who desired career growth, or wanted to move up into management, or had career aspirations was immediately let go because they're ""Not a fit for our organizational goals"" 



The most common thing I have seen is that it is impossible to get promoted. Most positions at analyst level are designed so that no one can proceed into other positions because they want you to stay exactly where you are currently and not move up, they try to make it as difficult as possible for you to move up into other roles in the company. If you don't want to sit exactly where you are for at least 5 to 10 years, you're a bad employee, and there is no way to be promoted."
169,Need some practical advice on choosing from different CNN model architectures.,4,https://www.reddit.com/r/datascience/comments/17cy5av/need_some_practical_advice_on_choosing_from/,1,"Hi everyone. I would just like to discuss a few things. I've spent about 2 months studying CNNs on coursera from the Deep Learning Specialization. In this time period I learnt the fundamentals and mechanisms of how CNNs work. I also took lectures on a few research papers that studied a few classical CNN models like AlexNet, LeNet-5, VGG-16. And then a few research papers that studied advanced stuff like ResNets, Inception Network, MobileNet, EfficientNet etc. Following that I studied Detection Algorithms, with a primary focus on YOLO Algorithm. I also briefly studied Regional Proposals, Semantic Segmentation, R-CNN, Fast-RCNN, Faster R-CNN, U-Net. I also learnt Face Recognition and Verification Models like Siamese Network using Triplet Loss function and Binary Classification. And also covered a little Neural Style Transfer. 

 I am now looking forward to build some projects. Most probably on object detection and image classification. After consuming all of the stuff that I mentioned above, I am confident enough that I can build an application in the real world, though I still have a few questions and need to talk to someone who can channel my thoughts in the right direction.  

If you could give me just a rough overview of how you approach a computer vision problem that'll be great. Especially, when you see a computer vision problem to solve, how do you make decision on which architecture to choose from to solve a given problem at hand. Since there are many architectures and research papers and every architecture works in a unique way to solve unique problems, how do you know which one to choose from? How do you make your way down from 100s of options to choose from, to a few where you can then start experimenting with those few options? Just need some practical advice on approaching an object detection or image classification problem.

Also, there might be some knowledge gaps that I have, I feel like I have em, but I don't know what I don't know at this point. So, I just need someone who can maybe channel me in the right direction."
170,What's one file or other digital resource which if deleted would most affect the world?,37,https://www.reddit.com/r/datascience/comments/17ccv2x/whats_one_file_or_other_digital_resource_which_if/,16,
171,Dataset splitting by time & why you should do it,26,https://www.reddit.com/r/datascience/comments/17cce10/dataset_splitting_by_time_why_you_should_do_it/,49,"I know this is likely to be controversial but I wanted to open up the discussion.

I think most problems and datasets should be split by time rather than uniform iid sampling for train-valid-test.

I almost always get pushback when I suggest this because it makes cross-validation more difficult to implement and can reduce the training dataset size in some folds.

Most people will say it's not necessary to split by time (e.g. test set in the future relative to train) because there is no time-wise dependency. However, the problem is that almost every data distribution involving human interactions will tend to shift over time and contain some dependency.

Let me give you one example: Let's say we have a web app that lets users submit a picture of an animal and we predict whether it's a dog or not. This seems like a simple problem where you could split by iid because there can't be any data leakage, right?

But if you think about it, the distribution of photos that get submitted is likely to change over time. It could be from new dog breeds becoming more popular, or from a shift in the types of users that use the platform and the dogs they submit. It could even be due to new phones/cameras being used, or people start posing their photos slightly differently or maybe covid hits and now your service is only getting indoor photos with different lighting whereas previously you got mostly outdoor shots.

These are all hypothetical examples and you could come up with a million different ones. The point being that the distribution of data for many many (most?) problems will change over time and our goal is almost always to train on historical data and predict on future unseen data.

So with that context, I think it often makes sense to at least test a time-split approach and observe whether there's a difference with simple iid CV approach. I think you could possibly be surprised by the result."
172,"Soooo, my manager thinks it’s a good idea to assign a mentor on me,",0,https://www.reddit.com/r/datascience/comments/17d2v13/soooo_my_manager_thinks_its_a_good_idea_to_assign/,16,"I am a sales operations analyst -by name- and I do what a typical junior data scientist does, I am an analyst from a team of four, I am the only one with exposure to proper statistical analyses and machine learning.

One colleague of mine -my mentor- has been at the company for a year before me, and he knows some python and is good at SQL. He is no where near my level at those two, but he’s a god-level suck-up! 
He can stay at the office after hours for no compensation just cause our manager said he needed to see something that would normally take a whole day to achieve, asked at 5:00 pm and needed to be ready in the morning.

The problem is raised because of a project I was leading, I automated the process of making routes for sales agents, I made it assign a 1 to retailers if we visit today will more likely make an order. I made it for the region I am operating in only -more on that later- and I also used clustering to get them the best routes possible in terms of likelihood to order and geographic coordinates. It made the success rate go from 40% to a big fat 60%. My manager appreciated that as much and thought its a great idea to make it for all regions, I designed an ab test and will run it for 2 weeks, as we have biweekly seasonality.

I prepared analyses for the test results and it was time for a meeting with other managers to discuss what it achieved. This was the forst time this team was doing an ab test, since I am the only one who actually understand it, I owned it.

When I shows the numbers, one region showed insignificant results, and I found that its seasonality is not biweekly, rather monthly and the mode of operations there is different, and it was -my mentor’s- region.

My manager said: why are you complicating things? Man, show me some pivot tables of agents who worked without your model and the ones who worked with and who is better, I disagreed as their performances might include other factors that are not controlled by mt model, pricing and geography and the agent himself.

My mentor already has the pivots ready, presented the numbers and he was happy.

After, my manager rambelled on for half an hour about my attitude and pointed out every thing that I fis wrong since I started working in the company, and assigned him as anentor to me, stating how much of an inpact on my coding skills and analytical skills he will add.

We started working in projexts together and had to take his way of doing things, and I don’t like how he lets me do all the work and take credit for it.

I started looking for new jobs and no luck the market is really tough especially that I know little tools, power bi and its dax, excel and python and sql.

What should i learn to get jobs as a junior data scientist? While searching, what should I do about my situation?"
173,Thoughts on DS roles,26,https://www.reddit.com/r/datascience/comments/17c78g5/thoughts_on_ds_roles/,15,"I’ve been working as a DS for a couple of years now and would like to share my thoughts on the role(s).


- Big corp: Benefits and salary good but can get stuck in deploying large products where your hard earned skills aren’t used. Best place to be during new projects where you accumulate alot of skills from SWE, IT and more.


- Consulting: Not Big4 but what I’ve experienced is basically BI and DE. The managers have no idea what DS is and just regurgitates names of cloud services. Compensation model is outdated and not realistic for DS. 


What are your experiences?"
174,Inviting initial users for dynamic data documentation tool,3,https://www.reddit.com/r/datascience/comments/17clbmx/inviting_initial_users_for_dynamic_data/,5,"I'm building a product that integrates with your codebases and takes your database metadata to create dynamic documentation of your data. Every time someone makes a new code change that affects the data, you're updated with how the code change altered tables, labels, cols, etc.

Let me know if you'd like to try it out. I'll send you a link and would love to get your feedback.

I'll provide a repo and public postgres database that you can connect to demo (if you don't have one that you want to connect)."
175,Help needed with a quadratic optimization problem,2,https://www.reddit.com/r/datascience/comments/17cnntn/help_needed_with_a_quadratic_optimization_problem/,2,"Hi, I am trying to solve finance-related quadratic optimization problem using CVXPY python library. I have a maximize objective function with a Beta variable which is subject to certain constraints. I am getting the output for Beta values from 1-10. But at certain beta values (e.g., 0, 1), the output is optimally inaccurate and the objective is not even satisfying constraints. Why would the program give solutions which does not satisfy constraints? More generally, can someone recommend some literature to solve such problems?"
176,Help with analysis of incomplete experimental design,1,https://www.reddit.com/r/datascience/comments/17cie3b/help_with_analysis_of_incomplete_experimental/,4,"I am trying to determine the amount of confounding and predictive power of the current experimental design is?  
I just started working on a project helping out with a test campaign of a fairly complicated system at my company. There are many variables that can be independently tuned, and there is a test series planned to 'qualify' the engine against its specification requirements.   


One of the objectives of the test series is to quantify the 'coefficient of influence' of a number of factors. Because of the number of factors involved, a full factorial DOE is out of the question, and because there are many objectives in the test series, its difficult to even design a nice, neat experimental design that follows canonical fractional factorial designs.   


We do have a test matrix built, and i was wondering if there is a way to just analyze what the predictive power of the current test matrix is in the first place. We know and accept that there will be some degree of confounding two-variable and three-variable + interaction effects in the main effects, which is alright for us. Is there a way to analyze what the amount of confounding and predictive power of the current experimental design is?  


Knowing the current capability and limitations of our experimental designs would be very helpful it turns out i need to propose alteration of our test matrix (which can be costly)  


I don't have any real statistics background, and i don't think our company would pay for a software like minitab and i don't know how to use such a software either.   


Any guidance on this problem would be most appreciated.   
"
177,Can you fit a code in a gamble?,0,https://www.reddit.com/r/datascience/comments/17cgmof/can_you_fit_a_code_in_a_gamble/,20,"How would you encode information into improbable events? For example, if you could influence the outcome of a roulette wheel or lottery draw, over as long a period as necessary, what would be the most efficient way of encoding data into the outcomes?

Perhaps a better example would be drawing from a deck of a million unique cards, and only yelling yahtzee when a specific one is drawn. Say you can add a few extra of the card to the deck whenever you want and boost the probability slightly. That would theoretically increase the frequency of the yahtzees from the right timescale perspective.

So if our hero does a million shuffled drawings a day, he might get 0-3 yahtzees. With careful timing, you can slip an extra card into the deck whenever you want, doubling his probability for the next drawing.

How would you encode as much data as possible in the frequency of this man yelling yahtzee?"
178,Any data imputation technique shares?,8,https://www.reddit.com/r/datascience/comments/17c0z6e/any_data_imputation_technique_shares/,15,"Hello, 

I’ve been reading up some articles from kaggle and blogs about data imputation. I’m wondering if there’s a complete guide that introduces all the methods to data imputation. I’m interested to see all the pros and cons and the usage of different situations. 

Thanks for sharing!"
179,Do you use CRUD or like apps to bridge the gap between business users and DS/DA teams?,6,https://www.reddit.com/r/datascience/comments/17c2u6b/do_you_use_crud_or_like_apps_to_bridge_the_gap/,19,"In my about 5 years of experience working for a medium sized organization, I have seen a lot of value in building and maintaining CRUD or CRUD like apps that allows business users input, interact, and distribute data and models. Yet, I don't see much talk about this skill/use case of analytics. So curious to hear other's thoughts and experiences. Do you concur? Why or why not?

PS: I understand it's probably not the case for big techs or companies with a very mature data science culture. But I would guess 90%+ orgs don't fall in this category. Pls feel free to bunk this too!"
180,[rant] Required - A designated tread for transitioning to DS and repeating questions,43,https://www.reddit.com/r/datascience/comments/17bmc70/rant_required_a_designated_tread_for/,27,"Mods, where are you? There are countless posts every week with questions that were answered already.  

Should I learn Python? 
Masters degree worth it?
Job market sucks, what projects should I do?

All of these are valid questions, and my heart goes out to those who are struggling to land their first job. BUT, a quick lookup will yield answers for most of the questions online. It also frustrating to find the same question to which you have answered a day ago.  Let alone the fact that many of these posts are low effort ones and their questions aren’t even phrased correctly.

All of this spam drives seniors away, and instead of making a discussion about ds content, hopefully more advanced stuff, we keep answering questions about which is better, a project of a master."
181,Predictive vs Explanatory modeling,12,https://www.reddit.com/r/datascience/comments/17bqhb0/predictive_vs_explanatory_modeling/,26,"In my past work I've become familiar with various techniques for *predictive* modeling--NNs, of course, but also more ""classical"" methods like random forests or LASSO regression (along with their implementations in Python, which was probably one of the best decisions I ever made was picking up Python--I've loved using sklearn and nltk, and I haven't even gotten to using pytorch yet).

All that said, I haven't worked as much so far with *explanatory* modeling and I'm looking to get more into it. I understand the conceptual differences: in predictive tasks, we care more about signal than significance--we might, for example, include variables that are predictive but not statistically significant, or exclude variables that are significant but not predictive. What's more, in the explanatory environment, there's a much greater emphasis on *model interpretability*--that is to say, models like NNs or even random forests that can get kind of ""black boxy"" are disfavored compared to simpler models with much more straightforward interpretability.

So what's the state-of-the-art, go-to model(s) for explanatory tasks? Stepwise regression??"
182,Use cases of Advanced Math in Data Science and Machine Learning,28,https://www.reddit.com/r/datascience/comments/17bg00y/use_cases_of_advanced_math_in_data_science_and/,21,"I come from a Math background, and im fascinated by Math topics like Functional Analysis, Differential Geometry, Topology, Manifold Learning etc, Im actually looking for ways where i can apply these Math topics in my day to day Data Science/ML work. Is there any DS or ML roles which can allow me to delve deep into these Math topics? This has been my dream job. Where can i find roles that will allow me to such expertise, my main issue being that im unable to find such roles."
183,Sharing large files for collaboration,2,https://www.reddit.com/r/datascience/comments/17bxccu/sharing_large_files_for_collaboration/,3,"Anyone got some cool ideas for sharing large files? We use DataBricks but every now and then we need to share a big csv or pkl. I worked at a Computer Vision company previously and we had an onprem NAS - this won't suit my current job. I'm thinking S3, but wondering if anyone has a better idea. Haven't used Git LFS either so curious about this one too. Cheers"
184,Where are all the entry level jobs? Which MS program should I go for? Some tips from a hiring manager at an F50,299,https://www.reddit.com/r/datascience/comments/17avmi5/where_are_all_the_entry_level_jobs_which_ms/,156,"The bulk of this subreddit is filled with people trying to break into data science, completing certifications and getting MS degrees from diploma mills but with no real guidance. Oftentimes the advice I see here is from people without DS jobs trying to help other people without DS jobs on projects etc. It's more or less blind leading the blind.

Here's an insider perspective from me. I'm a hiring manager at an F50 financial services company you've probably heard of, I've been working for \~4 years and I'll share how entry-level roles actually get hired into.

There's a few different pathways. I've listed them in order of where the bulk of our candidate pool and current hires comes from

1. We pick MS students from very specific programs that we trust. These programs have been around for a while, we have a relationship with the school and have a good idea of the curriculum. Georgia Tech, Columbia, UVa, UC Berkeley, UW Seattle, NCSU are some universities we hire from. We don't come back every year to hire, just the years that we need positions filled. Sometimes you'll look around at teams here and 40% of them went to the same program. They're stellar hires. The programs that we hire from are incredibly competitive to get into, are not diploma mills, and most importantly, their programs have been around longer than the DS hype. How does the hiring process work? We just reach out to the career counselor at the school, they put out an interest list for students who want to work for us, we flip through the resumes and pick the students we like to interview. It's very streamlined both for us as an employer and for the student. Although I didn't come from this path (I was a referred by a friend during the hiring boom and just have a PhD), I'm actively involved in the hiring efforts.
2. We host hackathons every year for students to participate in. The winners of these hackathons typically get brought back to interview for internship positions, and if they perform well we pick them up as full time hires.
3. Generic career fairs at universities. If you go a to a university, you've probably seen career fairs with companies that come to recruit.
4. Referrals from our current employees. Typically they refer a candidate to us, we interview them, and if we like them, we'll punt them over to the recruiter to get the process started for hiring them. Typically the hiring manager has seen the resume before the recruiter has because the resume came straight to their inbox from one of their colleagues
5. Internal mobility of someone who shows promise but just needs an opportunity. We've already worked with them in some capacity, know them to be bright, and are willing to give them a shot even if they don't have the skills.
6. Far and away the worst and hardest way to get a job, our recruiter sends us their resume after screening candidates who applied online through the job portal. Our recruiters know more or less what to look for (I'm thankful ours are not trash)

This is true not just for our company but a lot of large companies broadly. I know Home Depot, Microsoft and few other large retail companies some of my network works at hire candidates this way.

Is it fair to the general population? No. But as employees at a company we have limited resources to put into finding quality candidates and we typically use pathways that we know work, and work well in generating high quality hires.

EDIT: Some actionable advice for those who are feeling disheartened. I'll add just a couple of points here:

1. If you already have your MS in this field or a related one and are looking for a job, reach out to your network. Go to the career fairs at your university and see if you can get some data-adjacent job in finance, marketing, operations or sales where you might be working with data scientists. Then you can try to transition internally into the roles that might be interesting to you.
2. There are also non-profit data organizations like Data Kind and others. They have working data scientists already volunteering time there, you can get involved, get some real world experience with non-profit data sets and leverage that to set yourself apart. It's a fantastic way to get some experience AND build your professional network.
3. Work on an open-source library and making it better. You'll learn some best practices. If you make it through the online hiring screen, this will really set you apart from other candidates
4. If you are pre MS and just figuring out where you want to go, research the program's career outcomes before picking a school. No school can guarantee you a job, but many have strong alumni and industry networks that make finding a job way easier. Do not go just because it looks like it's easy to get into. If it's easy to get into, it means that they're a new program who came in with the hype train

EDIT 2: I think some people are getting the wrong idea about ""prestige"" where the companies I'm aware of only hire from Ivies or public universities that are as strong as Ivies. That's not always the case - some schools have deliberately cultivated relationships with employers to generate a talent pipeline for their students. They're not always a top 10 school, but programs with very strong industry connections.

For example, Penn State is an example of a school with very strong industry ties to companies in NJ, PA and NY for engineering students. These students can go to job fairs or sign up for company interest lists for their degree program at their schools, talk directly to working alumni and recruiters and get their resume in front of a hiring manager that way. It's about the relationship that the university has cultivated to the local industries that hire and their ability to generate candidates that can feed that talent pipeline."
185,Wrong data in dataset,3,https://www.reddit.com/r/datascience/comments/17bobx9/wrong_data_in_dataset/,2,"I have a very broad question about building a model using xgboost and feature selection. 

As an example, let’s say I have tabular dataset and build a binary classification model using xgboost to predict a purchase. I run the model with a 10 fold cv and get an auc score of x. I then remove some columns and rerun the model, everything else the same, and get an auc score > x. 

In this case, would the columns that were removed be random / wrong and is this common? I believe I can use a t-test to compare the scores and see if it’s due to random chance. 

My assumption was that xgboost would automatically find the best split in the data but wanted to know other peoples thoughts."
186,"Those that have moved from a technical position to a leadership/supervisory position, do you regret it?",46,https://www.reddit.com/r/datascience/comments/17b32vd/those_that_have_moved_from_a_technical_position/,40,"Do you still perform technical duties or is it nonstop meetings and people management? If it's the latter, do you miss the hands-on technical aspects or is it better on the leadership side?"
187,LLM domination on job descriptions,175,https://www.reddit.com/r/datascience/comments/17ar38i/llm_domination_on_job_descriptions/,69,"Can anyone explain why many companies asking for LLM experience for data scientist roles?  
It wasn't there like 6-8 months ago, now around %70 of the job descriptions asking for that and it goes like Python, SQL and LLM. Looks a bit weird to be honest.  
What are they doing, creating their own chatgpt?  
"
188,"What's better as a data scientist ""precursor role"": a software developer or a business analyst?",41,https://www.reddit.com/r/datascience/comments/17ay21z/whats_better_as_a_data_scientist_precursor_role_a/,42,"I've been offered the opportunity to transfer to my firm's IT department after I expressed interested in and demonstrated proficiency in data science (coming from a quantitative but not pure DS department). The IT department doesn't have a specific data science ""role"" though -- only software developer and business analyst. Given I want to eventually settle into a pure data scientist role -- and pursue a Masters in such (I'm 24) -- which of these two roles would you choose if you were taking a career-level view? 

In the software dev role, I'd get hands-on experience with writing code everyday, but it would be chiefly in a software development environment -- not data science. With the BA role, I would have hands-on experience with product management and dashboarding and Confluence, but not so much writing code. I'm torn. I just ultimately want to be in a role where I can dive into datasets everyday and always have a numpy-pandas-matplotlib-sklearn environment open on my computer.

Any advice would be greatly appreciated! Thanks so much."
189,Different loss function than evaluation metric,3,https://www.reddit.com/r/datascience/comments/17becn2/different_loss_function_than_evaluation_metric/,2,"Hi all,

I am currently writing my master thesis about gaze estimation and i am using a combination of a cnn for finding feature map and transformer for the regression task. The gaze angular error is a common metric in this field, because it calculates the angle and ignores the depth of two gaze predictions. But in most of the papers about this topic the L1 or L2 loss is used and gaze angular error is only the evaluation metric.

Do you know why gaze angular error is not used as loss as well?

&#x200B;

\[Edit\]

I tried now angular error as loss and it is really terrible. 

Like L1 loss results in a gaze angle error of around 2°, while my custom loss is resulting in errors around 50°. I though about using multi-loss approach, for example l1 + angular error to consider the depth length. What do you guys think of that?"
190,Will Understanding Advanced Data Structures Make Me a Better Data Scientist?,25,https://www.reddit.com/r/datascience/comments/17az6v2/will_understanding_advanced_data_structures_make/,14,"I'm a data scientist with 5 yoe now, and I've never needed to implement a tree, a linked list, a graph, a stack, or a queue. If I need a decision tree, I use a package like sklearn. If I'm doing graph analysis, typically I treat it like a matrix. I don't even have any idea what models might need a queue, but maybe that's really important for data processing or training somewhere?

&#x200B;

Have any of you really needed to implement these data structures, or do you just use packages that are using them under the hood? Would I actually be meaningfully better at my day to day job if I knew when and how to use a linked list or a stack?"
191,Programming language for machine learning and data analysis – Our choice,0,https://www.reddit.com/r/datascience/comments/17bf3cx/programming_language_for_machine_learning_and/,18,"&#x200B;

## Python

Undoubtedly, **the uncrowned king** of machine learning and data analysis, the ubiquitous language that data scientists turn to for a bit of number crunching, **is Python**. This is down to several reasons; the three most important among them are its **maturity**, the enormous **community**, and, last but not least, a **vast array of robust third-party libraries**. But even if Python is a magnanimous sovereign that many developers love, it doesn’t mean that there can’t be contenders occasionally.

## Julia

Fourteen years ago, in a bold attempt to combine all the good properties of well-established programming languages while getting rid of the less favorable ones, four developers came up with the idea of a new programming language that has a **friendly syntax**, offers **efficient mathematical computations** out of the box, at a **performance on par with compiled languages**. And thus, [**Julia**](https://julialang.org/) was born (here’s a manifesto explaining [**why**](https://julialang.org/blog/2012/02/why-we-created-julia/) in more detail). Its first version was launched a bit more than eleven years ago.

## Our choice

Many in-depth comparisons of Python and Julia on the web (such as [**this one**](https://richardpelgrim.medium.com/julia-vs-python-for-data-science-in-2022-1f5f6f38f3ac) or [**this**](https://www.turing.com/kb/julia-vs-python)) cover both the objective and subjective benefits and drawbacks of choosing one over the other. And given Julia’s growing popularity, we are sure more will follow. In the rest of this blog post, however, let’s explore why we picked Julia for our purposes. And that’s not to say that we don’t use Python for data science. On the contrary, we **often run analyses in both ecosystems simultaneously** to help each other out where one is lacking or to reduce the chances of mistakes by comparing their results.

## The advantages of Julia

So what makes Julia so compelling to us?

## Language features

Julia has:

* a friendly, easy-to-read (and write) syntax;
*  a flexible and expressive (part static, part dynamic) type system;
*  powerful mathematical notations, such as built-in vector and matrix operations;
*  efficient [**multiple dispatches**](https://en.wikipedia.org/wiki/Multiple_dispatch), a form of function polymorphism working with runtime types;
*  convenient and reliable parallel computing facilities;
*  meta-programming with macros and generated functions.

## Fast code execution

Julia compiles the source code to **native binary at runtime** via LLVM. This approach combines the flexibility of interpreters, such as Python, with the performance of compiled languages, like C++ or Rust. The drawback is that code loading and the first run takes longer; **the benefits start to shine when a piece of code is run multiple times**. This unique feature makes it an excellent tool for number crunching but less than ideal for scripting.

## Built-in package management

Julia has a pretty good (albeit not perfect) built-in package management tool, implemented as a base library; and a general registry of open-source packages. The offering of **stable and well-designed packages** is growing steadily along with the Julia community, especially in data science. Unit testing utilities are also part of the standard library.

## Interactive tools

Julia offers an **advanced** [**REPL**](https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop) with all the goodies of an interpreted language environment. These include:

* code and variable inspection,
*  code completion,
*  an interactive debugger,
*  benchmarking and profiling tools,
*  and a built-in help system.

**With third-party libraries, it can also be extended** with [**syntax highlighting**](https://github.com/KristofferC/OhMyREPL.jl), [**source code lookup**](https://github.com/tkf/InteractiveCodeSearch.jl) (even for base libraries), automatic [**code reload**](https://timholy.github.io/Revise.jl/stable/), and many more exciting, modern features.

All these together make Julia an **ideal environment for rapid prototyping**.

## From prototyping to production code

Because of the high-level interactive tools and fast code execution, **the transition from a rapid prototype to production-ready code can be as continuous as you’d like**. More often than not, we find that most of the code that implements our business logic in the research code can also be used in the final product.

Thanks to its friendly syntax and built-in package management, **the road to maintainable code is well paved**. Nothing replaces good API design, coding discipline, and rigorous testing, but Julia helps you to focus on these topics.

As a consequence, a computation pieced together in the REPL can easily become a piece of prototyping code in a POC module; then later, after some refactoring and unit testing, turn into a chunk of core code in an internal library, and finally, following more cleanup, find itself in a production package.

## The disadvantages of Julia

That said, every benefit comes at a cost, and Julia is not free from issues. Here are a few stumbling blocks worthy of mentioning:

* the very powerful tool of broadcasting and vectorization can be intimidating at first;
* [**time to first plot**](https://discourse.julialang.org/t/time-to-first-plot-clarification/58534) can be surprising, sometimes inconveniently long, although considerable effort has been put into making it shorter;
*  many packages never reach a stable state or just become unmaintained; others are poorly designed or written;
* [**releasing a binary package**](https://github.com/JuliaLang/PackageCompiler.jl) can be challenging, and compilation time can be unexpectedly long, not to mention obfuscation, which can also be tricky.

## Summary

In conclusion, the choice between programming languages for data analysis is not always clear-cut. While Python has been the go-to language for many data scientists, Julia is rapidly gaining popularity for its unique set of features that make it an attractive option. In this blog post, we explored why we chose Julia over Python for our purposes, highlighting its language features, fast code execution, built-in package management, interactive tools, and ease of transitioning from prototyping to production code. However, we also acknowledged that Julia has challenges, including overcoming some learning curves and the occasional instability of packages. Ultimately, the choice between Julia and Python (or any other programming language) will depend on specific project requirements, personal preferences, and available resources.

Still, in the past years, **Julia has proved to be our reliable and faithful companion**. It has evolved, matured, and improved significantly, and we would be less happy and less successful without it. So cheers, Julia; we are excited to see what your future brings!"
192,Market Timing & Risk Management - Portfolio allocation,1,https://www.reddit.com/r/datascience/comments/17bdzis/market_timing_risk_management_portfolio_allocation/,0,"Hi everyone!  
Is it possible to create a market timing strategy using unsupervised learning? 

Let's find out.

Relevant Topics:

* Used S&P500 data
* Segmenting Time series using Online Change Detection Point
* Clustering segments with KMeans
* Risk Allocation
* Value at Risk

Here's the notebook:  
[https://www.kaggle.com/code/mandmdatascience/mt-rm-portfolio-allocation/notebook](https://www.kaggle.com/code/mandmdatascience/mt-rm-portfolio-allocation/notebook)

Every and each comment / feedback is greatly appreciated!

Thank you!  
M&M"
193,Shit scared of Leetcode!,52,https://www.reddit.com/r/datascience/comments/17ajqwd/shit_scared_of_leetcode/,54,"I am currently a CS grad major and I really love this field! I have a major interest, work experience and projects in Data Science(majorly Deep Learning and Machine Learning). I am currently looking for summer internships in Data Science, ML, AI etc. I am being told that you'll probably be asked leetcode questions in your technical interviews and I am shit scared of it. I can't do anything beyond Leetcode easy, my mind just doesn't accept unseen medium questions. If I remember a solution to one of the medium problem, I might be able to solve it but that also fades away if I don't practice that problem in every few days. 

Someone please shed light on whether my targeted jobs require Leetcode or not, and if they do then what level of questions?"
194,Advice on imbalanced datasets with many missing values,2,https://www.reddit.com/r/datascience/comments/17b3lup/advice_on_imbalanced_datasets_with_many_missing/,5,"Hi! I am currently working on a binary classification model for a highly imbalanced dataset with lots of missing values in there. I tried using multiple techniques for resampling (Random, SMOTE, and SMOTETomak) and imputation (MICE), as well as a bit of tweaking of class weights and loss function, but still I am not able to get higher than this.

CatBoost Accuracy:  0.843492894540015
              precision    recall  f1-score   support

         0.0       0.95      0.87      0.91      4775
         1.0       0.36      0.62      0.46       573

    accuracy                           0.84      5348
   macro avg       0.66      0.74      0.68      5348
weighted avg       0.89      0.84      0.86      5348

Any ideas on what can I also try considering such results and above mentioned trials? Any feature engineering techniques that I might not know? 

Also one of the interesting things about dataset is relatively large amount of categorical features - 30 out of 140 (two of them have 2k different options, others are in the range from 3 to 30). I used multiple different methods for encoding here depending on the amount of categories - One Hot, Binary and Target.

One of the main issues of the dataset is lack of context so I'm mostly trying to improve both precision and recall (and f1 as a result) at least to somewhat degree.

Thanks in advance for any possible ideas?"
195,I'm giving up finding a job. I feel like I'll have better luck applying to PhD programs. This is a rant.,147,https://www.reddit.com/r/datascience/comments/17aba8a/im_giving_up_finding_a_job_i_feel_like_ill_have/,152,"Just recently graduated in May with a BS statistics from texas a&m with a specialization in GIS. I have a good knowledge of statistics, not a slacker in the academic sense. 3.5 gpa. One semester of research, no internship experience Edit: Passed two preliminary actuarial exams P and FM early on in university. Since then, I got a contracting gig at apple as GIS editor/mapper, maybe I can market it off as an analyst), I was training there for a month and got laid off, can def get a good ref letter though. I have a decent capstone project from university, shiny app utilizing exploratory methods for points patterns. I'm almost done with the meta coursera front-end prof certificate and I'm gonna do the back-end version, because I want to know how to deploy a shiny app with all the bells and whistles using the rhino framework, connected to a database, testing, user feedback, hosted on the cloud. Maybe then if can have a little web app on my resume that also makes peoples lives a little easier. I've thought about it, looks like I have a lot to learn, ux/ui design, marketing the web-app somewhere, even if it doesn't get any traffic, maybe it'll look good on a resume.

I'm disenchanted with it all, I'm hearing a person with a PhD in a quantitative field hardly ever needs PhD level knowledge in their work, unless they are in academia or industry doing research, do you even need a masters? I mean, doesn't a bachelors in statistics, especially coupled with a few graduate level stacked courses in statistics, basically qualify you, as ""pretty much as knowledgeable as a masters in statistics with no undergrad statistics related coursework, in terms of theoretical knowledge of probability, regression, inference"", I'm not asking any questions. It's just that a person with connections and a bachelors in english, can get a job in analytics, and I am having trouble. I call it how I see it, my knowledge of statistics is not nearly as important, as having something tangible, that says ""I'm of value"" and ""people can rely on me"", and knowing people. Especially when employers aren't going to ask my professors how I was like,  I imagine I'll have a better chance getting into a PhD program. Even if you get a PhD, you still need to fight for job, learn new skills, deal with layoffs, and probably, continue the wage-slave life like most people in America (which is a good life I admit for most people). No question here, I'm just saying how I feel at the moment, making no implicit claims. I can get good rec letters from my professors, I'm pretty sure, lol, ya think I can get it at places like texas tech, iowa state, or kansas state?  Open to conversation about anything. So plan is, get a PhD, because I can't get a job now, maybe yeet out with a masters, but honestly, I like teaching, I like learning, I don't mind taking tests, and I know how to live with a low overhead (I don't buy stuff I don't need). I know what really matters, your basic needs, family, a few good friends. Ok, that's not all that matters, there have been many people who have excelled in their fields, sacrificing their time with their family and friends, in order to do things that everybody would agree matters. Some I know regret it, others don't."
196,Binary classification question?,1,https://www.reddit.com/r/datascience/comments/17b2d08/binary_classification_question/,1,"So I’m trying to build a model to find some inappropriate payments. So I have the data of all payments made, however, some of them were audited while the vast majority aren’t. 

The ones that aren’t audited are just automatically approved while the ones that are audited are approved or rejected based on auditors judgment. So my plan is to just use all the payments that has been audited as the population and ignore the payments that have never been audited since they don’t really tell us much.  

So probably about 1% of payments are audited and if that about 7% are rejected. 

Now the issue is that most of the payments that were rejected were for minor issues. Maybe the person who’s entered the payment made a slight typo for the invoice number, so that was rejected and they had to resubmit it, or something minor. 

Those payments aren’t abiding by some minor rules and they need to be rejected and resubmitted after being corrected. They’re wrong but not really worth the time because we aren’t saving any money. Unfortunately, that’s about 70% of rejected payments. 

Now the other 30% is where the real savings is happening, potential fraud, the accountant mistyped the amount to be paid or whatever. And that’s what I’m really trying to find, if I find the others that’s cool but doesn’t really do much. 

How would I go about selecting my data for that. Would I just ignore the 60% of rejected payments that aren’t that big of a deal and proceed without. If so, would I also reduce the number the number of payments that were accepted as well by 60%. 

Or any alternative suggestions?"
197,Project ideas that combine Data Science (Data Analytics) and Digital Marketing,2,https://www.reddit.com/r/datascience/comments/17ax0xj/project_ideas_that_combine_data_science_data/,4,"Hello everyone! I am currently working in digital marketing (I’m entry level) and I have a degree in data analytics. I would like to be able to combine both fields, and I’m looking for any good project ideas to do so (preferably using R or Python). Any ideas are helpful!"
198,Microsoft Azure,5,https://www.reddit.com/r/datascience/comments/17aq5r0/microsoft_azure/,1,"I am Data analyst with 2 years of experience and in the companies that I have work, I have not had any experience with data processing in cloud services. I am interested in learn Azure, AWS or Google cloud for data science and get the certifications. Could you tell me what is better, and how important are those certificates in my career path?.
Thanks!!!"
199,Interview Take Home task seemed unreasonable,97,https://www.reddit.com/r/datascience/comments/17a79kw/interview_take_home_task_seemed_unreasonable/,58,"I am finishing my my masters degree in data analytics. Previously I've worked as a business analyst for three years. I just had an interview for a data analyst position and I was asked to complete a take home assignment with two parts: a written analysis, and an R project that included a business report with a summary and discussion for recommendations on improving the data reporting. I had 24 from after my interview to return the assignment. I got the exam at 2pm yesterday, so I had until 2pm today. 

I got home at 3pm and got the first written portion done yesterday. It involved some simple excel manipulations. Then I had to go to class at 5. Didn't get home till 10pm.

Fast forward this morning. I wake up at 8.i get started on the R project at 9am.

The data was some of the messiness I've seen, and cleaning and transforming the data took four hours. The analysis and visualizations took about one. I know there were some mistakes, and I got the written summary done. But I could not submit the discussion on recommendations. 

I'm not here to ask about my likelihood of getting the job. But this task seemed monumental for just 24 hours (i have other obligations like class and a family). Even my worst professors haven't asked me to do anything like that in such a short time. Is this to be expected going forward?"
200,Pricing Analysis Career Progression to Data Science,2,https://www.reddit.com/r/datascience/comments/17atfvp/pricing_analysis_career_progression_to_data/,2,"I was a DS in an insurance company (essentially a pricing analyst), I was doing a lot of XGB and GLM models etc. It was enjoyable but I have a degree in DS so I always wanted to move into something which would project me into more complex/cool modelling.

Anyway, my question, I moved to London and am now looking for a new job but the currently tough market is looking for much more experience than I currently have in data science related work (I have 1 year). Would taking a Pricing Analyst role (doing the same algorithms as before) hurt my progression or help it in the eventual goal of being in something machine learning related down the line.

I think it would strengthen my prediction models, but at the same time I wouldn't be exercising what I did in my MSc degree. What do you think?"
201,Forecasting sales,4,https://www.reddit.com/r/datascience/comments/17al968/forecasting_sales/,4,"So i’m working on a project that forecasts sales of products in a series. Curious to know the best approach to model “cascaded” products i.e old version of the series when the new one launches.
Using a Recursive multistep regression approach to forecast with some features

Appreciate the help, thanks 🙏🏼"
202,How can I show knowledge in topics I haven't worked on professionally?,4,https://www.reddit.com/r/datascience/comments/17alvvb/how_can_i_show_knowledge_in_topics_i_havent/,1,"I am in process of switching jobs, and preferably domains as well. I am currently in the banking domain (Consulting) and would like to move to a B2C/Product based company. 

The topics often mentioned in JDs are like price optimization, Cohort Analysis, Funnel Analysis, Forecasting etc.  I have no experience in such topics due to the nature of my work, but I have started doing small projects for the same.

My problem is how can I show this in my recruiters such that they don't just ignore my personal projects section. "
203,Where do you start if you are new to mathematical models,13,https://www.reddit.com/r/datascience/comments/17ad4og/where_do_you_start_if_you_are_new_to_mathematical/,10,I cant make heads and tails of theory papers that have  mathematical notations and equation. Where do you start? Is there an ebook/primer that can help? I dont have an economics background but I did study advanced math in high school. I am in accounting if it matters
204,Meme Mondays,1641,https://i.redd.it/zxdz4pm6ymub1.png,98,
205,Mainspring - Routine Planner,0,https://www.reddit.com/gallery/17ayhj7,0,"Hey everyone,
I'm an indie app developer, building in public on Threads.
Recently I launched Mainspring, a new routine planner app that helps you keep track of your every-day actions with a simple and intuitive UI.

Why is Mainspring different?
I built it with simplicity in mind, everyone have different goals with these kind of apps, some want to just track events, others want to keep themselves motivated, Mainspring will be a great fit for a broad number of people. Mainspring also provides motivational and beautiful statistics and graphs that can be viewed to empower progress.

Your full event history can be viewed and is beneficial if you want to remember when you last did something (e.g. when did I last got a haircut). 

Check it out and let me know what you think. 

iOS: https://apps.apple.com/app/mainspring-routine-planner/id6467129951

Android:
https://play.google.com/store/apps/details?id=com.naamapps.mainspring"
206,"DAGitty Question: Testable Implications only describes independencies, but not dependencies",2,https://www.reddit.com/r/datascience/comments/17alwcz/dagitty_question_testable_implications_only/,0,"Why does the DAGitty ""Testable Dependencies"" function only describe independencies, but not spurious correlations?

&#x200B;

E.g, if I have B->A<-C,

DAGitty just tells me that

B ⊥ C is the only testable (in)dependency

Why shouldn't we expect also

B⊥̸C|A

(i.e, B and C have a spurious correlation given A)?"
207,"Converting XGBoost decision models to ""if-then"" statements",17,https://www.reddit.com/r/datascience/comments/17a6ken/converting_xgboost_decision_models_to_ifthen/,17,"I am aware of a few tools that aid in converting XGBoost decision trees to ""if-then"" statements. I'm curious if anyone has experience with this approach, and how feasible/successful was the outcome?"
208,Question for Data Scientists in their day to day work,0,https://www.reddit.com/r/datascience/comments/17aveed/question_for_data_scientists_in_their_day_to_day/,16,"How often do you guys use calculus and linear algebra for your work? I've heard that for data science, especially machine learning, that it's important to understand linear algebra and calculus, but how true is this statement? I've taken some stats and probability courses in college for my minor, but haven't taken anything past calc 1 or linear algebra. Are these must-haves for your day to day work?"
209,Graduate US/International Career Opportunities,0,https://www.reddit.com/r/datascience/comments/17amx3l/graduate_usinternational_career_opportunities/,0," I'm about to graduate with a Master of Data Science from one of the top 5 universities in Australia. I am in my final few units with a 4.00 GPA - High Distinctions in every unit. Additionally, I have 2 years of experience as a Data Analyst in the supply chain domain.

I'm currently exploring career opportunities in the US and other international locations. I'm curious if there are well-known companies that frequently interview international candidates who are willing to relocate for the role. Any advice or recommendations would be greatly appreciated!

Thank you in advance!"
210,Moving to USA or Staying in UAE,60,https://www.reddit.com/r/datascience/comments/179uwm2/moving_to_usa_or_staying_in_uae/,82,"Hi Folks

I am currently working as  Senior ML Engineer on a startup in Dubai. I am 28 years old and getting 120k USD yearly. (no tax).

Actually, I am living a good life here, its close to my home country (Turkey), so I can see my family easily and we are almost in same timezone. But the quality of things we are doing here not that good, and I am not sure can I grow in my career here in long run. I don't want to move to Europe because as I can see salaries are very low . If I stay in Dubai getting a salary around 150k in 2 years in here is very doable for me now.

I started considering to move to USA. I found hybrid master programs (first year is remote second year is USA and I can OPT). So I don't have to sacrifice my 2 years to go USA. Probably I will stay without a job just one year.

Do you have any advice for me? Is moving to USA changing my lifestyle, and making sacrifices (time, masters, moving to USA, money etc) worth it?  


&#x200B;"
211,Anyone here that knows where to find scientific papers about regression models for Sports results?,3,https://www.reddit.com/r/datascience/comments/17ag1pr/anyone_here_that_knows_where_to_find_scientific/,1,
212,Fuel consumption,0,https://www.reddit.com/r/datascience/comments/17alfw3/fuel_consumption/,2,"Hello everyone 

I hope you have an amazing day so far.

I want to create a model to predict/estimate furl consumption of ships for their voyages. I'm thinking to consider weight,wind speed, wind direction etc. Any suggestions of what model should I create?"
213,What are some of the best library frameworks to use for speech2text and text2speech AI chatbot,1,https://www.reddit.com/r/datascience/comments/17al56s/what_are_some_of_the_best_library_frameworks_to/,0,"Hey guys, what are some of the best library or libraries to use to make a voice conservational AI chatbot? 

I googled around and found Vocode. They look pretty good. However Vocode rely on several other (paid) closed sourced libraries such as Deepgram (for transcribing) and Azure AI Speech (for synthesising). Are there any other libraries/frameworks available out there which are completely or more open sourced?"
214,What's the best way to implement Shaq and Anchor (XAI) techniques,1,https://www.reddit.com/r/datascience/comments/17ajf0e/whats_the_best_way_to_implement_shaq_and_anchor/,0,"Anyone done something on XAI where you use SHAP and Anchor model to explain your model?

I implementes Shap to predict the next day event but find it a bit confusing using Anchor or Lime to do so"
215,We built An Open-Source platform to process relational and Graph Query simultaneously,4,https://github.com/apache/age,4,
216,Moving to Big Tech from big government contractor,4,https://www.reddit.com/r/datascience/comments/17a9bma/moving_to_big_tech_from_big_government_contractor/,2,"Hello all,

 I work at one of the big 4 consulting companies as a data scientist on their public sector accounts( with security clearance). I was a campus hire who started this year but I had a solid year of experience as a data science intern at a small tech company.  My bachelor degree was in statistics.

I want to move to a data science or data analyst positions at big tech companies. I mainly want to work in analytics and data engineering. How many years of experience would I need to have a decent change?what would you recommend to increase my odds? Should I get a master degree? Where can I go to network other than cold email? Do certifications help?"
217,What makes a good take home?,2,https://www.reddit.com/r/datascience/comments/17ai9df/what_makes_a_good_take_home/,34,Getting around to expanding the team and wanted to implement some sort of coding portion. Does anyone have good experiences with a take home that is respectful of a candidate’s time but also will give you a good idea of their skills? Not a copy/paste LeetCode either.
218,Performance issues with dbscan,1,https://www.reddit.com/r/datascience/comments/17adx4s/performance_issues_with_dbscan/,6,I’m looking to clustering on a dimensionally reduced dataset of 3D vectors. I’ve tried using kmeans mini batches but the problem is that the visualization of the labelled data is not what I’m looking for. I also tried using dbscan but I’ve ran into performance issues where I run out of memory. For reference the dataset is over 100k rows and in the future I’d like to use a similar clustering approach for gigabytes worth of data. Any alternatives or advice will be greatly appreciated.
219,Predict maximum capacity of parking lots,15,https://www.reddit.com/r/datascience/comments/179ub5l/predict_maximum_capacity_of_parking_lots/,36,"Hello! I am dealing with a specific problem: predicting the maximum number of cars that can stop in a parking lot on a daily basis. We have multiple parking lots in a region, each with a fixed number of parking slots. These slots are used multiple times throughout the day. I have access to historical data, including information on the time cars spent in the slots, the number of cars in any given period, the number of empty slots during specific time periods, and statistics for nearby areas.

The goal is to predict, for each parking lot, the maximum number of cars it can accommodate on each day during the pre-Christmas period. It's important to note that historically, none of the parking lots have probably reached their maximum capacity.

Additionally, we are faced with a challenge related to new parking lots. These lots lack extensive historical data, and many people may not be aware of their existence.

How would you recommend approaching this task?"
220,Seeking Advice on Machine Learning Algorithm Selection for Competitions,2,https://www.reddit.com/r/datascience/comments/17a6t46/seeking_advice_on_machine_learning_algorithm/,1," 

Hello, fellow data science enthusiasts! I'm participating in some machine learning competitions and I'm looking for insights on the strengths and weaknesses of various ML algorithms, along with their ideal use cases. This will help me choose the most suitable model for my competition tasks. Your expert opinions would be highly valuable!

1. Could you please share your thoughts on the strengths and weaknesses of different ML algorithms, considering factors like accuracy, interpretability, computational requirements, etc.?
2. What are some specific use cases or scenarios where certain ML algorithms excel? For example, which algorithms are best for image classification, natural language processing, or time series forecasting?
3. Are there any resources, articles, or books that you would recommend for a deeper understanding of ML algorithm selection?

Your insights will be greatly appreciated and will aid me in making more informed decisions for my competition endeavors. Thanks in advance!"""
221,Feedback on my MVP project - Pre-Recorded Standardized Video Interviews Job Site for Data Professionals,1,https://www.reddit.com/r/datascience/comments/17aba8j/feedback_on_my_mvp_project_prerecorded/,0," 

Hey!

**Startup:**

\- Apply Script dot com ""Connect business and data professionals via pre-recorded standardized video interviews.""

**More details:**

**Problems with Traditional Hiring**

\- Outdated: The current method of conducting interviews has become overly complex and outdated.

\- Time-Wasting: The process involves too many appointments, meetings, and stages, leading to communication errors.

\- Expensive: The man-hours invested by HR and engineering teams are costly.

\- Constraining: Interviews are fixed to specific times and locations.

\- Cumbersome: The experience is challenging for both businesses and professionals.

**Our Solution**

\+ Talent Identification: We find top talent that matches your job post.

\+ Standardized Interviews: Professionals standardized pre-record their interviews (apples to apples comparison), covering areas such as CV, personality questions, project presentations, theory questions, coding tests, and hobbies.

\+ Efficiency: Businesses receive a pre-filtered batch of top applicants with their interviews ready for viewing.

\+ Time-Saving: Professionals can apply and businesses can employ candidates more quickly than with traditional methods.

\+ Reduced Workload: Minimize time spent reviewing applications; all interviews are pre-recorded.

\+ Flexibility: Managers can watch, speed up, or rewind interviews at their convenience.

\+ Transparency: Applicants receive immediate feedback on their applications to avoid being ""ghosted.""

**Life cycle stage:**

\- Validation: Currently looking to run our ***#1st pilot B2B*** with our first client.

**My role:**

\- Founder

**Goals for this month:**

\- Secure my first client for the pilot.

\- Obtain feedback from both the employee and business sides.

\- Optimize the product based on the feedback received.

**How can I** **help?**

\- I am searching for a business, that wants to streamline and accelerate the hiring of top data professionals (ex.: Data Scientist, Machine Learning Engineer, Data Engineer, Data Analyst) in the USA.

\- in the USA.

Thx for the feedback ;)"
222,What does it mean to get a take-home assignment before screening call?,4,https://www.reddit.com/r/datascience/comments/179yve1/what_does_it_mean_to_get_a_takehome_assignment/,6,"This has happened to me twice now, dunno if it’s a new trend in recruitment processes. I’m fine with it, to be honest, because it lets me show that I have the skills necessary for the job. I’m not currently working in DS but in finance with some data analysis, but not much modeling work to show for (even though I have my master’s in a computational quantitative field and so know the stats/theory behind most models).

 I didn’t get the first job that required a live-coding exercise because they could only schedule it while I was on vacation and I didn’t feel like I could really prepare, but now with this second position I passed the assignment and I have a 45 minute behavioral interview tomorrow. 

Just wondering for anyone who has had a similar recruitment process, does this mean that this recruitment process should be relatively quick? Just this interview and maybe one more technical one? (Am a bit desperate to switch jobs as my current job has a crazy high tempo and it’s hard to find time to interview, which is the main reason I don’t want a super dragged out process)"
223,Is the 30th percentile of a standard normal distribution closer to one standard deviation below the mean or two standard deviations below the mean?,0,https://www.reddit.com/r/datascience/comments/17aatez/is_the_30th_percentile_of_a_standard_normal/,3,
224,Why employers want experience over education,146,https://www.reddit.com/r/datascience/comments/179ebar/why_employers_want_experience_over_education/,79,"**Creativity**: We often focus a lot on hard skills, but creativity is the most important attribute for a data scientist. You will get some crazy requests. For example, I was once asked to build a recommendation system with NO DATA. Many other data scientists dismissed the project saying it couldn't be done. I was able to accomplish it by building a simple model were I manually entered weights depending on how important I thought each feature was. I then set up a pipeline to update these weights as real data would come in. Was it perfect? No. But it did a good enough job while we were waiting for data and made the client happy. I have had many crazy requests like this. So many data scientists out there have to be told what to do, very few can come up with creative solutions. The best never use phrases like, ""that is impossible."" How do you learn this creativity? By working on real world problems. This skill is not developed when you are given a toy dataset and told what the output should look like. Sure, you might learn some technical modeling, but virtually no creativity. I wish more bootcamps would give ""impossible"" tasks.

**Dirty Data**: I understand that provided or toy datasets can sometimes be dirty. They don't come close to real world data. Imagine you are asked to build a model using datasets you do not know exist yet, coming from source systems with little-to-no descriptions of what the features mean. Somehow you need to find the right data in a sea of millions of irrelevant features. You will need to fight political battles to even get access to the features you do not yet know if you even need. You will need to track down knowledgeable people who can tell you the weird quirks in the data (e.g. missing months were poorly imputed when this random country suffered a natural disaster 12 years ago). You then need to build a full pipeline that pulls the data from 10 different data sources that don't link to each other naturally, do regression tests because they don't update consistently, transform it, do feature engineering, feed it to a model, monitor the model for drift, redo everything after you find out a feature is completely different from what you were told, and the list goes on. This is not an exaggeration, it is typical. It goes way beyond cleaning up a few outliers and training a prototype model. This experience can only be gained by doing it.

**Being easy to work with**: A bad hire can be a disaster! One person can ruin group moral and be difficult to get rid of. It can be difficult to judge personality from a few interviews. Haveing work experience where you got along with the same team for years greatly reduces that risk.

There are many others, but these are three big ones. If you don't have these skillsets, that is fine! But you have to start smaller. Get a more Jr level position where you are not expected to know all of these. Get experience working on them with more senior mentors. Even if you are one of the lucky few who get a job out of college in this market, your manager is probably clueless of these issues (i.e. won't be able to help you) and setting you up for failure. Many on this sub are looking for shortcuts or complaining about their job after they took a shortcut. You will have a much better career if you take the patient route."
225,Anyone got interview call from Kodiak Robotics?,1,https://www.reddit.com/r/datascience/comments/17aahht/anyone_got_interview_call_from_kodiak_robotics/,4,"Hey y'all, I have a 15 minute interview coming up with Kodiak.ai (Kodiak Robotics). Wondering what it's about. Any help is greatly appreciated!"
226,"Q: How to extract learnings from my spreadsheets, beyond simple correlations?",2,https://www.reddit.com/r/datascience/comments/17a2wb4/q_how_to_extract_learnings_from_my_spreadsheets/,2,"**TL;DR:**

Below, I describe the info I'm tracking, and an algorithm I want to follow to produce a model that shows which factors matter and which don't. **My question is, does this algorithm already exist in some code library?** Or do I have to code it myself?

**Background:**

I've been keeping a spreadsheet of my sleep habits and energy levels for the last 60 days. I have looked a bit at simple correlations -- the highest correlation so far is (no surprise) the correlation between the number of hours a night I have been sleeping recently, and the energy level I feel in the morning. Other correlations, like drinks of alcohol or caffeine, are lower, but I wonder if they would show a stronger effect if I controlled for other factors.

**Regression algorithm:**

I used to work at a data science company where we would run studies we called ""regression hill climbs"", where we would iterate like this:

1. identify the output factor (AKA ""dependent variable""); in this case, it would be energy level on a given day
2. for every input factor (AKA ""independent variable"", e.g. whether I taped my mouth shut the night before), calculate the correlations between it and each other input factor
3. start with an empty ""model"", a set of independent variables
4. start with a correlation between model and dependent variable of 0
5. repeat until no more variables are selected to add to the model:
   1. filter all candidate independent variables, omitting any with too high a correlation to any of the already selected variables in the model (e.g., must be under a threshold of 0.3; this avoids over-fitting) 
   2. of all remaining candidate independent variables, try adding each to the model, and running a new regression on the model's variables (to best predict the dependent variable)
   3. select the candidate independent variable that most increased the resulting correlation between model and dependent variable, if and only if the increase is above some threshold (e.g., .02 improvement in correlation)

This results in a model whose total number of independent variables is small, where each is not influenced too much by the others, and where you can see how significant it is (and whether it is positive or negative!). 

**Why it matters:**

For instance, if I have nights where I'm more disciplined overall -- say, when I don't drink, I go to bed early, I set up my CPAP machine and use it all night, etc. -- it might turn out that there's a high (negative) correlation between drinking and sleep quality, but the model may omit alcohol as a variable because its value is really just captured entirely in hours of sleep and in CPAP compliance.

Or, maybe, even taking these things into account, drinking alcohol does consistently disturb my sleep quality, and I should stop. Or maybe it has a slight positive effect! The point is, it's very hard to isolate it as a factor; this algorithm helps.

**What I'm looking for:**

A code library -- presumably in python -- that is built to perform such a ""regression hill climb"", and allow for the various thresholds and other settings to be specified.

Does anyone know of such a library? Or, is there something different I should do, or some way I'm misunderstanding the problem?

Thanks!"
227,Should data-scientists look for their own datasets or be provided by the hiring company?,2,https://www.reddit.com/r/datascience/comments/179ztob/should_datascientists_look_for_their_own_datasets/,12,"Hi,   


We just hired a data analyst to analyse a time series representing a certain commodity value over time, we offered them the possibility to take the price data from a source of their choice, but they insisted that we provide it ourselves. Is this good or bad practice? Could someone give pros and cons of letting the analyst find their own publicly available data vs. the company providing them the data set?   


Thank you"
228,Time series data filtering - keep outliers and remove only flat trend,1,https://www.reddit.com/r/datascience/comments/17a5u8t/time_series_data_filtering_keep_outliers_and/,1,"I'm building price tracker and want to plot prices over time for few dozens products. Seaborn relplot alike functions are pretty slow and I want to limit script run time to minimum.

I thought about 2 solutions:

1. sample data for each product in a way that keeps 'outliers' in dataset (i.e. spikes for visibility and dips to get notified that maybe it's time to buy it). Not sure if it's easy 
2. get rid of data points for which data trends flat based on moving average

&#x200B;

Any better idea that is easy to implement?

&#x200B;"
229,Does anyone have a good glossary for data science?,1,https://www.reddit.com/r/datascience/comments/17a5thj/does_anyone_have_a_good_glossary_for_data_science/,1,I'm looking for a detailed glossary of terms in data scientist that an experienced data scientist should know. It's mostly for myself to test my knowledge. Anything from regression types to p values and much more.
230,Live 2023 Election Results (Also Future Results),0,https://www.reddit.com/r/datascience/comments/17a5plc/live_2023_election_results_also_future_results/,0,"Specifically for Kentucky but I'm trying to get an automated tracker by county (precinct if possible) to keep track of results coming in. I saw some 2020 ones using New York Times in this [comment](https://www.reddit.com/r/rstats/comments/jo1yuw/comment/gmnxfz3/?utm_source=share&utm_medium=web2x&context=3), but can't figure out what it would be for a single state's off off year election

&#x200B;"
231,Shared Public Contextual Database for RAG,2,https://www.reddit.com/r/datascience/comments/179z4yq/shared_public_contextual_database_for_rag/,1,"Hey Guys,  
It seems RAG is really taking off as an increasingly popular use case for LLMs to leverage contextual data. However, everybody is building their own contextual data sets and embedding them in their own silo'd vector dbs.   


Do you guys think there's any utility in having a shared public vector db that anyone can tap into their API, without having to self-host, worry about the embedding pipelines and filling the vector db with enough data in the first place for their use cases? Would this save devs alot of time in quickly testing testing product ideas? (albeit it does seem that propriety data is what everyone's raving about today)  


\-  


For context, I'm building a social media product we're users can upload a few pieces (approx 10) of content (social media posts, websites, videos to start with), which becomes the verified human-curated list/Niche. We then classify and embed this into a vector db. From this, we have set up a data pipeline to scrape the web and find new content that is most similar which we suggest to users to add to the Niche (upvote, downvote style). When a piece of content is upvoted on its added to the verified list updating the Niche's classification string. Essentially we're aiming to construct an ever-growing, user-curated, contextually classified vector database from a relatively small set of sample data. "
232,How many companies actually have a clear plan for their data?,114,https://www.reddit.com/r/datascience/comments/179945p/how_many_companies_actually_have_a_clear_plan_for/,48,"I have been working as a ""data scientist"" in supply chain for a little over a year at a fortune 500 company. I am the only person with a data related title on my team. There is one small team of people with ""data scientist"" titles in the whole org but they are in a separate silo from me. 

Generally I am tossed tasks that don't make a whole lot of sense: for example comparing forecast accuracy for the exact same models between a no-code out of the box forecaster like SAP IBP with Python models that a contractor they hired built. Other times I will get requests so vague like ""build us a chatbot"". I have always hounded them with questions and shared my opinions on these asks, but basically get told to shut up and go away each time.  

Now they have cut what I can only assume is a few million dollar check with a large consulting company to build out a demand and inventory forecasting model. The thing is, they just launched an out-of-the-box SAP solution less than 2 years ago which does exactly that: inventory and demand forecasting. I can't imagine that project was less than a few million as well. 

In all of this, no one can ever really articulate to me why we are doing this or what specifically they are trying to improve. It seems like they don't even realize the consultants will likely build a very similar model to SAP. 

Are most companies like this? Only some? It has been very stressful for me, as 4 people have also been let go from my team within the year I've worked here. It seems like they have no vision or clue what they are doing."
233,How to Build Data Products? Deploy: Part 3/4 - Doubling down on the power of Unified Experiences,2,https://moderndata101.substack.com/p/how-to-build-data-products-deploy,0,
234,How good are the Linkedin Learning Paths?,1,https://www.reddit.com/r/datascience/comments/17a25ns/how_good_are_the_linkedin_learning_paths/,3,"Hi all,

&#x200B;

I have access through my school to LinkedIn learning. I saw that they have different paths for python and data science, business intelligence, and data analyst.   
Has anyone tried them or what do you guys think of them?  
I saw these paths: Advance Your Python Skills for Data Science, Become a Business Intelligence Specialist, Getting Started as Business Analyst, and Become a Data Analyst.

&#x200B;

Is it worth giving a try to any of these? I would be interested either in Business Intelligence or the Data Analyst one. I do have some time so could use the input before I just jump into one. My interest is to gain data analysis knowledge and make a transition over time. My background is in higher education and currently teach at the uni but do not see myself doing that for a long time.

&#x200B;

Appreciate the input or help."
235,Repetitive airflow pipeline problems,5,https://www.reddit.com/r/datascience/comments/179r5li/repetitive_airflow_pipeline_problems/,0,"Hi r/datascience,

From my experience working with data orchestration tools (Airflow primarily), I tend to deal with a lot of repetitive fixes with flaky pipelines such as resource exhaustion issues, single malformed entries or other edge cases, figuring out why a task isn't running, and so on. I was wondering whether any of you had the same experience in your day-to-day work. How much of the job is actually just dealing with repetitive issues and maintenance of pipelines, and do any of you know of any tools or tips to make the experience of working with these pipelines less time-consuming?

Thanks!"
236,Cracking the Code of Human Motion: Describing Movement Patterns with Scalar Values,2,https://www.reddit.com/r/datascience/comments/179u12d/cracking_the_code_of_human_motion_describing/,0,"Hey fellow Redditors!

Ever wondered how technology can tackle a range of challenges like signature authentication, detecting cheaters in games, assessing neurological conditions, or dealing with pesky bots? The answer lies in the fascinating world of human motion analysis!

In this discussion, we delve into the concept of ""features"" in the context of human motion. Features are scalar values obtained from motion segments, offering insights into movement patterns. We explore how these features are essential in addressing diverse challenges and share insights into the basic features of movements.

# 💡 What's a Feature?  

In this context, a feature refers to a scalar value obtained from a motion segment. For example, the average acceleration of a cursor. As depicted in the diagram below, users cannot be distinguished solely based on their average acceleration, but there are discernible individual tendencies.

 The next step involves constructing our feature space by identifying features that contain relevant information about movement patterns. 

# 📊 Analyzing the appropriate time series

The majority of the data we work with consists of x and y coordinates that change over time, such as the position of a cursor or a pen on a screen. Therefore, we already have two time series. Additionally, we calculate directional speeds, accelerations, jerks, as well as direction-independent speed, acceleration, and jerk. 

**Unmasking forgery through speed analysis**

Let’s explain the use of derivatives through an example of **signature forgery**. Suppose someone attempts to replicate a signature they have seen before, familiar with its form. How would you approach this situation? Initially, one might **meticulously trace the line to be replicated, proceeding slowly and accurately**, inch by inch. The result would be a slow, nearly constant-speed movement. **The speed time series would exhibit an approximately constant value.**

Now, imagine **someone writing their own signature**. **The speed can vary significantly**, but it won’t remain constant. They would draw longer, straight lines more quickly and slow down at tight turns. When moving right and upwards, the arcs would be faster and more dynamic than when turning left. Even if the forged signature’s image is an exact copy of the genuine one in terms of x-y coordinates, **the speed profiles would look entirely different.**

Of course, this was a rather clumsy attempt at forgery; there are far more skilled individuals in this field. The speed of a signature can be estimated based on the signature image alone, either by assuming faster movement on straight lines and slower movement on curves or by considering the line quality.

Delving into the details is beyond the scope of this discussion, but the key point is that estimating and replicating the speed of motion requires practice and talent. It is more challenging than simply replicating the x-y coordinates of the signature image. Moreover, forging the acceleration and other factors becomes even more difficult.

In theory, we could **take derivatives of our time series as many times as desired**. However, there is a practical limit as, **after a certain point, the derivative becomes more noise than meaningful information.**

From this example, it becomes apparent why we thought utilizing derivatives (speed, acceleration, jerk) was a valuable approach for motion analysis. **When we began using this method, the results demonstrated exceptional accuracy**.

# 🔍 Describing Time Series with Scalar Values 

 We have extracted various time series from our motion sample. To condense the valuable information of a lengthy time series into scalar values, **we employ a straightforward approach: calculating a few statistical characteristics**. Our selection criteria ensure that these characteristics effectively represent the distribution of the time series.

Some of these characteristics are expected, such as the minimum, maximum, mean, and standard deviation.

To understand how the values progress from the minimum to the maximum, we utilize percentiles, including the 10th, 25th, 50th, 75th, and 90th percentiles. The minimum and maximum values are also considered as percentiles, specifically the 0th and 100th percentiles.

Two lesser-known statistical values are skewness and kurtosis. **Skewness measures the asymmetry of a distribution**. For instance, if the speed values below and above the average speed are evenly spaced, the skewness will be around zero. However, if there are numerous values below the mean but close to it, with only a few exceptionally high values above, the skewness will be positive.

In the context of cursor movement, this suggests that an individual typically uses the cursor at a relatively constant speed, but occasionally makes sudden moves. This could be a personal habit or characteristic.

On the other hand, **kurtosis indicates whether the values are concentrated around the mean or spread out across a broader range**.

These are the basic features we utilize for analysis.

Feel free to join the discussion and share your thoughts on this fascinating intersection of technology and human motion analysis! 💬🕺🏽💻"
237,Regretting Data Science,22,https://www.reddit.com/r/datascience/comments/179etbr/regretting_data_science/,28,"I was wondering if there are other people out there who regret choosing data science as a career path.

For context: I got my B.S. in Mathematics in 2018. I worked 1 year as a program associate for a non-profit, managing their database and writing reports for grants/funding purposes. I then switched to a job in retirement investing as an analyst. I was originally going to start grad school (for a Masters in DS) in the Fall of 2020 but delayed to 2021 due to covid so I stayed at that job for 2 years.

I enjoyed working with data and numbers, I kind of like how it feels to develop that tunnel vision and fixate on numbers lol. So I thought data science would be a good fit given those jobs revolved around data and it would be something financially stable (of course having no idea just how much covid et al. would impact the job market).

In the fall of the 2nd year of my Master's I received an offer to work for a large Healthcare company, which is where I am currently employed. To be honest, I genuinely hate it. I'm stuck working on the insurance side and it just feels miserable and unethical to me on a daily basis. I was hoping to join a team on the clinical side but wound up on the healthcare side due to the way the company matches employees to teams. I realized I miss working more directly with people, as I am on the west coast and the entirety of my team is on the East Coast or in India.

I can't really tell if my misery is because of the company I work for itself or the field in general. I think I want something more interesting than what I am currently doing. I work with insurance plan design data. I applied to this job on a whim, because of the condition of the job market I felt I had to apply to all sorts of things. I'm personally opposed to for- profit healthcare but accepted because I didnt feel I had much choice as it was the only offer I received after hundreds of applications over many months. 

Does anyone else feel extremely unsatisfied as a data scientist or as a data engineer? I guess I feel really under-stimulated and extremely unsatisfied. I don't know if every job feels like this and I have to suck it up, or if I should just leave. I've only been here 3 months and my resume is inconsistent enough as is so it feels too risky to leave even if I had a different offer lined up.

I'd love to hear about people who switched into data science / engineering then changed their mind. Also, id appreciate input on the longevity of this career. I'm having a hard time setting career goals for myself and understand what career growth in this industry looks like and what I should aim for."
238,Decoding LLM Uncertainties for Better Predictability,14,https://www.reddit.com/r/datascience/comments/1799oao/decoding_llm_uncertainties_for_better/,1,"Hi all,

Building off our last research post, we wanted to figure out ways to quantify ""ambiguity"" and ""uncertainty"" in prompts/responses to LLMs. We ended up discovering two useful forms of uncertainty: ""Structural"" and ""Conceptual"" uncertainty.

In a nutshell: Conceptual uncertainty is when the model isn't sure what to say, and Structural uncertainty is when the model isn't sure how to say it.

You can play around with this yourself in the [demo](https://uncertainty.demos.watchful.io/) or read about it in more detail in the [blog post](https://www.watchful.io/blog/decoding-llm-uncertainties-for-better-predictability)"
239,How can I do an AI Training for my team without it being totally gimmicky? Is it even possible?,3,https://www.reddit.com/r/datascience/comments/179kwrd/how_can_i_do_an_ai_training_for_my_team_without/,7,"My company is starting to roll out AI tools (think Github Co-Pilot and internal chatbots). I told my boss that I have already been using these things and basically use them every day (which is true). He was very impressed and told me to present to the team about how to use AI to do our job.

 Overall I think this was a good way to score free points with my boss, who is somewhat technical but also boomer. In reality I think my team is already using these tools to some extent and will be hard to teach them anything new by doing this. However, I still want to do the training mostly to show off to my boss. He says he wants to use it but has never gotten around to it.

I really do use these tools often and could show real-world cases where it's helped out. That being said, I still want to be careful about how I do this to avoid it being gimmicky.
How should I approach this? Anything in particular I should show?

I am not specifically a data scientist but assume we use a similar tech setup (Python / R / SQL, creating reports etc)"
240,Cruise Ship Musicians Scheduling,1,https://www.reddit.com/r/datascience/comments/179q91p/cruise_ship_musicians_scheduling/,12,"I am a musical director on a large cruise ship and am responsible for scheduling sets for 10 different bands around the ships 10 different music venues. I have to work around trivias, parties and shows in the aqua theatre and Theatre and other various venues on the ship. I want to analyze the data I have from Day 1 of the cruise a few weeks ago in a chart. How would you guys go about doing this? Thanks!"
241,What would be a good curriculum for a data scientist to learn about forecasting?,15,https://www.reddit.com/r/datascience/comments/17941v2/what_would_be_a_good_curriculum_for_a_data/,9,"Basically, the title. I would really like to hear from the  experts in the forecasting what do you think are the most important things to learn to be a competent professional in a forecasting field and where to pick it up? I am.especially interested in the dand forecasting. Thank you very much!"
242,Identity Crisis in Data Science,72,https://www.reddit.com/r/datascience/comments/178vvrk/identity_crisis_in_data_science/,32,"Anyone else confused where they fit in data science? There's a huge range of backgrounds, from bootcamps to Ph.D.s. I've found DS quite unwelcoming because of this. Everyone is trying to distinguish themselves from the ""fakers,"" while most companies needs are quite basic.

I've been working on a DS master's degree for a year. I certainly know more than the typical data analyst or self-taught MOOCs student, but I'm overwhelmed by the interdisciplinary nature of the field. I've invested countless hours and thousands of dollars, yet there's a lifetime more to learn. This makes me question whether I want to continue in the field. When I talk to computer scientists, they're all very encouraging and emphasize that, although difficult, everyone can learn to code. When I talk to other data scientists, I get an air of elitism.

I think this happens because data science is a relatively new field. Other specialized skills like accounting, law, or finance have had time to settle into a list of requirements and utilize certifications where necessary. Since we have one title to describe a huge population, people end up getting defensive so they're not grouped together with the less qualified. Maybe overtime this resolves itself as data science expands into more titles. For now, I feel caught between both sides of the argument. I have no desire to get a PhD and a lot of imposter syndrome. It leaves me feeling like I should have gone MBA -> product management and called it a day.  On the flip side, when I explain basic stats at work, I'm met with blank stares, leading me to think the push for Ph.Ds is more about ego than practicality. My hope is to see clearer distinction in titles and more encouragement in the field than discouragement. 

For those of you in the middle like me, where have y'all had success? What kinds of industries, companies, or roles do you target?"
243,Free Open-source ML observability course: starts today 🚀,6,https://www.reddit.com/r/datascience/comments/1796r3n/free_opensource_ml_observability_course_starts/,0,"Hi everyone, I’m one of the people who work on [Evidently](https://github.com/evidentlyai/evidently), an open-source Python library for ML monitoring. I want to share with you our free ML observability course that starts today, Oct 16.

We cover the key concepts of ML monitoring and observability, different types of evaluations, and how to integrate them into ML pipelines. We also look into different ML monitoring architectures and explore how to monitor unstructured data, including LLM and NLP models.

💻 Code examples and end-to-end deployment blueprints.  
✅ Open-source focused. You’ll work with tools like Evidently, MLflow, Airflow, and Grafana.  
❤️ Free and open to everyone.  
🗓 You can join the cohort that starts on October 16, 2023, or learn at your own pace.

Course info and notes: [https://learn.evidentlyai.com/](https://learn.evidentlyai.com/)

Hope you’ll find the course useful!"
244,Time series forcasting,0,https://www.reddit.com/r/datascience/comments/179q60m/time_series_forcasting/,6,"Why we cannot use GAN's inplace of LSTM for any recurrent neural network for time series forcasting.
As we can plot univariate time series on plot and train GaN's to complete that plot.

Not so much work is in going on this feild.
Why ?"
245,"Hitting a bottleneck (500+ applications over the past half year with barely any interviews at all). Any advice on job searching, applications, or even transitioning from another field?",9,https://www.reddit.com/r/datascience/comments/1792cy2/hitting_a_bottleneck_500_applications_over_the/,12,"I've been job searching for awhile now, and while I understand that the job market in general is rough right now, I have to imagine that struggling to even get initial interviews means that I'm doing something wrong. 

For context, I'm pretty much graduated with a BA in Economics at Boston University. I have some part-time and internship experience: about half a year of working the front desk of a small hotel (I have not put this on my resume since I worked the job for side money, not for work experience), a few months as a Sales Representative, a few months as a Dispute Resolution Analyst for the Better Business Bureau, and a few other internship experiences during my high school years. Obviously, none of my work experience is related to working with data or analysis, other than some of my Economics coursework, completing the Google Data Analytics certificate, and a guided project with Python (NumPy, Pandas, Seaborn) in Exploratory Data Analysis on Coursera. In any case, I know that my work experience is pretty weak/nonexistent and I've been struggling to even get an initial interview for entry-level/no-experience-required roles. So what can I do in terms of job searching/applications? Should I focus more on my resume/work experience by completing my own projects that demonstrate self-taught skills (Excel, SQL, Python, etc.)? Or should I give up on trying to apply for data/analyst roles and instead try to transition in through a different field like Marketing, Consulting, etc? Any and all feedback that can help me get past this current bottleneck would be greatly appreciated!"
246,Popularity of Data Visualization tools mentioned in data-science/ml job descriptions,6,https://www.reddit.com/r/datascience/comments/1792wrc/popularity_of_data_visualization_tools_mentioned/,2," Source: [https://jobs-in-data.com/blog/machine-learning-vs-data-scientist](https://jobs-in-data.com/blog/machine-learning-vs-data-scientist)

About the dataset: 9,261 jobs crawled from 1605 companies worldwide in June-Sep 2023

https://preview.redd.it/dympbqa3ljub1.png?width=2560&format=png&auto=webp&s=e5db457072a89a08528d73fe0c064adc45372dea"
247,Not getting noticed for data science jobs,55,https://www.reddit.com/r/datascience/comments/178r037/not_getting_noticed_for_data_science_jobs/,37,"I've been a data scientist with 3 (almost 4) years experience and a Masters. Is there somewhere you guys go to get your resume critiqued or improved? I've tried sending it to a career counselor and she thought it was good. Also, I met someone who works in the industry through a career fair, and he said it is ""impressive"". Nevertheless, I apply to job after job, only to get rejection emails. After 4 months, I've had one interview and that was through a referral. Even the hiring manager said the resume looks good for the job (before interview). This happens even if I tailor my resume, apply to jobs that I feel I'm highly qualified, and am early in applying (within a week of job posting). I feel like I'm wasting time, and this is just the first step. Interviewing is going to be another battle, and at this rate I will never find something!"
248,What are the best sites to review DS topics/study for interviews?,23,https://www.reddit.com/r/datascience/comments/178wh2z/what_are_the_best_sites_to_review_ds_topicsstudy/,13,"It’s been a while and all I really do in my job is NLP and googling. I haven’t used SQL, stats, etc.. in such a long time. I’ve looked at leetcode and interviewquery, but there’s a lot out there.

What would you recommend using? Thanks!"
249,Do you folks Leetcode?,111,https://www.reddit.com/r/datascience/comments/178juum/do_you_folks_leetcode/,74,"I come from more of a engineering(non-software) background and never learned Data Structures and Algorithms. I want to start applying for jobs next year(3 YOE), how often are you asked Leetcode questions in interviews? I'm trying to figure out a plan of action to get prepared."
250,Will being data analyst in casino resort ruin my career?,210,https://www.reddit.com/r/datascience/comments/178fhbg/will_being_data_analyst_in_casino_resort_ruin_my/,131,"Updated:

Thank you so much for all the suggestions and comments! The community is so supportive and enthusiastic. I read every comments very carefully, probably more than one time for most, and they are very insightful and play a vital role in my decision making, whether thumbs up or down.

I have been thinking about this almost every minutes in the past few days. In the end, I decided to take this offer. For me this decision is very complicated. Actually I am not sure how long I will stay, but it's always important to make my first step.

Thank you again for all the comments! 

\--------------------------------------------------------------------

As a new graduate recently I am getting a data analyst offer from a casino resort. It's a hard time for new grad and after two times of withdrawals of my offers, this is the only one I have in my hands. The job duty is about analyzing campaign performance, analyzing customer patterns, and forecasting business trends.  They are also working on breaking data silos utilizing cloud service so ETL jobs should also be expected.

Overall the project sounds pretty attractive to me. My only concern is the business itself. One of my friends (not in US) gave me a strong suggestion that don't easily go into this industry. He was working in an operation role for company building mobile casinos, and the business logic was so different from other industries that it's hard to get out of this. Many people have a bias toward this career so he had a hard time changing jobs.

I am scared, to be honest. But I am not sure to what extent his thoughts work in my scenario. Casino Resort still looks much different from mobile casinos and his role was not data analyst. I wonder how you guys think about this.  Should I take this offer?"
251,Forecasting Using Clickhouse Machine Learning Functions,2,https://ensembleanalytics.io/blog/forecasting-using-clickhouse,0,
252,Which Model is best for Word Embedding?,8,https://www.reddit.com/r/datascience/comments/178ztsj/which_model_is_best_for_word_embedding/,1,"Hello, I'm currently involved in a project that focuses on generating embeddings exclusively for individual words, without considering the context or entire sentences. For instance, we aim to establish similarity between ""Company City Name"" and ""Company Country Name"" and compare them with ""Employee City Name"" and ""Employee Country Name."" I'm seeking recommendations on the most suitable model for generating embeddings tailored to this specific word-level analysis. Thank you for your guidance. "
253,Is this normal qualification?,156,https://i.redd.it/ek2tuv1p5dub1.jpg,56,
254,"When using bagging or boosting to combine decision trees, which algorithm takes more time to train?",2,https://www.reddit.com/r/datascience/comments/1794e1d/when_using_bagging_or_boosting_to_combine/,2,
255,ML Engineering Courses/ Certs,3,https://www.reddit.com/r/datascience/comments/1791y53/ml_engineering_courses_certs/,2,"I'm an MSc graduate with some DS experience and I'm looking to move to a ML Engineering role. Are there any courses you would recommend? My Masters was in applied math and my UG was in mathematics, so I have the maths and stats, and have done a lot of work with neural nets and PyTorch. "
256,[Applied Data Science in Marketing] How to measure marginal returns and elasticity of marketing campaigns,1,https://www.reddit.com/r/datascience/comments/1798de7/applied_data_science_in_marketing_how_to_measure/,0,"Hi, all! I am a Data Scientist experienced in Marketing Science, and am writing a small online book regarding topics that are important in marketing science. I wrote a chapter regarding:

\- The law of diminishing returns

\- ROAS and Marginal ROAS

\- Advertisement elasticity on Returns

Hope that it is useful for everybody. Any feedback is welcome.

[https://phc4rdoso.github.io/2.%20The%20Law%20of%20Diminishing%20Returns.html](https://phc4rdoso.github.io/2.%20The%20Law%20of%20Diminishing%20Returns.html)"
257,Is my idea worth pursuing ?,6,https://www.reddit.com/r/datascience/comments/178yk7k/is_my_idea_worth_pursuing/,5,"I'm a software engineer, while building AI side projects I noticed that it takes a while to setup the MLOPs and cloud infra for deploying and building models so, I'm creating a low-code platform for finetuning and deploying ai models (B2B mostly). do you guys think there is a market for this product ?"
258,Data Science Protfolio,2,https://www.reddit.com/r/datascience/comments/17932k1/data_science_protfolio/,3,"Hello everyone,

I'm a former data science student who started to work in IT audit but decided to go back to DS.  I am rebuilding my portfolio with new projects. Any great project ideas ?   
Here are some projects i think about, please don't hesitate to give your opinion on which to choose :   


* Credit Card attrition.
* Black&white video/ picture coloring and improving.
* License plate recognition
* Facebook Friend Recommendation
* Quora Question Pair Similarity
* Credit scoring improvement
* Disease Outbreak Prediction
* Product Recommendation system
* Housing Price Predictor
* Sentiment Analysis
* Stock Price Forecasting
* Flight Delay Prediction
* Fire Outbreak Prediction
* Game Outcome Prediction
* Object Detection in Videos
* Influencer Detection

Thank you in advance for your response.

P.S : If anyone has great mentorship platforms or any other way of mentorship please don't hesitate."
259,Causal inference as a blind spot of data scientists,64,https://www.reddit.com/r/datascience/comments/178ifs7/causal_inference_as_a_blind_spot_of_data/,61,"Do you use Causal Inference as a data scientist? I wrote an article to reflect why it took so long for data scientists to discover Causal Inference and and tried to give an inspirational overview (just look at the images). 

[http://www.dzidas.com/ml/2023/10/15/blind-spot-ds/](http://www.dzidas.com/ml/2023/10/15/blind-spot-ds/)"
260,Sap ui5 fiori vs data science,1,https://www.reddit.com/r/datascience/comments/1796r9j/sap_ui5_fiori_vs_data_science/,5,"I'm in a part of my life where I hate my job. I work as a SAP EP consultant with little SAP ABAP handson. Should I continue with this or should I opt to something I am interested in I.e data science/compute vision? 

Mainly looking from future, career , job security and money. Which one has more benefits say in years so that my future self feels good about today's decision"
261,Advice on my approach for a project,1,https://www.reddit.com/r/datascience/comments/1796ecp/advice_on_my_approach_for_a_project/,2,"For my project, I need to identify existing to users to start using a product. 

I have different ideas that I want to try, but I would like to have your input.

&#x200B;

**Idea 1**: Cluster existing clients and see if within a cluster a majority of clients are already using the product, meaning that we can recommend it to all clients inside that cluster

&#x200B;

**Idea 2:** Calculate the centroid of all clients that use the product, and using Eucledian distance, find which clients are closest to the centroid, meaning that we could get them to start using the product.

&#x200B;

**Idea 3:** Run a clustering algorithm. Then, select a cluster where the product usage is very high, and another where product usage is very low. From there, I could randomly sample each cluster to train a classifier and run it on other samples to see which clients do we predict could use the product.

&#x200B;

Let me know what you think or if I am on the right track!"
262,Sharing is caring - with Gorudo.io,0,https://www.reddit.com/r/datascience/comments/17961eu/sharing_is_caring_with_gorudoio/,1," Sharing is caring - Creators can share your trade diary with your Members any time using [Gorudo.io](https://Gorudo.io)

&#x200B;

https://preview.redd.it/kyec0yu6hkub1.jpg?width=2048&format=pjpg&auto=webp&s=5bb8633dcf5fb1d7a240fc7d86f5376a0db4e2e3"
263,"Weekly Entering & Transitioning - Thread 16 Oct, 2023 - 23 Oct, 2023",5,https://www.reddit.com/r/datascience/comments/178xboh/weekly_entering_transitioning_thread_16_oct_2023/,105," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new)."
264,Interpretation of logistic regression in absolute terms,1,https://www.reddit.com/r/datascience/comments/17950k5/interpretation_of_logistic_regression_in_absolute/,0,"I have a lofistic regression that predicts the probability a customer converta to sale. It has different intercepts based on demographic segment and a coefficient to advertising.

The problem is very unbalanced, most people will not concert.

Now....I want to use this logistic regression to say how many sales advertising delivered, in absolute terms.
I.e. you had 1000 sales, 800 were baseline /intercept and 200 are from TV.

How would you go about solving this?"
265,Which Model is best for Word Level Embeddings Generation?,2,https://www.reddit.com/r/datascience/comments/178zw5j/which_model_is_best_for_word_level_embeddings/,1," Hello, I'm currently involved in a project that focuses on generating embeddings exclusively for individual words, without considering the context or entire sentences. For instance, we aim to establish similarity between ""Company City Name"" and ""Company Country Name"" and compare them with ""Employee City Name"" and ""Employee Country Name."" I'm seeking recommendations on the most suitable model for generating embeddings tailored to this specific word-level analysis. 

I have tried ""[https://tfhub.dev/google/universal-sentence-encoder/4](https://tfhub.dev/google/universal-sentence-encoder/4)"" but it gives high score even there is no matching between words.

Thank you for your guidance. "
266,How remove highly skewed feature,1,https://www.reddit.com/r/datascience/comments/1792i6s/how_remove_highly_skewed_feature/,4,"Hey everyone,
I work actually in a ML project for binary classification problem. When I did the EDA, I found that there are some numerical features highly skewed ( almost close to zero) and we plotted the histogram of each feature by class I have the same distribution... 

Can someone help to solve this problem 🙏🏻"
267,How to use PPO policy network to find global min of a function ?,2,https://www.reddit.com/r/datascience/comments/178yb8k/how_to_use_ppo_policy_network_to_find_global_min/,0,"Hello everyone, I have been given a task where I have to find the minimum of a function. I know i can easily do this using Gradient descent but I have been specifically told to use PPO policy network and explore-exploit framework.

Is it even possible? If so then how should I go about achieving this?

link to the function formula is given here: [https://www.sfu.ca/\~ssurjano/holder.html](https://www.sfu.ca/~ssurjano/holder.html)"
268,Build a Data Science App with Just Python: A Streamlit Guide,39,https://www.reddit.com/r/datascience/comments/178eu2m/build_a_data_science_app_with_just_python_a/,10," td/dr: easily build a SaaS with just python + zero front-end knowledge using streamlit.

I wrote this short guide which allows you to create a Data Science micro-SaaS MVP with stripe integration using Streamlit python package. I thought folks here might find it useful. Example of a zillow clone below.

[A Comprehensive Guide to Building and Deploying a Scalable SaaS Web App with Python, Streamlit, MongoDB, and Stripe](https://medium.com/gitconnected/build-a-data-science-saas-app-with-just-python-a-streamlit-guide-240e0a56fc86)

[example of Streamlit SaaS](https://preview.redd.it/xl4z0dtf6dub1.png?width=1510&format=png&auto=webp&s=82643795b248c160de48cdc0f2fee9b0c6ac19ed)"
269,The ML project failure funnel,5,https://www.reddit.com/r/datascience/comments/178shmx/the_ml_project_failure_funnel/,2,"Hello there. 

I've been thinking a lot recently about ML projects that failed and tried to organize and write up my thoughts. Do y'all see it this way?  

[https://www.kobrosly.net/ML\_failure\_funnel.html](https://www.kobrosly.net/ML_failure_funnel.html)"
270,"How to handle ""A.I."" obsessed management?",157,https://www.reddit.com/r/datascience/comments/1786pqr/how_to_handle_ai_obsessed_management/,48,"Just wondering how to handle management that thinks ChatGPT is a sentiment being that is going to that is self learning entity that solves every problem. I was asked to give a presentation on how LLMs work and indicated they are  not considered classical A.I. After I was sent crackpot articles on how Chapt is thinking and learning, reading and learning how to talk.  Management literally is asking with every data science  project  if we incorporate ChatGPT A.I.. Im in a leadership role so have to try hard not to poo poo  this enthusiasm but its hard. Thoughts?"
271,Opinions about the insurance industry?,5,https://www.reddit.com/r/datascience/comments/178oz6c/opinions_about_the_insurance_industry/,1,"Apologies if this is the wrong place to ask. I was recently hired as a data scientist in a (motor) finance company. What is your opinion about this industry? Are insurance skills transferable to other industries too and if so, which ones do you think are closest?"
272,Data science/analytics project idea for friend's business,1,https://www.reddit.com/r/datascience/comments/178z2x2/data_scienceanalytics_project_idea_for_friends/,5,"Hi everyone. My friend has a small business (think ecommerce) and asked me if i can help in any way. I have a math background but I'm interested in trying some sort of DS/DA side project. Any ideas on what topics / results i should look for?

Sorry if this is open ended; this kind of project seems very different from college projects where they tell you to do a,b,c and put it in a presentation.

Thanks!"
273,MS in Statistics at East Bay location vs MS in Data Science in top 150 ranked University.,1,/r/gradadmissions/comments/178ysg4/ms_in_statistics_at_east_bay_location_vs_ms_in/,1,
274,Mgmt and team want me to put a model in production without data. What do I do?,9,https://www.reddit.com/r/datascience/comments/178ioxq/mgmt_and_team_want_me_to_put_a_model_in/,32,"Edit: thank you for all of your help!! I spoke with legal and said where I was, where I was going to be, and asked for more time to get the data. The data is slowly coming in; very excited! 

Feeling incredibly anxious since this goes against my ethical morals. 

I trained a model on data that won’t be used anymore; however, they want to use this model for data/KPIs that I’ve never seen before. They overpromised to senior leadership because the company is suffering. And they want me to over-deliver and do the paperwork/put this model into production.

I’ve asked to delay the deadline to get access to the KPIs for the model, but all they did was move the model due date up by…. A month. 

I’m having panic attacks and can’t sleep because this is just setting me up to fail. I’m so burnt out after speaking with management/teams. They just want to push this model into production, no matter what. 

How do you handle that? I’ve escalated the problem to other pp in mgmt and they said to just do it because of how important the model is. I’m 1000% sure that I’ll be seen as a scapegoat because there’s no way you can have a good model if there’s no data to train it/the wrong data.

For example, the OG data was on cats, but now they want me to look at data about ligers. It’s ridiculous and I’m not sure what to do. 

I haven’t been able to deliver the paperwork like they want/legal review because I know that this model isn’t good, but they want this to go into production so badly that the paperwork/things I’m saying aren’t correct. It’s due tomorrow, but there’s no way I can feasibly do that. I’ve tried meds and even thought of taking myself out of office this week to avoid this, but I lack the PTO. I got sick from the lack of sleep and I’m finding myself procrastinating on anything else because this ask seems so unethical. So many people at my company/role are getting laid off, and I should do this, but I just can’t do this. It’s related to my performance goals, too."
275,Casual Inference,6,https://www.reddit.com/r/datascience/comments/178kkpc/casual_inference/,5,"I am aware about the experiment design process in simple business model, but experiment design is lot more complicated in two sided or three sided marketplace. Can anyone help me to understand how the experiment design works in three sided marketplace like Uber or Amazon ?"
276,Is my experience not good?,5,https://www.reddit.com/r/datascience/comments/178lcts/is_my_experience_not_good/,9,"
For some context, I’m a 24 year old international who recently graduated with a MS in CS in the US. Throughout my bachelors and while applying for internships during my first year, I always wanted to do DS. This was primarily based on a misconception however. 

During my bachelors I was not serious about coursework or coding, not in the slightest. It was only when covid hit and I realized I’ll be going to the US soon, did I start looking into some actual coding stuff. Started off with Python and thought DS was all about pandas, numpy and scikit learn and decided this is what I wanted to do. Obviously as I started grad school and learnt more about the actual nuances of ML and DS, I realized I was nowhere near good enough with my foundations in stats and math. 

I do consider myself to be a problem solver though, so despite not having a great base and starting off with grad level concepts in school, I was able to get upto speed and score a good grade. 

After this, I landed my first internship in “Data Science” at a consulting firm. Through 3 months, all I did was a ton of web scraping and ETL operations. Applying traditional ML in litigation casework is not easy because eventually all cases or most cases end up in front of a jury. So I never got to apply all that math in a professional environment. 

Since then, the world went through a “recession” and I couldn’t even land a single other interview. Did another internship with these guys and switched my focus to development based cases. Started building dashboards in Javascript and backends in C#. The closest DS related work I have done is integrating Azure OpenAI LLM APIs into a VueJs frond end through a .NET backend. Did this for 2 reasons, one, web scraping and ETL was redundant and boring. Two, the manager in charge of those cases is awful, constantly undermining my credentials, never even making eye contact during a conversation, insanely condescending and even told me multiple times that he doesn’t believe I have 2 degrees in CS. 

Anyway, at this point, I have been doing this for about 10 months. Based on my work that has transcended into more software development, do you think I should exclusively apply to SWE jobs to find a way out? What could my options be? Also, does this kind of a resume where you jump from one tech stack to another hurt? I haven’t received any interviews in about a year. Wondering if this is the general state of the world or is something fundamentally wrong with my work exp and if I’m stuck where I am."
277,Data analytics leadership and imposter syndrome?,12,https://www.reddit.com/r/datascience/comments/178eum0/data_analytics_leadership_and_imposter_syndrome/,13,"Data analytics leadership and imposter syndrome?

I have found myself in and out of data analytics leadership roles in the past decade, mixed with hands-on data analyst work. I know I have some legit skills (eg, I have lots of experience in inferential statistics, research, can speak to the outcomes well, etc), but I can’t seem to shake the feeling of not deserving to be in a leadership position. For example, I recently hired a data analyst to expand my existing team and going through all the resumes showed me all the things that I can’t do (work in specific coding languages, predictive modeling, just to name a few). At several points, I asked myself why these people shouldn’t be MY boss because they clearly have to teach me lots of valuable skills. 

So please talk to me about the value-add of analytics leadership: what does a good leader bring to the table? Is it okay to not be able to do everything yourself? Is this imposter syndrome and do others recognize it?"
278,What is the best tool or way to measure uncertainties using machine learning ?,1,https://www.reddit.com/r/datascience/comments/178vkg9/what_is_the_best_tool_or_way_to_measure/,2,"I have a certain data that I measure the uncertainty via Monte Carlo, but I was wondering if there is a practical way to do that using machine learning."
279,Get masters if my bachelors is in data sci?,3,https://www.reddit.com/r/datascience/comments/178kwz8/get_masters_if_my_bachelors_is_in_data_sci/,3,I’m seeing a lot of people recommending people that have a degree in econ/cs/math to get a masters in data science or statistics. Will I need one if my whole bachelors is based in pure data science anyway?
280,Took me over a year but I finally got a data analyst job,132,https://www.reddit.com/r/datascience/comments/1780308/took_me_over_a_year_but_i_finally_got_a_data/,15,"Graduated summer of 2022 with a MS in Analytics after discovering the field by accident while exploring possible new fields, as I got burnt out from crazy hours at a previous database engineer role. I kept getting far in interview processes but never the role, although in hindsight I dropped out of a few interview processes that I maybe shouldn't have since I'd be the only analyst in the company. Finally got one this week, albeit as a data engineer/analyst supporting another analyst, right after taking a customer service role as I was giving up and planning on going to grad school next year for something completely different. Still processing this as I can barely believe it."
281,c3AI data scientist interview,2,https://www.reddit.com/r/datascience/comments/178neqa/c3ai_data_scientist_interview/,4,"Has anyone interviewed at c3ai? I've read there are 3 stages of b2b interviews: ML/stats fundamentals, pandas/numpy/python coding, case study. 

What kind of questions are asked, especially in the case study portion? what exactly does the coding part inolve? also for stats - is it enough to cover hypothesis testing, p-values, PCA, etc? 

Any insight is appreciated!"
282,Tips on Data Science Jobs Abroad,3,https://www.reddit.com/r/datascience/comments/178j8v9/tips_on_data_science_jobs_abroad/,0,"I am a 27-year-old guy who lives in the Netherlands and has about 2.5 years of experience in data science/software engineering. I've always dreamt of going on an international adventure and working abroad in Europe. Unfortunately, I have not yet been able to or have had the courage to take the leap. Now, with my girlfriend going on an exchange at the start of 2024, it feels like the perfect time to explore the possibilities of finding a job abroad.

I'm looking for tips, help, or experiences on how to tackle this big project. How do you start to look for jobs or projects? I know LinkedIn of course, but I'm wondering if there are also companies hiring people for a fixed-time contract. Or are there any businesses or platforms that connect job seekers with such companies? I'm uncertain about committing to an indefinite job, and I think for example a 6-month project might provide more security.

I'd appreciate any advice or stories that people are willing to share about their experiences working abroad. Thank you in advance for your support and wisdom!"
283,Price effect on room occupancy rate,2,https://www.reddit.com/r/datascience/comments/178l850/price_effect_on_room_occupancy_rate/,4,"Hello wonderful people,
I've been ask to study the effect of price on the final room occupancy rate for the hostels of my company.

So here are the data :
For a date (t), and for a specific room type, I have the occupancy Rate (OR, between 0 and 1), a set of categorical ordinal variables (total of 90 variables) that represent an indexed price of the room at a date (t-z). In other words, I know what was the indexed price of a specific room from the date being analysed back to 90 days before.

As I said, those exogenous variables are categorical ordinal. For example : PRICE1, PRINCE2... PRICE10, with price2 being more expensive than PRICE1. It is an indexed price in the sense that it drives the applied price on different booking network (booking.com, Expedia, our own website...)

How would you approach this subject ? I had in mind to try fitting an ARIMA model and look at the model parameters, but with the categorical ordinal variables, it would mean one-hour encoding and therefore having a huuuge dimensionality...

What do you guys think ? 💪"
284,"I am interviewing my future boss, what should I ask them?",30,https://www.reddit.com/r/datascience/comments/1784jir/i_am_interviewing_my_future_boss_what_should_i/,28,"As the title suggests I am going to be having 1-on-1 interviews with 3 candidates to replace my previous boss. Others within my team as well as higher ups will also be interviewing them separately. I will be given some instruction and there will be some coordination between all of us involved in this process. As this is a new experience for me (and likely a little unusual for most people to be choosing their boss), I am wondering if anyone has any suggestions as to questions that might be a bit outside of the basics you'd find on any old list of interview questions.   


For context, I have worked as a data analyst/data scientist/statistician (there isn't really a distinction between these roles in my area) for about 4.5 years now and have been in this current job for 2 years. I work in healthcare analytics with some of my work being straightforward research for the purposes of publication and other work with hospitals, governments, etc. trying to leverage their data to improve different aspects of their work and responsibilities. I am based outside of the U.S.A. and this is not for an American company FYI.

Update: Appreciate all the feedback. There were some really great responses in here that I will definitely be using."
285,What is the best tool/ way to make forecast using machine learning ?,0,https://www.reddit.com/r/datascience/comments/178vkrx/what_is_the_best_tool_way_to_make_forecast_using/,1,
286,Going back to school,1,https://www.reddit.com/r/datascience/comments/178kwzn/going_back_to_school/,0,"Hello!

I’m going back to school full time in the spring. I’m double majoring in data science and interactive media and getting my B.S. in both. I’m projected to be graduated by Spring of 2027. What internships should I start looking into and how far along in school should I start applying? I’m new to this field and have done alot of research into the type of jobs I can get but just wanted outside opinion."
287,Company building an LLM App. Need some understanding if my opinions are reasonable.,16,https://www.reddit.com/r/datascience/comments/1785em4/company_building_an_llm_app_need_some/,15,"I'm your generic mid-career data scientist who sometimes functions as an ML engineer. I've been tasked with advising a team building an LLM application to automate 'data analysis' for non-technical customers. My role is to bring some wisdom and system design expertise to the team. The team is compromised of two people: a young, eager software engineer who calls themselves a ""Langchain Developer"" and a senior technical director who believes in the macro trends around Generative AI and wants to learn more about applying the techonology.

The idea is a customer types a vague question in to a field  *e.g.* ""Is my business meeting my customer retention goals"" and the output would be a visualization of some descriptive metrics and an interpretation of the data.

The design presented to me by the Langchain developer sounds overly complex and a bit unhinged to me. I'm looking for an external opinion to make sure my opinions are well grounded or make sense.

1. This project is my first time using LangChain. From reading through the LangChain code,  and building some basic examples, the library feels over abstracted.  You have to navigate a tangled mess of private variables to even find the prompt the tool is using. I am *really* concerned about putting Langchain code in production since it seems difficult to debug and modify. Why can't we use a DAG or state machine instead?
2. The langchain developer doesn't present any systematic way to deal with hallucination. Generally, the strategy verbalized is too play ""wack a mole"" every time they see or measure a hallucination. If hallucinations are rare, then sure, and I'd be a bit more comfortable with this approach. But I've see no evidence that's the case.
3. The scalable ways to measure hallucination often use an LLM to judge it's own output. Generally, I try to avoid feedback loops between models. Is that too strong of an opinion to have when working with LLMs?

Appreciate the responses!"
288,Biologist (PhD) --> Data Scientist?,0,https://www.reddit.com/r/datascience/comments/178nz28/biologist_phd_data_scientist/,4,"I'm just starting a PhD in a life science field (at a top university, if it matters). I've been wanting to learn more about the data science field and whether having a PhD in a biology domain would be helpful for data scientists positions within biotech, healthcare, etc. I plan to complete a computational certificate that my program offers, and my thesis project should involve a good amount of data science on top of wet-lab work.

Would this be a good career path? Will not having a degree in computer science, data science, etc. put me at a disadvantage?"
289,From Lab to Live: Implementing Open-Source AI Models for Real-Time Unsupervised Anomaly Detection in Images,2,https://www.reduct.store/computer-vision/edge-computing/ai/Implementing-open-source-ai-anomaly-detection/,0,
290,Should I pursue a PhD,74,https://www.reddit.com/r/datascience/comments/177qnvc/should_i_pursue_a_phd/,79,"So I’m in my late 20s, I received a bachelor of science in math and a master of science in data analytics. I have been working as a “Data Science Consultant” for 2 years now. I really just don’t find the work challenging or interesting. My field of interests include NLP, Policy, Media, and International Relations (I know very niche). The data science market is terrible and I’m applying to jobs and getting a few interviews, but not roles I’m really interested in. I think I would really enjoy doing applied data science research, like how can we use data science, statistics, etc. to address this issue. The problem is all of these jobs I see are reserved for PhDs. I just keep going back and forth on whether this should be something I pursue or not. What would you all recommend for someone in my shoes?"
291,Looking for a tool for image recognition,2,https://www.reddit.com/r/datascience/comments/178bdnk/looking_for_a_tool_for_image_recognition/,0,"Hi, I'm looking for a tool to easily categorize a huge amount of images. Best case would be, if i could use the tool with a python library. Could you recommend anything?"
292,What do data scientist do when their data isn't reliable?,0,https://www.reddit.com/r/datascience/comments/178rqxf/what_do_data_scientist_do_when_their_data_isnt/,5," 

\#Apple, #Question, #Data\_Scientists,

What do data scientist do when their data isn't reliable? Looking for answers other than the easily Googled/ChatGPTed validate, clean, imputation, transformation, documentation, source investigation, quality assessment, etc.

\#Context, 

A project my team and I are working on we regularly release builds using Testflight. 

An observation is that Apple has incorrect analytics even within their walled garden from AppStoreConnect to TestFlight.

Specifically, in this screencast/video we can see that the version of the app which the App Store Connect dashboard says I've currently got installed is 1.0.1+26 which was installed today October 15th 2023.  


[https://youtube.com/shorts/Sc2NrvAKFlA?feature=share](https://youtube.com/shorts/Sc2NrvAKFlA?feature=share)

But at the beginning & end of the video, we clearly see that I haven't installed that version yet; I still need to update.

I accept data between differing aggregators being ""off"" no problem. 

\#Unpopular\_Opinion

However seeing this behavior within a platform/company which is the largest, most well-funded, arguably among the most technical in the world makes me doubt the value of data analytics/science.   


How can we be sure of our analysis if we can't be sure of our data? It's disconcerting.

Not trying to flame data scientists here, trying to figure out how to feel cause I do believe we have to have analytics/benchmarks to make informed decisions but this conundrum is causing cognitive dissonance.  


Looking forward to seeing everyones feedback.  
"
293,Finding ds job after life sciences degree,1,https://www.reddit.com/r/datascience/comments/178e7fp/finding_ds_job_after_life_sciences_degree/,3,"During my BSc biochemistry degree I realised that I’m much more interested in analytics and data science than pure science. My dissertation was about analysing existing mitochondria proteins databases for which I used R, excel and Prism. I graduated from university as adult (M27) and I’ve been a quality manager in a local coffee shop chain for the last two years. What are my chances to get into data science field without cs/math degree and what would be the best strategy to land a job? For context I live in the UK."
294,Do companies consider it cheating to Google/chat gpt stuff on hackerrank tests?,24,https://www.reddit.com/r/datascience/comments/177w76r/do_companies_consider_it_cheating_to_googlechat/,26,"Curious because I just took an assessment. Not like I googled the full question. I just had chat gpt fix some syntax issues and googled some functions I couldn’t remember the exact way to write. I think if they asked me about it, I’d just explain that’s what I did — same as when I’m writing code outside an assessment. But I’m curious what’s considered the norm in assessments for jobs.

Edit: there was nothing on the assessment that said either way."
295,Interested about cricket and data science ? Here is my new article on medium about building the IPl Win Predictor from scratch please have a look!!,1,https://medium.com/@harshsmj1504/ipl-win-predictor-analyzing-winning-probabilities-d9f4f38e0226,0,
296,Walmart Data Science Internship,1,https://www.reddit.com/r/datascience/comments/178csio/walmart_data_science_internship/,1,"Hey Guys , I have my Walmart first round karat interview next week .

Any tips would be helpful:)

Thanks in advance"
297,Comprehending Research Papers,1,https://www.reddit.com/r/datascience/comments/178byoc/comprehending_research_papers/,0,"Hi DS community, Was just wondering what are the approaches you guys take reading and comprehending Research papers and the maths behind it. I have developed a keen interest reading research; however, For me digesting the whole research paper takes a lot of time (5-6)hours. Since, I plan to go for PHD, this is the skill I want to polish the most. I was wondering, what approaches you guys take for the following.

*  Maths portion (which I enjoy I must say), here mostly I try to rederive the equations on paper to understand better. 
* The reference papers that I have to revisit to gain praticle insights about the research at hand ( most time I read them Abstract, intro, conclusion and diagrams to extract important insights only and other time I read them end-to-end.

Thanks again."
298,Warning to would be master’s graduates in “data science”,622,https://www.reddit.com/r/datascience/comments/17798wz/warning_to_would_be_masters_graduates_in_data/,291,"I teach data science at a university (going anonymous for obvious reasons). I won't mention the institution name or location, though I think this is something typical across all non-prestigious universities. Basically, master's courses in data science, especially those of 1 year and marketed to international students, are a scam. 

Essentially, because there is pressure to pass all the students, we cannot give any material that is too challenging. I don't want to put challenging material in the course because I want them to fail--I put it because challenge is how students **grow** and **learn**. Aside from being a data analyst, being even an entry-level data scientist requires being good at a lot of things, and knowing the material deeply, not just superficially. Likewise, data engineers have to be good software engineers.

But apparently, asking the students to implement a trivial function in Python is too much. Just working with high-level libraries won't be enough to get my students a job in the field. OK, maybe you don’t have to implement algorithms from scratch, but you have to at least wrangle data. The theoretical content is OK, but the practical element is far from sufficient.

It is my belief that only one of my students, a software developer, will go on to get a high-paying job in the data field. Some might become data analysts (which pays thousands less), and likely a few will never get into a data career.

Universities write all sorts of crap in their marketing spiel that bears no resemblance to reality. And students, nor parents, don’t know any better, because how many people are actually qualified to judge whether a DS curriculum is good? Nor is it enough to see the topics, you have to see the *assignments*. If a DS course doesn’t have at least one serious course in statistics, any SQL, and doesn’t make you solve real programming problems, it's no good."
299,Supercharging Reinforcement Learning with Logic,2,https://www.reddit.com/r/datascience/comments/1786d5a/supercharging_reinforcement_learning_with_logic/,1,"Deep reinforcement learning has led to a variety of compelling results.  However, performance issues, particularly relating to the data efficiency of simulation has limited it applicability in domains where simulations run more slowly.  Our solution is to use a logic base framework, PyReason, as a proxy for the simulation.

&#x200B;

https://preview.redd.it/x7050xg2baub1.png?width=1786&format=png&auto=webp&s=14929e5614404808c85d48922e0af947f8d52b90

We showed that inference with PyReason logic program can provide up to a three order-of-magnitude speedup when compared with native simulations (we studied AFSIM and Starcraft2) while providing comparable reward and win rate (we found that PyReason-trained agents actually performed better than expected in both AFSIM and Starcraft2).

&#x200B;

https://preview.redd.it/k1ntxyh3baub1.png?width=1636&format=png&auto=webp&s=bdf0bb030a0a4d38034460d52940593e6a57cb32

However, the benefits of our semantic proxy go well beyond performance.  The use of temporal logic programming has two crucial beneficial by-products such as symbolic explainability and modularity.  PyReason provides an explainable symbolic trace that captures the evolution of the environment in a precise manner while modularity allows us to add or remove aspects of the logic program – allowing for adjustments to the simulation based on a library of behaviors. PyReason is well-suited to model simulated environments for other reasons – namely the ability to directly capture non-Markovian relationships and the open-world nature (defaults are “uncertain” instead of true or false).  We have demonstrated that agents can be trained using standard RL techniques such as DQN using this framework.

Preprint: [https://arxiv.org/abs/2310.06835](https://arxiv.org/abs/2310.06835)

Video: [https://youtu.be/9e6ZHJEJzgw](https://youtu.be/9e6ZHJEJzgw)

Code for PyReason-as-a-Sim (integration with DQN): [https://github.com/lab-v2/pyreason-rl-sim](https://github.com/lab-v2/pyreason-rl-sim)

Code for PyReason Gym: [https://github.com/lab-v2/pyreason-gym](https://github.com/lab-v2/pyreason-gym)

PyReason home: [https://neurosymbolic.asu.edu/pyreason/](https://neurosymbolic.asu.edu/pyreason/)"
300,AI-based Research tool to help brainstorm novel ideas,1,https://www.reddit.com/r/datascience/comments/1788uk9/aibased_research_tool_to_help_brainstorm_novel/,2,"Hey folks,

I developed a research tool [https://demo-idea-factory.ngrok.dev/](https://demo-idea-factory.ngrok.dev/) to identify novel research problems grounded in the scientific literature. Given an idea that intrigues you, the tool identifies the most relevant pieces of literature, creates a brief summary, and provides three possible extensions of your idea.

I would be happy to get your feedback on its usefulness for data science related research problems.

Thank you in advance!"
301,Embed multi-dimensional data points for visualizing and inserting a new data in the plot,1,https://www.reddit.com/r/datascience/comments/1787v23/embed_multidimensional_data_points_for/,0,"Say, I have an N group of students. And I have their normalized test scores for 8 subjects from 0 to 1. 

I want to create a model that can put the data points into 2D plot showing which students are similar to each other. I will show the visualization of the data points.

Lastly, if someone gives their data point, I want to show them where they are in the plot, show which students are most similar to the new data point.

Which amongst PCA, tSNE, UMAP is suitable for this? Or are there other options like VAEs for tabular data?

The new data point is a test point and the N group of students are the training points."
302,Does the big 4 tag really matter?,0,https://www.reddit.com/r/datascience/comments/1786ci4/does_the_big_4_tag_really_matter/,12,"So basically is a data analytics job (SQL and power bi viz) is better than a data scientist job (hands on python, model building and cloud) at a national company ?


Or just joining the big 4 in hopes of getting promoted to a job with more hands on coding is the right way to go?"
303,Why do we maximize likelihood of theta in logistic regression?,7,https://www.reddit.com/r/datascience/comments/177rzkj/why_do_we_maximize_likelihood_of_theta_in/,10,"Very new to the topic.  
I do not understand why we want to maximize the likelihood of the parameter theta: isn't the likelihood we care about just the likelihood of output y? What is the point of maximizing the parameter's likelihood?

Apologies if this is a silly question and thank you so much for your input"
304,Do you also often deal with problems that turn out to be some kind of constrained optimisation problems?,28,https://www.reddit.com/r/datascience/comments/177k8pw/do_you_also_often_deal_with_problems_that_turn/,16,"I've been working in the role of a data scientist for about 3 years at a large corporate. My training is as a physicist. I'm often involved in early stage proofs-of-concept for different departments so we're often in exchange with ""innovation managers"" whose role is to find use cases for ""AI"", as they call it. As a result, I often get pitched ideas for new projects from those managers.  


Now, upon closer inspection, many of these problems involve, at their technical core, an optimisation problem, where an objective function has to be optimised in the presence of constraints. I find these problems intriguing but I usually feel overwhelmed tackling them, as I lack the training to deal with them and I feel there is no good tooling around to help me model them, not to mention choosing and tuning the solver, benchmarking and then finally bringing them in production. 

As a result (and also for other reasons), those projects usually don't get realised.

I wonder whether others here face the same challenge or whether this is particular to me and if there are others, how you deal with it. Thanks"
305,"In 1 year of data science in college, what do you guys learn? Let me know!",0,https://www.reddit.com/r/datascience/comments/1788zxi/in_1_year_of_data_science_in_college_what_do_you/,8,
306,How to handle incompetent manager while looking for another job,31,https://www.reddit.com/r/datascience/comments/177ifms/how_to_handle_incompetent_manager_while_looking/,21," 

I work in a large federal government agency, and regrettably, I have an extremely incompetent manager who spent many years working on dashboarding before being promoted to lead our team. My manager lacks any prior experience as a data scientist, data engineer, or machine learning engineer and is unwilling to learn in these areas. Given the nature of government employment, the likelihood of termination or layoffs is exceedingly low. The organization comprises both employees and contractors with the title of ""data scientists,"" but there's no clear plan on how to utilize their skills effectively. Additionally, our data governance and data quality processes are almost nonexistent.

There is a  significant fraud problem resulting in multimillion-dollar losses. One of the major challenges is that there are multiple definitions of fraud within the organization, making it nearly impossible to get straight answers when seeking guidance from supposed subject matter experts. Furthermore, various teams within the agency have different agendas when trying to address the fraud problem.

The CIO has recently directed us, likely influenced by management consultants, to use machine learning to solve the fraud problem. Nevertheless, it's apparent that there are many low-hanging fruit solutions, like process changes, that don't require machine learning and could significantly alleviate the issue.

Now, our manager is pressuring our team to build a machine learning model to supposedly save X millions of dollars. It appears that many people here are more interested in showcasing flashy tools and ideas to the directors and CIO, rather than delving into the details of the problem. Some of the other data scientists are demonstrating the use of complex machine learning techniques without truly understanding the problem statement or the models they are building. To make matters worse, we don't even have a clear, agreed-upon estimate of how much money we are losing.

In this chaotic environment, the manager wants us to build a model simply because someone in another team has done something similar. Our manager is focused on marketing and doesn't seem to care about the necessary details. I've suggested that we should invest time in understanding the data and conduct a feasibility study to determine if machine learning is an appropriate solution before committing to creating elaborate models. However, my manager either doesn't grasp the importance of understanding the data or simply doesn't care. Today he said I want each of you to build a model and compare results.

I know that the right thing to do is to leave the company or the team, and I am actively working on it. In the meantime, how can I handle this situation in the best possible way?"
307,What are the best data science courses for curriculum in US?,0,https://www.reddit.com/r/datascience/comments/1786ftu/what_are_the_best_data_science_courses_for/,0,"I’m planning to live in NY, and wanted to known the best online or live short courses , pos graduation courses and/or masters related with data science , and possibly with sustainability as well?"
308,Need help in my senior project,0,https://www.reddit.com/r/datascience/comments/1781xnk/need_help_in_my_senior_project/,0,"I am graduating soon in a Bachelor in DS and I am starting early on my senior project, it is my first complete DS project I'll be doing so I am sure I would be facing concerns and struggles throughout this project, I have been taking taking some online courses apart from university so I have some basic knowledge to start with, and I am confident that I can get all the necessary data for this project and preprocess it to begin the analysis. 

I just need a data scientist with some decent or more experience that I can contact and use his/her help while pursuing my project (AKA a mentor) , I know most of you guys are busy most of the time, I am not asking to teach me how to crawl or to handle my project yourself, I will only be asking questions for clarifications and using your opinion and review on the progress of my project. 

Yes there exist chatgpt and of course I'll be using its aid, but it won't help me as much as a data scientist who had enough experience to handle real world projects to check the quality of my work. So I hope whoever of you guys is down to help to let me know in the comments, and thanks in advance :) 

The project is about a football team's probability to win the league, the data will be gathered based from the performance stats of the team in the first half of the season, and I'll analyze it to forecast the performance in the next half and calculate the chance of my selected team winning the league upon its rivals which of whom's data will also be considered throughout this project. 

Again thanks in advance for anyone that would be down to help me, I am patiently waiting for your response in the comment section of this post :) or you can contact me directly if you want and I would be very greatful. Peace ✌️"
309,What are good questions to ask in interviews to validate the quality of your future boss?,95,https://www.reddit.com/r/datascience/comments/1778u49/what_are_good_questions_to_ask_in_interviews_to/,32,"Not many people pay attention to this even though most people know that when you are interviewing for your next data scientist roles, you are also interviewing your next boss!

You've done a great job answering all the technical questions, but asking good questions are also critical but not much effort was put into this is what I've seen typically. 

So what are some good questions to ask your next prospect boss?

As a hiring manager myself, here are some of my favorite questions from my best candidates:

**To learn more about the day-to-day:**

* What's the day-to-day like for you (or for a data scientist on your team)?
* What percentage of your time (a DS on the team) is spent on coding?
* What percentage for other tasks? And what are those tasks?

**To learn more about ownership:**

* How are projects assigned across the team?
* How do team members collaborate?
* How is the scope of a project typically determined? 

**There are more you can ask to learn more about scope of projects and to learn more about room for adaptability:**

More detailed questions here:

[https://mlnotes.substack.com/i/106670575/questions-you-can-ask-in-an-interview](https://mlnotes.substack.com/i/106670575/questions-you-can-ask-in-an-interview)

What did you ask that got you great insights about your interviewer? 

&#x200B;"
310,Can I get a UK perspective on how important personal projects are for beginner data analyst roles?,1,https://www.reddit.com/r/datascience/comments/177zdxe/can_i_get_a_uk_perspective_on_how_important/,1,"I have a degree in computer science and 1 year of experience as a data analyst done in the middle of my degree. Looking online a lot of the advice on standing out recommends doing personal projects. However, it also all seems very US-centric. Data analysts from the UK, how important do you feel personal projects are to get hired for beginner roles?"
311,What is the best UI creator for DS projects?,0,https://www.reddit.com/r/datascience/comments/177yjgm/what_is_the_best_ui_creator_for_ds_projects/,0,"Im new to the Data science community and just started my first job as a robotics engineer. 

Im wondering how I can take my data science skills to the next level and so Ive made [this showcase](https://visualstudycode.com/stochastic-gradient-descent-for-robotics/) on stochastic gradient descent for robotics, as the first step in visualization and UI experience. Let me know your thoughts!"
312,Data Science Scoping Questions (Looking for feedback from DS consultants),3,https://www.reddit.com/r/datascience/comments/177r3bk/data_science_scoping_questions_looking_for/,0,"Hi everyone! I work in the consulting arm of a data science software company. I scope data science projects with my clients regularly using the following questions. Would love some feedback if there is anything missing/I should be asking them in a different way:

Questions about client

* What is your project budget?
* Describe your familiarity with data science and data analytics
* Describe the nature of your business (feel free to include any links to your website)

Questions about the project

* What are the main objectives you want to achieve with this project? Try to be as specific as possible, using numbers
* Describe the current situation (without this project)
* Describe the envisioned situation if the project is a success (e.g. how will you use the project output?)
* Who will benefit from the most from this project? Who else will be impacted?

Questions about the data

* Describe the nature of your data in your own words. (prompts include how do you normally access this data? How is it normally used?)
* What data sources do you have for this project? Where do they come from?
* Are there any public data sources that might help?
* In what format is the data available (e.g., CSV, Excel, SQL Database)?
* Would you consider your data structured, semi-structured, or unstructured?
* How much data do you have (e.g. rows, records, or file size)
* Is it possible to collect more data? Would it be difficult to do so?
* Does your data need to be labeled? If so, what is the corresponding effort?
* How would you rate the quality of the available data? Are there any known issues? (missing values, conflicts, outliers, reliability)
* Please send over an example of your data if possible

Other questions

* What is your current technical set-up? Describe the tools you currently use may be relevant to the project
* Do you foresee any technical integration requirements?
* Is there any additional information or specific requirements that have not been covered? (cybersecurity, data privacy, ethical considerations)

&#x200B;"
313,What’s the best AI tool for statistical coding?,0,https://www.reddit.com/r/datascience/comments/178744m/whats_the_best_ai_tool_for_statistical_coding/,4,"Is git copilot going to be a major asset for stats coding, in R for instance?"
314,Question on School options,1,https://www.reddit.com/r/datascience/comments/177xuon/question_on_school_options/,3,"Hey there! 

I'm currently transferring to Indiana University Northwest in Spring 2024 from a community college for my Data Science degree and got an internship next summer. 

The thing is I also applied to UIC and got rejected with some weird reasoning but after talking to a faculty member, they were recommending I take a break and apply again in the summer to undecided and then transferring into the Data Science program.

I'm wondering if I should consider transferring to UIC instead and also if that hinders my internship for Summer 2024."
315,"In your time working with data science at a corporation, what cool things did you pick up / learn that school didn't teach you?",108,https://www.reddit.com/r/datascience/comments/1775fq0/in_your_time_working_with_data_science_at_a/,64,Can't wait to read your comment!
316,It's been two months since I was laid off as a DS. Any advice on how to deal with current market.,127,https://www.reddit.com/r/datascience/comments/177479m/its_been_two_months_since_i_was_laid_off_as_a_ds/,84,"Two months ago, I was laid off from my role as a data scientist after 2 years. It was ""reduction in force"" and my role was affected. 

Some background:

* Previous Role: Data Scientist 1
* 2 yrs of xp, master's in statistics
* Had a big tech company as long term client at previous role (13 months)
* I was in top 10% of performers (98% billable hours and internal recognition for innovation)
* Was confirmed for promotion.

It took me 5 years of studying and interviewing to get to my first position with this company, worked my butt off to get the long term client, and now I'm laid off. What should I do about this market? I barely see any positions open for someone like my self."
317,Do I need more statistics?,2,https://www.reddit.com/r/datascience/comments/177q65k/do_i_need_more_statistics/,3,"Hello everyone,

&#x200B;

I'm relatively new to the field of Data Science, with approximately 6 months of experience. Prior to this role, I worked as a Machine Learning Engineer for a year and a half.

In my current position, I spend a significant portion of my time conducting data analysis, applying basic statistical techniques (hypothesis testing, regression analysis, etc), and developing standard banking models (so far, I've worked in churn rate prediction, client clustering, and currently studying to help building a recommendation system)

I'm currently pursuing a Master's degree in Computer Science, with a research focus on weather forecasting. This research involves the use of time series analysis and machine learning. As we progress in our research, we are also delving into deep learning models, the goal is to build state of art models.

My academic background is in computer science. In both bachelor's and master's I've completed classes in basic linear algebra, three levels of calculus (up to Multivariate Calculus and First Order Differential Equations), discrete mathematics, two statistics courses, one time series analysis course, and several classes focused on machine learning algorithms and artificial intelligence.

While I generally have a good understanding of the mathematical principles behind machine learning models, there are certain areas where I struggle. For instance, I've never fully comprehended why the kernel trick is effective in SVMs (got the intuition, but not the maths)

When it comes to statistics, I feel that my knowledge is lacking. I can effectively work with machine learning frameworks, but there are specific statistical topics where my knowledge is either superficial or non-existent. These include:

&#x200B;

* Post hoc analysis
* Survival analysis
* Multivariate statistics, such as PCA, MANOVA, and Factor analysis
* Markov Processes

Given my current role and academic pursuits, I'm wondering if it's essential to address these knowledge gaps immediately or if it would be more practical to focus on completing my Master's degree first.

I would greatly appreciate any guidance on how to begin studying these statistical concepts effectively."
318,Hourly salary Data Scientist Canada,24,https://www.reddit.com/r/datascience/comments/177cfpy/hourly_salary_data_scientist_canada/,14,"I got contacted by a recruiter today for an immediate hire for an ""Intermediate level data scientist"" at an energy company in Calgary. This would be a contract position for one year, full-time, hybrid (2 days from home per week), and required 5 years of experience.

The salary was 46.5 CAD/hour, no benefits and required you as a contractor to be incorporated.

I have a PhD, a completed post doctoral position, over 3 years of work experience as an independent contractor in a variety of industries as a data scientist and was honestly surprised by the low hourly rate. The majority of my clients have not been from the energy sector though, so maybe this is why?

After mentioning that this was below the hourly rate that I would consider a position, comparing this to a base salary of a full time employee coming with benefits such as healthcare, pension plan, paid time off, etc, while also not requiring the overhead of costs you have as a incorporated business in regards to bookkeeping, invoicing, taxes, etc, the rate was increased to 47 CAD/hour. 

I thought I'd throw it on here to keep these kind of salaries transparent and see if other Calgary/Canada-based data scientists have had similar experiences in this job market."
319,How much stock would you put in Andrew Ng's ML/DL course?,1,https://www.reddit.com/r/datascience/comments/177qw2v/how_much_stock_would_you_put_in_andrew_ngs_mldl/,9,"Hi! I have a Bsc (Honours) in Applied Mathematics, and I have done various courses on Udemy on ML and DL by SuperDataScience. I have also done some self work on Kaggle.
I am currently a Robotics Process Automatiom (RPA) developer. I'd love to move into the DS/ML/DL/AI space. I do of course use some AI tools within my automation solutions. I miss doing the Mathematics though. I really loved studying it.

Anyways, it's been a while since I've done any studying or self-work in the AI space, and I was wondering what your thoughts on the renowned Andrew Ng Deep Learning course are? I know I'd really enjoy doing it, but how much would it help me in getting closer to a job in the AI space?

Note: I haven't done any mathematics for quite a few years, as a I graduated end of 2018, so I would also need to spend sometime relearning some of the work I learnt in my degree. I also do not want to go into academia, despite my love of research, because it often involves lecturing (which I dislike) and it will generally not pay as well - I want to have enough money to live a comfortable life and travel the world.

Thanks"
320,Choosing the Right Academic Path for Job Security and Career Growth in Europe,1,https://www.reddit.com/r/datascience/comments/177q2t2/choosing_the_right_academic_path_for_job_security/,5,"After spending considerable time researching on the Data Science (DS) field, I've noticed two significant challenges: 

1. The difficulty of breaking into DS as a fresher 
2. The necessity for a specialized niche in a particular domain, such as healthcare or business, which often requires prior field experience or a related bachelor's degree.

I'm a final year bachelor's in Technology student (specialization-Information Technology ) and possess average coding skill. My aspirations involve pursuing higher education and professional opportunities in Europe, particularly in German universities.

Despite some institutions prioritizing revenue generation and offering below average DS programs(as repeatedly mentioned in this sub), low cost German public universities offers numerous DS programs taught in English, welcoming international students. Personally, I'm drawn to the profound impact DS can have on decision-making processes (specifically policy making), which makes it a very rewarding field.

I'm at a crossroads between pursuing a Master's in Computer Science (CS) with a DS track or opting for a specialized Data Science degree. Which academic path would provide more job security and a stronger foothold in the European job market for a background like mine?

There are some courses that have intersection of two disciplines like policy making and DS. Will those courses limit me to certain domain and thus affect my chances of getting jobs? or Will the specialization in a field actually be more beneficial?

Furthermore, I'm curious if I can smoothly transition into DS roles after gaining several years of experience working with other technologies in the IT sector.

Thank you in advance for your time and guidance!"
321,"What were the worst misconceptions/requirements of senior management in data science projects in connection with web applications (lead generation & churn, content generation, data driven marketing, etc.)?",1,https://www.reddit.com/r/datascience/comments/177lhhw/what_were_the_worst_misconceptionsrequirements_of/,2," TL;DR: **Biggest fails and your most loved data science solutions** in **web related applications**, which you have experienced **in your data science career**.

*(Similar posts were previously removed for unclear reasons, so I have reworded the post. Please let me be clear: this is not a homework exercise, nor is it breaking any other rule in my opinion! My last attempt...)*

I  am just curious in your personal data science experience of common web  applications like e-commerce, lead generation, web marketing and so on.

Upper   management often wants solutions or applications which have a positive  imapct in selling products, gaining more customers or at least improve  existing products and services which can be used in marketing. And you  know, sometimes it's all about slapping the ""AI"" label on products.

What  were the worst misconceptions/requirements of senior management?  In  contrast: What unexpectedly  worked well? I.e. Data may be very limited  on training due to data  protection rules, but still lead to ""good""  models which are production  ready.

In  my experience it was not  a big deal to produce a working model. But I  failed to deploy or  integrate the model into an existing solution. The  guys which were  responsible to implement the model api failed to  present the results in a  nice way or the UX was just terrible.

Another  fail requirement: ""generate automatic A/B landing pages in a web  application"". So the requirement was to automatically generate different  versions of landing pages based on the visitor flows (or origin  parameters: organic vs direct hits). It would be technically possible,  but imho at least 2000h of work ot get good results.

I look forward to an exciting exchange of experiences!"
322,"For binary classification, where the focus is to avoid FP, can you help with which metrics to use?",2,https://www.reddit.com/r/datascience/comments/177ffq9/for_binary_classification_where_the_focus_is_to/,8,"I hope it's ok for me to ask questions here, please point me elsewhere if that's not the case.

I have a binary classification model for identifying profitable trades, and I have just learned how AUC works (which took my smooth brain a lot longer than perhaps it would for you fine folk).

Anyway, would someone mind providing some pointers about which Classification metrics (Accuracy, AUC are the ones I already know) would be beneficial to understand, when comparing and understanding models? Or is AUC the de-facto standard?

I'm reading books on this topic, but finding that it can be difficult to follow.

Thanks"
323,"Customer Growth Accounting (churn, resurrections, etc) framework",2,https://www.reddit.com/r/datascience/comments/177dfyv/customer_growth_accounting_churn_resurrections/,0,"Does anyone have a good resource to share that lays out customer growth accounting framework (churn, resurrections, etc), and how it's used?"
324,How does your team organize ideas?,3,https://www.reddit.com/r/datascience/comments/1778xvq/how_does_your_team_organize_ideas/,3,"While I understand that some industries have a pretty shallow pool of ideas, what do those with a lot of ideas use to organize them into a way that allows project tracking and or understanding relationships between them?"
325,Demand forecasting FMCG company,2,https://www.reddit.com/r/datascience/comments/177b4po/demand_forecasting_fmcg_company/,19,"Hello guys,  im kinda new in the data science area,  i was wondering what might be the best approach to tacle a demand forecasting  per sku project for the next 6 months in an fmcg distribution company , i have the sales per customer per sku per salesman for the last 2 years ( daily) but i prefer to give more weight to the last year data since its very different fot the previous one.

Ps: the customer data is not always accurate since the salesman can sometimes close a sale with partner A and pass it as its customer B , so the sale quantity per sku is always correct, the customer not always (75% accurate)

Thaanks in advance!!"
326,"Got hit with a layoff today but they offered to shop me around internally, any advice?",87,https://www.reddit.com/r/datascience/comments/176nzqe/got_hit_with_a_layoff_today_but_they_offered_to/,45,"I ended up getting laid off today from my role as a data scientist after a little more than a year. It was framed as a ""reorganization"" by a higher up and that my role had been eliminated.

Anyways, they offered to help shop me around to some other internal teams and I'll be meeting with two other DS managers in the next week. Before I meet with them, I was wondering if anyone could offer any advice for the situation and how to proceed. I'd really appreciate it.

Does anyone have any advice for how to use these meetings to their fullest, and maximize my chance of landing another role? How direct should I be about wanting to join their teams? I know my biggest selling point is that there's no training period, I'm already familiar with all the datasets and industry. I'm going to spend tomorrow trying to summarize all the work I've done at the company since I got hired.

Some other key details below:

- Was told I was rehire eligible. They specifically said that severance wouldn't be impacted if I boomeranged unless I switched teams before final date (1 month).
- Worked for over a year and have 2.5 years of experience in data science.
- Probably was on the bottom half of performers, but I wasn't the worst. I was the most recent hire though. My boss's boss offered to write a letter of recommendation, probably was a casualty of money, seniority, and not being a top performer. Was given a large new project two weeks ago.
- The company is large but has a small amount of tech and is about to lose a lot of money in the coming year. Could be a negative for staying if I find a new role.

I'm going to keep the ranting to a minimum because this post is pretty identifiable, but I'm honestly at a loss of what to do. I moved across the country for the role (in-person) and turned down a higher paying offer as a quant. I finally got an ounce of stability after not having any for years and I got laid off without even a PIP or a warning. I guess that's life but god damn."
327,What are the best practices for interviewing data science candidates?,7,https://www.reddit.com/r/datascience/comments/1771460/what_are_the_best_practices_for_interviewing_data/,6,My experience as a candidate wasn't always great and I often felt that interviewers just asked random qs. I was wondering if any experienced interviewers can share their best practices to gauge a candidate's technical aptitude and work ethic on the job.
328,Jobs to switch to from Data Science,86,https://www.reddit.com/r/datascience/comments/176ndbd/jobs_to_switch_to_from_data_science/,62,"I’ve been in data science about 3 years and I’m just miserable coding day in and day out. I’ve applied to some manager jobs but haven’t gotten and the ones that I have been offered pay less than what I make now.

I’m looking for something more business facing, that could be a good career transition for someone who enjoys tech but doesn’t have his heart in programming after doing it since college 9 years ago, and doing it daily since."
329,Holdout Experiments,1,https://www.reddit.com/r/datascience/comments/177dgos/holdout_experiments/,0,Does anyone have a good resource to share on long term holdout experiments and what they're used for?
330,Book recommendations about Descriptive Statistics for an Economics freshman.,2,https://www.reddit.com/r/datascience/comments/1778n6i/book_recommendations_about_descriptive_statistics/,0,"Good day to everyone.  I started taking a course called ""Descriptive Statistics"" at university and I want to improve myself outside of class.  The professor recommended Cleff's ""Exploratory Data Analysis"" as a reference book, but I would also like to hear your opinions.  Thank you."
331,I want to improve more!,3,https://www.reddit.com/r/datascience/comments/1773x9b/i_want_to_improve_more/,1,"Hi everyone,



First time posting here so not sure this is where it belongs.



I do crime intelligence with data analytics at university and was lucky enough to score an internship. However, I've not had much experience in SQL or Power BI, neither of which the internship need either.



I wanted to do a small project on the side to play around with these and learn some more. Can anyone help me with some ideas, or even just a starting point for this?



Nothing to publish, solely extra academic learning I can play with. Thanks !"
332,James Lamb (Light GBM) on getting into open source from a data science background,4,https://open.substack.com/pub/onceamaintainer/p/once-a-maintainer-james-lamb?r=2773u5&utm_campaign=post&utm_medium=web,0,
333,Fraud Detection Machine learning project,2,https://www.reddit.com/r/datascience/comments/1772in6/fraud_detection_machine_learning_project/,1,"https://preview.redd.it/ha6kw13ewztb1.png?width=966&format=png&auto=webp&s=53c4b89cb5c003c689a1b0b1a62c8902e907c8df

&#x200B;"
334,How ballsy do you have to be to take on the role of Senior Data Scientist at both McDonald's and Burger King simultaneously (remote),300,https://www.reddit.com/r/datascience/comments/17666j9/how_ballsy_do_you_have_to_be_to_take_on_the_role/,124," If you were presented with such an offer for a remote position, would you accept it? Is there a risk of legal consequences if you were discovered? "
335,Guidance on Language Model,0,https://www.reddit.com/r/datascience/comments/1775rtq/guidance_on_language_model/,5,I want to utlitze a gpt like language model for my company. I want to bascially search for patterns in data and notifiy us if their is an anomoly.  Does anyone know of any good resources to learn how to do this?  I'd preferably like to use an offline language model or one that would be safe to put in our code
336,Fetching User Details for Triggered AWS Glue Job,1,https://www.reddit.com/r/datascience/comments/1775qrn/fetching_user_details_for_triggered_aws_glue_job/,0,"I'm implementing a data lake architecture on AWS, storing raw data in the bronze layer and transformed data in the silver layer. During the storage of data in the silver layer, I would like to append additional columns to hold metadata details such as ""created by"" and ""last modified by."" For AWS Glue jobs, I want to retrieve details about the user who triggered the job. I'm aware of CloudTrail's Lookup Events API, but I'm looking for an alternative approach to retrieve this information from the server-side without using a client library."
337,Guidance to analyze data reliability and variables related,2,https://www.reddit.com/r/datascience/comments/176yuks/guidance_to_analyze_data_reliability_and/,1,"Hello guys and girls,

I'm a State Veterinarian Officer in Brazil and work in a public agency that has as goal prevent, control or erradicate some diseases related to farm animals. In order to do that, we apply measures like restrict animal movement, culling, take samples, among others.

All this measures relly on a database system of all farms, animals movements between them and records of borns, deaths and other occurences. This database is mostly filled with information provided by farmers, what we call declaratory data.

But to ensure the quality and reliability of this data, one of our tasks is inspect farms in loco to correct any wrong or incomplete information. 

So, I have this database with data not audited and data audited with it's outcomes: data needed to be corrected and don't.

We want to optimize this auditions by analysing the data and find wich farms are proner to have misleading data throught comparations to variables like: quantity of animals, quantity of animal movements, region, age of farmers, etc

So I would like advice to how to approach this problem. Like: methods, books, papers, authors, really, anything helps. One of major problems I see is, although I have outcomes to inspected farms, it's not representative as it's not a random sample, so how to look to it? 

Obs.: I have skills with R, SQL and a bit of Python. And already conducted a project in my master degree with INLA.

Thanks in advance."
338,How to Perform Monte Carlo Simulation on the Stock Market,0,https://www.youtube.com/watch?v=O3K4nrXyqwc,0,
339,What is a personal side project that you have worked on that has increased your efficiency or has saved you money?,55,https://www.reddit.com/r/datascience/comments/176de18/what_is_a_personal_side_project_that_you_have/,38,"This can be something that you use around the house or something that you use personally at work. I am always coming up with new ideas for one off projects that would be cool to build for personal use, but I never seem to actually get around to building them.


For example, one project that I have been thinking about building for some time is around automatically buying groceries or other items that I buy regularly. The model would predict how often I buy each item, and then the variation in the cadence, to then add the item to my list/order it when it's likely the cheapest price in the interval that I should place the order.


I'm currently getting my Masters in Data Science and working full-time (and trying to start a small business....) so I don't usually get to spend time working on these ideas, but interested in what projects others have done or thought about doing!"
340,Traffic Data Source for Senior Project,1,https://www.reddit.com/r/datascience/comments/1771jsh/traffic_data_source_for_senior_project/,1,"Hi All, 

I am doing a project that involves vehicle traffic data and need to know where I can find information regarding how many cars pass by a certain address (a restaurant) or nearby intersection or coordinate point, so I can estimate sales (how many customers does the store get vs how many cars pass by, etc.).

I have store sales & customer but need the traffic data. 

How would one go about finding this information? I am okay with paying a modest amount for access to a database if I have to but would prefer other avenues (Google Maps API and the like?).

I tried government data and websites and the information is available but not to the public and it isn't quite the information needed. 

Welcoming all suggestions, thanks everyone!"
341,"📊💡 Dive into a comprehensive guide on Multilinear Regression Model, covering each stage from data collection to evaluation! 📈🧪",5,https://www.youtube.com/watch?v=SHa-58-n6ew,0,
342,Ocean protocol,0,https://www.reddit.com/r/datascience/comments/1777d0q/ocean_protocol/,0,What do you think guys -> [https://twitter.com/Cesar\_Ges/status/1712541730053173280](https://twitter.com/Cesar_Ges/status/1712541730053173280)
343,"If you were starting over again, How would you go about getting a Data Science job?",103,https://www.reddit.com/r/datascience/comments/1763k33/if_you_were_starting_over_again_how_would_you_go/,66,
344,Seeking Recommendations for Multivariate Time Series Analysis Resources with a Focus on Economics/Finance and R Applications,2,https://www.reddit.com/r/datascience/comments/176t8at/seeking_recommendations_for_multivariate_time/,3,"Hello everyone,

I recently completed **Hyndman, R.J., & Athanasopoulos, G. (2021) Forecasting: principles and practice, 3rd edition**. It's a great book for introducing time series analysis and forecasting in general and has in-depth examples with univariate time series analysis and forecasting exercises. It also introduces multivariate forecasting techniques briefly with dynamic regression models touching on VAR models. I wanted to continue on this and move on to understand multivariate time series analysis and modelling. Specifically, I'm looking for sources that focus more heavily on economic or financial time series analysis. Could you recommend any **books or video materials that also have comprehensive applications demonstrated in R for this (video lectures for this topic would be especially welcomed)**? Also, how much mathematics would be needed for the above material, and are there sources with less math-heavy content?"
345,How much of an effect does this job market have on people who were Data Scientists for a solid 3-5 years?,50,https://www.reddit.com/r/datascience/comments/1767l3b/how_much_of_an_effect_does_this_job_market_have/,25,Is it still as crushing for entry level. I have a clear shot at an entry level position so I know I will get an entry level DS job in a Fortune 100 company. But I want to know if it is typical for those of you with more experience to struggle to get a mid level to management job.
346,Guides that explore statistical theory and concepts through analysis in R using tidyverse,1,https://www.reddit.com/r/datascience/comments/176uhmx/guides_that_explore_statistical_theory_and/,1,"During my PhD, I got increasingly into statistical computing and greatly benefited from Andy Field's ""Discovering Statistics Using R"" book. This was particularly useful as my background is in biomedical sciences and clinical trials. I ended up doing my PhD secondment in a computational biology lab, where I was programming in R and python every day. It was here that I started leaning more on tidyverse for my R analyses.

  
Several years later, I've left the academic world and I am a consultant in the pharma industry. I really need to go back and recap some fundamental statistics. Can anyone recommend alternatives to Andy Field's ""Discovering Statistics Using R"", which uses the tidyverse package? I know Andy himself is currently re-writing his book to include tidyverse but this is taking years to be released.

  
As a secondary question / discussion point for those aficionados in the community: is it even a good idea for me to refresh my statistics knowledge through the tidyverse language? I know there is the debate in the community regarding base language vs tidyverse. But I don't know how much of that is reflective of the typical old generation vs new generation programmers. Thoughts?"
347,Alphanumeric Search Algorithm?,1,https://www.reddit.com/r/datascience/comments/176tcyw/alphanumeric_search_algorithm/,2,"I am facing a situation where I need to identify stores with very similar names within a radius of 100m from one another. Now, there are \~ 150k stores in the dataset.

I can distribute these into \~21k regions with varying number of stores (max \~5k) and search locally within and that aligns with the problem statement.

My current method involves:  
Loop for region  
Calculate distance of first store from all other stores  
Loop for each store  
dist col = dist col - dist store(current loop iteration)  
filter for dist col <= 150m

store\_ref = current loop iteration

check if dist (store\_ref and store in iteration <=100m)

if yes,

check similarity,

if similarity>threshold, add to list/dataframe

&#x200B;

&#x200B;

This is a 3 level loop of max \~21k \* 5k \* 600 iterations and is taking too long. 

I understand that there could be a possibility doing this using KNN/ANN, but would need some specific steps to be able to implement it. Please offer suggestions, if any?  
"
348,Explainable AI Scepticism,9,https://www.reddit.com/r/datascience/comments/176drw8/explainable_ai_scepticism/,6,"For context, I work in a regulated industry where model interpretability has a large emphasis, from both the business and regulators. We use a lot linear models, like OLS, logistic regression, and GAMs to account for non-linear relationships. Recently, some of the data science leadership has been pushing us to explore machine learning models to see if and how large the predictive gains are. 

Not surprisingly, XGBoosts, Random Forests, among others, show a small increase in predictive accuracy compared to the linear models, as we spend a fair amount of time fine tuning the linear models. 

However, we still need to show that we understand how these models are making their predictions and I have come to the opinion that most of the explainable AI techniques out there do a poor job of explaining anything meaningful about the model or the data. 

Things like SHAP values of LIME are okay in some instances with a stable model, but we've seen that they often show bizarre relationships. For instance two observations that are theoretically close to each other in the data generating process, are close to each other in data itself, are very different from each other in the model space. In addition, these local interpretation techniques really fail to show anything about the model globally. 

This blog post summarizes most of my thoughts clearly: https://randomeffect.net/post/2020/08/07/is-explainable-ai-anything-at-all/

Anyways, I guess what I'm asking is are there practicioners out there that hold a different view? Are there advancements in this space that I'm unaware of? I know there's a lot of effort going into the explainable AI space right now, but I'm pessimistic that it's even possible for us to have a good explaination for many models. Thoughts?"
349,Coding sometimes scares me. Is this the wrong field for me?,15,https://www.reddit.com/r/datascience/comments/1769ler/coding_sometimes_scares_me_is_this_the_wrong/,27,"I have been working as a ""Data Scientist"" for a little over 2 years but in my company I'm primarily tasked with developing MVPs with the company's  AI technology for potential clients. Most of the coding we do is setting up API calls, setting up environments, and connecting the different parts of the company's technology. I loathe this. Many calls people are sharing their screen showing this API call code and I absolutely cannot focus for the life of me. Mentally, I feel a huge friction/resistance to setting up a coding environment. 

In school, I took Mechanical Engineering and I was a pro making code to model engineering stuff and my programming logic was solid. I was the top of the class. But this environment set up stuff and API stuff just drives me insane.

I'm trying to figure out if the problem is with this role or if I just am better off in a non-coding role, like product management?"
350,Resources on Monte Carlo Simulations (Python),5,https://www.reddit.com/r/datascience/comments/176h4n3/resources_on_monte_carlo_simulations_python/,4,"Hi all,

I have a background in math + DS but little exposure to Monte Carlo methods. I find them interesting and potentially useful for my work and personal projects (sports betting models). I know the basics but am looking for more intermediate tutorials or literature that can educate me on how to build my own robust MC simulations in Python.

Thanks! Any advice would be appreciated."
351,Two different ways to execute Python code on an EC2 instance,1,https://medium.com/@hello_prism/running-a-python-script-on-an-ec2-instance-8691589b3080,0,
352,On handling multi-label/multi-value categorical features and high cardinality.,1,https://www.reddit.com/r/datascience/comments/176ojaz/on_handling_multilabelmultivalue_categorical/,3,"Hi all, I'm working on a binary classification problem with all input features being categorical (and nominal).

The problem I'm facing is that each input example can contain multiple values of a feature and there are too many different values.

(For example, multi-value feature being a 'Hobbies' feature that contains a list of strings:

>data = {'User': \['User1', 'User2', 'User3'\],'Hobbies': \[\['Soccer', 'Swimming', 'Hiking'\],\['Swimming', 'Cycling'\],\['Soccer', 'Hiking'\]\]}

)

I first tried one-hot encoding (for each single value instead of each list), but the feature dimension became too large with most of them being 0's.  I searched for other suggestions that address this issue and [this article](https://medium.com/swlh/stop-one-hot-encoding-your-categorical-features-avoid-curse-of-dimensionality-16743c32cea4) stands out. Basically, it suggests other encoding methods to reduce the dimensionality, namely frequency encoding, target encoding, and embedding.

The tricky part is that (to my knowledge) these approaches only work well for when each input example has a single value for each categorical feature. When it comes to my case, there still exists the risk of high dimensionality. Another way that I can try is to explode the examples for each feature so that each feature contains a single value, then proceed with encoding from there (and align the target labels accordingly). But I'm not sure about this approach.

How would you approach this kind of data? Any suggestion will be appreciated. Thank you! Sorry as I'm new to these concepts and if this question was asked before in one way or the other. All of my search for the topics doesn't address the multiple-value nature of the features.

&#x200B;"
353,High Performance Teams: Is the Balance of Personal and Professional Connections Vital for Team Synergy? Should you really KNOW and CARE about your colleagues?,0,https://www.reddit.com/r/datascience/comments/176rwg6/high_performance_teams_is_the_balance_of_personal/,3," I've been thinking about the dynamics of high-performance teams lately, and a thought has been on my mind: just how important is it really for team members to truly KNOW and CARE about each other on a personal level to reach peak performance?

I've heard arguments that strong personal connections within a team can lead to better collaboration, empathy, and an overall positive impact on performance. Others argue that it's all about the work, and personal connections might be secondary.

I'd love to hear your thoughts and experiences on this matter:

1. Have you been a part of a high-performance team where deep personal connections among team members played a significant role in its success?
2. Conversely, have you been on a high-performance team where personal relationships weren't a focal point, yet it still excelled in achieving its goals?
3. What are your thoughts on the balance between personal connections and professional performance within a team?
4. Any tips or strategies for fostering a sense of knowing and caring about colleagues within a team without it feeling forced?

Feel free to share your insights, anecdotes, or opinions. I'm genuinely curious to see the various perspectives on this topic. Let's have a meaningful discussion!

 "
354,What are your thoughts on time series analysis and forecasting with Generative models like TimeGPT,0,https://www.reddit.com/r/datascience/comments/176tmht/what_are_your_thoughts_on_time_series_analysis/,3,"Recently i was in conversation with professor Rob Hyndman and he told how TimeGPT was a promising model that could be used for prediction tasks. For those who don't know this is an excerpt from the company website:-

TimeGPT, developed by Nixtla, is a generative pre-trained transformer model specialized in prediction tasks. TimeGPT was trained on the largest collection of data in history – over 100 billion rows of financial, weather, energy, and web data – and democratizes the power of time-series analysis.

So what are your thoughts on such models and where do you think the future lies for forecasting tasks when compared to statistical models like ARIMA or state space models."
355,Is networking key?,0,https://www.reddit.com/r/datascience/comments/176n9lw/is_networking_key/,7,I'm autistic. I have really bad social anxiety. Is networking key in getting a job? I am just getting started in school.. i've been a stay at home mom for the last 9 years. Am i wasting my time?
356,What to do when looking for a job,4,https://www.reddit.com/r/datascience/comments/176c3gh/what_to_do_when_looking_for_a_job/,3,Do you guys recommend grinding leetcode? Or doing personal projects and learning how to use tools?
357,can any research scientists share their experience?,4,https://www.reddit.com/r/datascience/comments/1769z7v/can_any_research_scientists_share_their_experience/,2,"I'm interested in becoming a doing climate, GIS data/AI research and am intrigued by the postings at these big tech companies (Google, MSFT, IBM, etc.). I currently have a MS in Mechanical Engineering and 2 YOE as a Data Scientist in a big tech company.

I wanted to know what you do as a Research Scientist. How much academic freedom do you have? Is it a lot of meetings or do you get more freedom to get into a deepwork headspace? Do you enjoy the role? Whats the work-life balance like?

How did you get the role? If I'm interested, do I need a PhD or is my MS + Professional Exp good enough? Will not having a PhD hurt me in the long run?"
358,I feel like I’m stuck with my scientific research,5,https://www.reddit.com/r/datascience/comments/1769vr7/i_feel_like_im_stuck_with_my_scientific_research/,7,"Hi, I’m writing this post hoping to get some advice from everyone. I’m studying for a Master's degree in Data Science and conducting scientific research to publish a paper in a conference or journal. My mentors are very supportive and kind. Currently, we have selected an already published paper to build upon. I've completed all the research, read many relevant papers, and my mentors have already provided guidance on how to proceed.

However, in addition to their suggestions, they want me to identify other weaknesses in the paper and find solutions. I'm stuck at this stage; one month has passed, and I haven't been able to discover anything new beyond what they have pointed out. I'm really worried that I might disappoint my mentors, as they've been exceptionally good and supportive to me. Am I overthinking the situation? What should I do to uncover the weaknesses of the proposed method? I'm afraid that I might be slowing down the whole team :("
359,What's Pandas .loc time complexity?,3,https://www.reddit.com/r/datascience/comments/176di2y/whats_pandas_loc_time_complexity/,5," Hi guys, i'm doing research on Pandas, and I've read various posts here and there on the web, but i haven't reached a definitive conclusion regarding the question i posed. I'd like to understand how Pandas stores indices and what the time complexity of lookup operations performed with **loc** is . Some claim that the indices are stored as hash tables, while others contradict this assertion.  I found this post on Stack Overflow, [https://stackoverflow.com/questions/16626058/what-is-the-performance-impact-of-non-unique-indexes-in-pandas](https://stackoverflow.com/questions/16626058/what-is-the-performance-impact-of-non-unique-indexes-in-pandas), which discusses the topic, but there's no concrete evidence that this is true. Can anyone help me? Thanks a lot."
360,CVXPY: Why Norm constraint is not DCP?,0,https://www.reddit.com/r/datascience/comments/176fpo0/cvxpy_why_norm_constraint_is_not_dcp/,6,"\`cp.norm(weights, 1).is\_dcp()\` returns true. Then why this code works:

&#x200B;

    import cvxpy as cp
    import numpy as np
    inputs = np.random.normal(0, 1, (100, 300))
    inputs_mean = inputs.mean(axis=1) # shape (features,)
    inputs_cov = np.asmatrix(np.cov(inputs)) # shape (features, features)
    weights = cp.Variable(len(inputs))
    risk = cp.quad_form(weights, inputs_cov)
    constraints = [
    # cp.norm(weights, 1) == 1.,
    cp.sum(weights) == 1.,
    ]
    problem = cp.Problem(cp.Minimize(risk), constraints)
    problem.solve(verbose=True)
    weights.value

But if you use the first constraint (\`cp.norm\`) instead of the second, it does not:

&#x200B;

    DCPError: Problem does not follow DCP rules. Specifically:
    The following constraints are not DCP:
    norm1(var456) == 1.0 , because the following subexpressions are not:
    |-- norm1(var456) == 1.0

&#x200B;

Why is it not DCP-compliant? How can I troubleshoot it? Is there an alternative way to solve the problem of requiring the sum of abs weights to be 1? Thanks.

&#x200B;"
361,Need problem statements for a project,2,https://www.reddit.com/r/datascience/comments/176aamb/need_problem_statements_for_a_project/,5,"I want to make a project in which I'm thinking of combining IoT devices, PCA, LDA and SVD but I want a problem statement for which there isn't already a solution however I'm not able to think of anything so I thought I should reach out onto reddit to see if I can get something from here. If y'all have any suggestions please let me know it'll be genuinely appreciated!"
362,Recommend data science course,0,https://www.reddit.com/r/datascience/comments/176bn2q/recommend_data_science_course/,2,"I'm a beginner in data science, Can someone recommend some good Data Science courses? "
363,DS exits or pivots,1,https://www.reddit.com/r/datascience/comments/1769fk8/ds_exits_or_pivots/,0,What's the most creative exit or pivot you have done (or seen others do) after being a DS for some time?
364,Career planning,1,https://www.reddit.com/r/datascience/comments/17686qn/career_planning/,1,"Hi everyone, I am currently a penultimate uni student doing a double degree in business and data science (majoring in accounting). While doing uni, I balance a normal grocery store job for the past 2 years. I feel very burnt out with the workload and was wondering if its any better to take a gap year to find a full time job within my field (more so on the data science field), but I am not sure if I should just hang on another year and finish my degree. Another potential approach would be to go full time work and balance uni with 2 courses. What would be ideal and if so, what sort of IT job could I look for with no prior experience or qualifications in IT or data science?"
365,How do you store your ad hoc experiments?,47,https://www.reddit.com/r/datascience/comments/175jep1/how_do_you_store_your_ad_hoc_experiments/,31,"Let’s say you get an ad hoc task that will take an hour or two. You run an sql query extract the data from the db dump into .csv spin up a quick Jupyter notebook and be done with it. But what happens after?


How would you store/archive this project?
Committing Jupyter notebooks to a repo? Now you have bunch of html in your codebase. Code that’s impossible to pull request/review that also bloats the repo. If you clear the outputs of the notebook to reduce the notebook size it instantly becomes useless for later review because now you have to run it again to see what was it about. If you need to run it again you need the exact same data. Now you need to store the data snippet somewhere. Where do you store that data snipped for future reproducibility? The project is too small to spin up DVC or MLFlow so what do you do with it?

What tool / workflow am I missing here?

I keep hearning notebooks are great for experiments but I don’t see what the workflow is like for these experiments…

EDIT: Based on the responses there is no solution to any of this chaos that covers both the code and the data... you either end up over-engineering the experiment or dumping it somewhere and hoping that a well written readme will do the job.  There has to be a better way.."
366,Existing relational database to new vector database?,3,https://www.reddit.com/r/datascience/comments/1761n34/existing_relational_database_to_new_vector/,1,"I'm in the very early stages of an investigatory project at my job (senior software engineer with a moderate amount of data mining and snowflake/star pattern ETL OLAP warehousing experience in SSAS from years ago, long before modern tools and platforms, who has somehow now been deemed the SME for all things ""AI"").

Basically, I have a relational SQL Server database containing tens of millions of products, each with up to 20 categories of detail. I also now have usage data from our website that tracks customer interaction with these products, logging things like their account details and demographics as well as their IP, location, searches, where they clicked, how long they interacted, what they interacted with previously, what they interacted with next, etc.

If they wanted to run this in an old-school schema, I could work something up. I could probably even make some great reports in Power BI. But my bosses, of course, want to load this into a ChatGPT-type interface to ask natural language questions about the data.

My cursory research tells me I need to massage my data into a vector database first and foremost before I start worrying about Langchain, Llama, and OpenAI, and any specific platform or toolset. But I'm not sure where to start, and I'm getting hung up on that there doesn't seem to be any good examples of migrating existing data - everything is either too much hype and promise-selling language that is sparse on detail or is a very in-the-weeds, poorly documented, mostly-incoherent mess with no examples at all or uses examples that are so simplistic to be not relevant to anyone.

I found some (albeit again very simplistic) examples from Milvus that show importing semi-structured JSON-formatted objects that roughly align with what I'd equate to, in my world, denormalized key/value pairs for various product properties. Cool, that makes sense. That's half of it. But I'm not sure about the other half - how much, if any, pre-aggregation do I need to do with the analytics data? Do I import essentially one object for every single piece of tracked data, or do I roll it up beforehand? I'm most interested in having this vector data be used to identify period-based trends, forecasts, and recommendations like ""Based on his individual product engagement tracking as well as the aggregate tracking of his demographically similar cohorts over the past week, what products should we surface for Bob Smith next?""

Basically, all this is a very long-winded, rambling way to get to three questions:

1. Are there any examples of converting a remotely complex RDMS into a vector database?

2. How much massaging beyond basic denormalization and pre-aggregation do I need to do?

3. Is it sufficient to load data as lists of a buttload of key-value pairs, or would I do better to zhuzh it into wordy natural language descriptions of the data?"
367,Where to spend £5k budget for professional development in Data Science,13,https://www.reddit.com/r/datascience/comments/175ptfa/where_to_spend_5k_budget_for_professional/,24,"Hi everyone,

I am hired by a government based organization to work as a data scientist. I currently have 1 year of full time experience and 2 years part time before graduation. My project is ending in about 2 months and I have a budget of around £5,000 that I can use for personal and professional development. I have to complete the bookings before the end of the project, although actual training/conference can take place beyond the end date. 

Working in an applied research role, I can spend it on conferences, for training opportunities or certification exams. I want to ask you guys for your opinions about what would be good things to spend this budget on, considering I am at an early stage in my career. "
368,How important is being appreciated and team fit as a factor to stay in a role with average salary given slow adoption of data science solutions?,70,https://www.reddit.com/r/datascience/comments/175caah/how_important_is_being_appreciated_and_team_fit/,85,"My team and managers are so easy to be with. Very grateful for that. The pay is okay. 150k/yr TC in Midwest. Hard for me to make a switch given how much I am appreciated. I almost feel spoiled when it comes to flexibility. I have overachiever tendency and the pace is so slow in adopting my ML models.

I am the “lead”/senior data scientist in an R&D supporting scientists decision making with machine learning. Importantly, I am in a huge multinational consumer product company and I am not in the Data science organization, I bridge between the two and the data science expert on the team.

  I have developed the domain expertise and I have  a PhD in  an applied computational field with 5 years experience . I am not as challenged with getting deeper into complex stats, I have been really honing the soft skills of communication, influencing etc so getting comfortable in a senior role. Also I have been growing as a ML engineer building my own pipelines and deploying my models on prem server that they bought for me.

I am not sure how greener it is on the other side, how do senior folks approach deciding when to move on? Any input is much appreciated."
369,Any value to an unrelated advanced degree to get into DS?,9,https://www.reddit.com/r/datascience/comments/175nbtg/any_value_to_an_unrelated_advanced_degree_to_get/,14,"I'm a PhD in biology and my next step in the pipeline is a bioinformatics post doc while studying for a DS course (IBM Data Science Professionnal Certificate) on the side.

I know certificates have become insufficient to get an entry level jobs in Data Science (and tech in general) now that the market has cooled down from the pandemic craze, but I was wondering if having an advanced degree in another field and minor experience from my post doc (mostly specific data analysis tools for bioinformatics, a lot of R, and probably very minimal Python) would really be helpful or if companies don't care about non-CS scientific education ?

What about getting an online MS in Data Science, would that be required ? How difficult would that be for someone with a weak background in statistics ?

I'm interested in Data Science and I'm looking to expand my skills to give myself more options but while the certificate is short and could be useful as a biotech scientist, I wouldn't want to pursue more formal education if it doesn't really give me more options other than a false hope and wasted time applying for DS positions I can't get."
370,What are grid search alternatives?,22,https://www.reddit.com/r/datascience/comments/175gyx0/what_are_grid_search_alternatives/,40,Grid search is a basic parameter that is very slow when dealing with huge datasets. What are other tuning algorithms that are faster and perform equally as well.
371,SHAP Deep Reinforcement Learning,2,https://www.reddit.com/r/datascience/comments/175x92z/shap_deep_reinforcement_learning/,0,"Hi Guys,

Is there a way to integrate SHAP with deep reinforcement learning agent ? I am using the FINRL library on ensemble stock trading , and trying to use SHAP with on it. But i hardly find any information or tutorial on it. 

&#x200B;

Thanks. "
372,Markdown To HTML,0,/r/StreamlitOfficial/comments/1760rc0/markdown_to_html/,3,
373,"Julia leads Rust, Zig, Go and Java in data processing benchmark",6,https://www.reddit.com/r/datascience/comments/175oh0k/julia_leads_rust_zig_go_and_java_in_data/,0,"[https://github.com/jinyus/related\_post\_gen](https://github.com/jinyus/related_post_gen)

https://preview.redd.it/ii0dm13dymtb1.png?width=849&format=png&auto=webp&s=6cd6064d23e26958abe65cdf48e73e688f3d5f4f"
374,Security measures at my workplace,2,https://www.reddit.com/r/datascience/comments/175q00o/security_measures_at_my_workplace/,7,"I work for a pretty big Aerospace manufacturing company where my job title is 'Digital Engineer'. What this actually is, is a mix of data analytics and software engineering in PHP and C#. However, quite a lot of my work revolves around the transfer of Excel-based operations throughout the company to more efficient mediums. I can't disclose specifics about my current project but it involves producing a web form for our engineers to log parts into, and a big part of this project is scanning through the old Excel sheets looking for, and removing duplicate entries.

I would of course like to use Python's Pandas/Polars libraries to automate a lot of my work, but due to the high-security nature of my work, I cannot pip install any packages or install most open source software.

My question is, can I automate much of my project work with a standard installation of Python or SQL Server? We also use some corporate standard software called Thingworx, but I haven't really been exposed to it yet."
375,Predicting what features lead to long wait times,3,https://www.reddit.com/r/datascience/comments/175qvkx/predicting_what_features_lead_to_long_wait_times/,4,"I have a mathematical education and programming experience, but I have not done data science in the wild. I have a situation at work that could be an opportunity to practice model-building. 

I work on a team of \~50 developers, and we have a subjective belief that some tickets stay in code review much longer than others. I can get the duration of a merge request using the Gitlab API, and I can get information about the tickets from exporting issues from Jira. 

I think there's a chance that some of the columns in our Jira data are good predictors of the duration, thanks to how we label issues. But it might also be the case that the title/description are natural language predictors of the duration, and so I might need to figure out how to do a text embedding or bag-of-words model as a preprocessing step.

When you have one value (duration) that you're trying to make predictions about, but you don't have any a priori guesses about what columns are going to be predictive, what tools do you reach for? Is this a good task to learn TensorFlow for perhaps, or is there something less powerful/complex in the ML ecosystem I should look at first?"
376,Sucking at my job?,143,https://www.reddit.com/r/datascience/comments/174wmnk/sucking_at_my_job/,41,"Got into my first job about 10 months ago. I study a master’s on data science and I’m about to finish school in 2-3 months. I’m doing okay, my lowest score is B+ and I’m working on a churn project. 

I got my job through a friend, the company knew I was recently starting my master’s and that I had no experience in this field. However, they were really interested in what I was (supposedly) going to learn, and were excited that I’d bring a new perspective to the team. 

Things started ok and I’m doing pretty good on every day tasks, but whenever I’m handed an analysis task/data science project, it always ends up taking more time than allowed, and the more experienced people in my team usually end up coming in and having to re-do everything, sometimes even work overtime to meet deadlines. 

It’s not that I’m not working on it, like for example I have about 8 hours on this one project I had to do, and all I have is a few tables and metrics. Yet, the customer meeting is tomorrow and I have nothing to show for the time I have put in.

I’m starting to feel like I’m wasting company’s time and resources and more importantly, I feel bad about not having learned anything and not being able to apply anything."
377,R-SESSION CRASHING-PHOBIA,0,https://www.reddit.com/r/datascience/comments/175mipy/rsession_crashingphobia/,9,"I have a 2Mio x 1139 dataset (huge right) and ive spent the whole day trying to load and work with in r (package data.table, function fread). It loads the data pretty quickly, in 1-2 minutes I'd say. I wanna loop over the data (or use lapply or something similar to gain efficiency). My function is fairly simple though, but the dataset is just huge. And then it runs and runs and runs, and half an hour goes by and it still runns. I AM SO AFRAID OF THE ''SESSION CRASHED''!

Do you guys have any tips on dealing with such datasets and am i guaranteed if i leave the loop running over night, that it wont crash? Can I have trust in R? Are there any measures I can take to support R with its looping and looping and looping?

P.S. i sadly mustn't split the dataset. 

Thanks a lot, i wish you nothing but simple datasets. "
378,Predicted raw probabilities or threshold-adjusted ones?,2,https://www.reddit.com/r/datascience/comments/175errf/predicted_raw_probabilities_or_thresholdadjusted/,5,"I have a classifier model. I would need the predicted probabilities for production purposes (on unseen data), as the probability score is of more concern in the project. Should I consider just the raw probabilities, as predicted, or should I make some sort of adjustment with the optimal threshold (for the trained model) and then consider the adjusted probabilities? 

For example, suppose I get a probability as 0.55. Which means, in face value, that there's more likelihood of it being 1 than 0. But my model says optimal threshold is 0.6. Which means model still wants to predict it to be 0, being more conservative in predicting 1. However since I'm concerned with ONLY the probability, isnt that deceiving or wrong? 

Any suggestions are appreciated."
379,Data Science for Sales,12,https://www.reddit.com/r/datascience/comments/1754v9n/data_science_for_sales/,21,"I work as a Sales Engineer for a SaaS company where my work mainly revolves around working with Excel Spreadsheets and PowerPoint decks, which I am very tired of and want to make a switch. I’m very passionate about data science and have some skillset through side learning- intermediate Python and SQL with basic grasp of machine learning. For xyz reasons I can not make an official role switch so the best I can do is make my job more interesting. Any suggestions on how I could use data science to add value to the sales/ sales engineering process? For context, I have access to my company’s CRM data and my company’s product offering is price benchmarking."
380,"Can anyone provide an easy to understand real world example of tensors, and how they are used?",69,https://www.reddit.com/r/datascience/comments/174pvw9/can_anyone_provide_an_easy_to_understand_real/,63,"One area of data science I think that people struggle to wrap their head around is thinking of problems and frameworks, tools, technologies in simple real world terms. Very hard to understand something You're just writing lines of code and programming into a machine, without really understanding in the real world that you live in what they could possibly be related to...


And recently I've been learning tensorflow, and apparently tensor is an actual word, like this is a real thing. But what I don't understand is what a real world example of a tensor could possibly be, like an analogy, or metaphor for how to explain them to someone else. For example, tree, box, power plant, etc. I'm not saying those are related to tensor, but those are often things that people use to explain complex concepts in the real world. 


So how would you explain what a tensor is in real world terms?"
381,A/B Testing Product or User Split,5,https://www.reddit.com/r/datascience/comments/1756hae/ab_testing_product_or_user_split/,5,"I work for a company that sells unique items online (think collectibles or artwork in an eBay style auction). We have a data model that can tell if the item is ‘attractive’, meaning the seller has a reasonable reserve and users can potentially get it for a good deal.

If I want to do A/B test on this to see if this ‘attractive’ indication makes those items sell at a higher rate, how would you design the test? Would you:
1. Identify those items (say they are 500) and split them randomly into test/control groups (can be 250 items each) and provide all users the same experience for those items then measure how well they sell by group?
2. Identify those items and only show the ‘attractive’ indicator to half of the users. Meaning that half the users will see the existing experience (no ‘attractive’ indicator at all) and half will see the ‘attractive’ indicator on all 500 items, then compare how they sell by user group?

Intuitively #1 makes more sense to me, but I’m not finding a lot of literature to support this methodology. How would you design such a test and what’s your rationale?

Please note that engagement, clicks, time on site are not our main drivers for this test, I am mainly focused on testing if this will lead to more sales.

Thanks"
382,"How can data science be used to ""make the world a better place""?",128,https://www.reddit.com/r/datascience/comments/174gxvo/how_can_data_science_be_used_to_make_the_world_a/,99,"I see a lot of data scientists in this subreddit describing their work as using different types of methods to, in the end, improve company performance and/or profits.

I was wondering, if you have examples for how data science is used for social benefit instead of the bottom line of profits?"
383,How quickly should you be expected to start producing?,46,https://www.reddit.com/r/datascience/comments/174n6w2/how_quickly_should_you_be_expected_to_start/,33,"How soon would you expect a new Senior Data Scientist to start churning out models, analysis, reports, experiments, etc? What would you think dictates this expectation?"
384,Is fitting functions to data (with chi2 and all that) data analysis or data science?,0,https://www.reddit.com/r/datascience/comments/175qent/is_fitting_functions_to_data_with_chi2_and_all/,53,&#x200B;
385,Fraud Detection Thesis,0,https://www.reddit.com/r/datascience/comments/175nces/fraud_detection_thesis/,12,"Hello.

I have to do a project for my thesis.
I have decided about Fraud Detection for banks. How to see if the money is like made from fraud or if it’s being laundered.

What do you say about it?
 How should I approach this topic and how to do it?
Any ideas? Thanks."
386,Has anyone used Comet for experiment tracking?,2,https://www.reddit.com/r/datascience/comments/1755h3b/has_anyone_used_comet_for_experiment_tracking/,2,Hey! Has anyone used Comet (https://www.comet.com) for their experiment tracking? I’m looking into the product and am curious if anyone here has enjoyed using it
387,"How does SEMRUSH, and other big analytic crawler works?",3,https://www.reddit.com/r/datascience/comments/1752wat/how_does_semrush_and_other_big_analytic_crawler/,2,I'm trying to build something similar where websites can be crawled and refresh daily
388,Creating a Visualizations Map,1,https://www.reddit.com/r/datascience/comments/17578q8/creating_a_visualizations_map/,2,"Hi Everyone

I am a new data analyst in an insurance company that uses DOMO as its BI tool, there have been many previous contractors doing similar work and this has led to many visuals being duplicated and many dashboards having redundant and repetitive information. 

I am in the process of having only one source of truth for a specific graph, however, different departments have been using different graphs (i.e. monthly premiums but unconnected cards in different dashboards). 

My question is beyond a refresher training I wanted to make a map for the ~~lazy~~ some staff to easily locate specific graphs, has anyone done something similar and have any advice on how to go about it."
389,Advancements in extracting tabular data from PDFs?,8,https://www.reddit.com/r/datascience/comments/174pkt1/advancements_in_extracting_tabular_data_from_pdfs/,7,"Hi everyone!

Is there a simple and robust method for extracting highly tabular data from a PDF without resorting to rule based regex parsing?  I'm currently using PDFminer, PDFplumber and regex to build templates to extract PDFs based on the type of PDF but it's very time-consuming and tedious.  Is there a better way?

I've used Langchain and OpenAI to build ""Chat with your document"" apps which works great for uploading a PDF of a whitepaper and asking it to summarize the paper, but when it comes to extracting table data - I don't think this solution will work.

&#x200B;

Thank you for your input,

Data Scallion"
390,[US] What are some hubs for data science or data analytics?,2,https://www.reddit.com/r/datascience/comments/174sfb2/us_what_are_some_hubs_for_data_science_or_data/,14,"I mean cities where a data scientist with a few years of experience who lives there would have a hard time NOT finding a new job.

What are the top 5 or 10 DS hubs in the US, and then what's 1 or 2 cities near the great lakes that punch well above its weight (besides the obvious answer which I'm assuming is Chicago)?"
391,Question animal tracking data and filling in periods of sleep?,1,https://www.reddit.com/r/datascience/comments/174wama/question_animal_tracking_data_and_filling_in/,0,"I'm working on a project that is looking at the interaction between gps tracked pelicans and oil rigs in the gulf of mexico. The big thing with tracking data analyses such as hidden markov model and step selection functions is to have consistently recorded locations to analyze, looking at the data I realized that there is a gap from 9:30pm to 5am everyday, this is because it was assumed they were sleeping at these times and the rows removed. Should I put back those missing rows if possible or just have the coordinates record at 9:30pm repeated every 90 minutes until the 5am ping for each pelican?"
392,Tough spot,25,https://www.reddit.com/r/datascience/comments/1748bph/tough_spot/,17,"
Hey everyone,

I recently joined a company as a data scientist and found that their data warehouse is in dire shape. It seems they haven't invested enough time in validating their data, resulting in most tables being unreliable for modeling or reporting. The analysts are reporting incorrect data and the upper management knows it. To add to the challenge, there's only one overburdened data engineer here, so I'm pretty much on my own in navigating this.

I've been identifying and communicating these data issues to upper management, but I also need to produce some models. The warehouse is poorly built, many tables with no data, a lot of columns in one table meaning they didn't bother creating more dimension tables. And worst of all, the data in tables is simply wrong. My current thought is to pivot temporarily:

1. Use existing, validated CSVs and Excel files to begin my analyses and model building.
2. Parallelly, work on gradually rectifying the data warehouse issues.
3. Eventually, transition the models to source data directly from the fixed warehouse.

Has anyone faced a similar situation? How did you handle it? Any advice or alternative approaches would be greatly appreciated!"
393,Highcharts for Python v.1.4.0 Released,2,https://www.reddit.com/r/datascience/comments/174ml3k/highcharts_for_python_v140_released/,2,"Hi Everyone - Just a quick note to let you know that we just released v.1.4.0 of the [Highcharts for Python Toolkit](https://core-docs.highchartspython.com/) (Highcharts Core for Python, Highcharts Stock for Python, Highcharts Maps for Python, and Highcharts Gantt for Python).

While technically this is a minor release since everything remains backwards compatible and new functionality is purely additive, it still brings a ton of significant improvements across all libraries in the toolkit:

**Performance Improvements**

* 50 - 90% faster when rendering a chart in Jupyter (or when serializing it from Python to JS object literal notation)
* 30 - 90% faster when serializing a chart configuration from Python to JSON

Both major performance improvements depend somewhat on the chart configuration, but in any case it should be quite significant.

**Usability / Quality of Life Improvements**

* **Support for NumPy**

  Now we can create charts and data series directly from NumPy arrays.

* **Simpler API / Reduced Verbosity**

  While the toolkit still supports the full power of Highcharts (JS), the Python toolkit now supports ""naive"" usage and smart defaults. The toolkit will attempt to assemble charts and data series for you as best it can based on your data, even without an explicit configuration. Great for quick-and-dirty experimentation!

* **Python to JavaScript Conversion**

  Now we can write our Highcharts formatter or callback functions in Python, rather than JavaScript. With one method call, we can convert a Python callable/function into its JavaScript equivalent. This relies on integration with either OpenAI's GPT models or Anthropic's Claude model, so you will need to have an account with one (or both) of them to use the functionality. Because AI is generating the JavaScript code, best practice is to review the generated JS code before including it in any production application, but for quick data science work, or to streamline the development / configuration of visualizations, it can be super useful. [We even have a tutorial on how to use this feature here.](https://core-docs.highchartspython.com/en/latest/tutorials/callbacks.html)

* **Series-first Visualization**

  We no longer have to combine series objects and charts to produce a visualization. Now, we can visualize individual series directly with one method call, no need to assemble them into a chart object.

* **Data and Property Propagation**

  When configuring our data points, we no longer have to adjust each data point individually. To set the same property value on all data points, just set the property on the series and it will get automatically propagated across all data points.

* **Series Type Conversion**

  We can now convert one series to a different series type with one method call.

**Bug Fixes**

* Fixed a bug causing a conflict in certain circumstances where Jupyter Notebook uses RequireJS.
* Fixed a bug preventing certain chart-specific required Highcharts (JS) modules from loading correctly in Jupyter Notebook/Labs.

We're already hard at work on the next release, with more improvements coming, but while we work on it, if you're looking for high-end data visualization you'll find the Highcharts for Python Toolkit useful.

Here are all the more detailed links:

* [Highcharts for Python on Github](https://github.com/highcharts-for-python)
* [Highcharts for Python Website](https://highchartspython.com)
* Highcharts Core for Python

  * [Source Repo](https://github.com/highcharts-for-python/highcharts-core)
  * [PyPi](https://pypi.org/project/highcharts-core/)
  * [Documentation](https://core-docs.highchartspython.com)

* Highcharts Stock for Python

  * [Source Repo](https://github.com/highcharts-for-python/highcharts-stock)
  * [PyPi](https://pypi.org/project/highcharts-stock/)
  * [Documentation](https://stock-docs.highchartspython.com)

* Highcharts Maps for Python

  * [Source Repo](https://github.com/highcharts-for-python/highcharts-maps)
  * [PyPi](https://pypi.org/project/highcharts-maps/)
  * [Documentation](https://maps-docs.highchartspython.com)

* Highcharts Gantt for Python

  * [Source Repo](https://github.com/highcharts-for-python/highcharts-gantt)
  * [PyPi](https://pypi.org/project/highcharts-gantt/)
  * [Documentation](https://gantt-docs.highchartspython.com)

Please let us know what you think!"
394,Why would I use Tableu/BI over Streamlit? Is there any advantage?,5,https://www.reddit.com/r/datascience/comments/174f1cc/why_would_i_use_tableubi_over_streamlit_is_there/,30,"Asides from skill issue

Is there any benefit to using Tableu/BI over streamlit given that coding isn't the issue? "
395,Explainable boosting machines,5,https://www.reddit.com/r/datascience/comments/174dzeb/explainable_boosting_machines/,13,Just curious how many people out there favor explainable boosting machines over bread and butter methods like lgbm or xgbm. Should I learn this or is it a fad?
396,Data scientists - How many hours a week do you work?,94,https://www.reddit.com/r/datascience/comments/173txze/data_scientists_how_many_hours_a_week_do_you_work/,77,
397,Are you happy with your job?,40,https://www.reddit.com/r/datascience/comments/17404sl/are_you_happy_with_your_job/,47,"I see so many complaints of people who hate their job or can't find one. I am starting to wonder if this industry is awful and I have just been lucky, or if the negatives just pop up more.

How happy are you with your job?"
398,What are some red flags to look out for in a job interview for a data job?,62,https://www.reddit.com/r/datascience/comments/173ubu3/what_are_some_red_flags_to_look_out_for_in_a_job/,60,
399,How to work with product managers,24,https://www.reddit.com/r/datascience/comments/1740tx7/how_to_work_with_product_managers/,14,"Hi all, I’m in the midst of a job search and one question I’ve been asked a few times is how I work with product managers. 

In truth, I’ve worked with product managers very little, and when I did, the partnerships were not fruitful. They generally wanted me to do exactly what they asked with minimal input from me on whether that task was worthwhile. In the worst cases, it felt like my entire job was just to keep the PM happy. This is quite different from my interactions with other stakeholders like managers, execs, etc, who have typically valued a more collaborative approach. I don’t know if this is typical—just my experience. 

Rather than ask for interview advice, I’m hoping I can prompt a more interesting discussion here on how to work well with product managers. What makes a good product manager? When is it worth pushing back on requests, and when should we just put our heads down and do what is asked? How do you balance the needs of PMs with those of other stakeholders?"
400,Most valuable data science project you've worked on for a company?,57,https://www.reddit.com/r/datascience/comments/173l7aj/most_valuable_data_science_project_youve_worked/,34,"(Previous post was removed for unclear reason)

I'm curious to hear about the impactful data science projects you've had the opportunity to work on in the corporate world. Whether it's in healthcare, finance, e-commerce, or any other industry, I'd love to know about the projects that made a significant difference.

I understand it may not be possible to go into details, but please share your experiences:

1. The industry or sector you were working in.
2. A brief description of the project.
3. The impact or results the project had on the company. 

Just to clarify, when I say “valuable” I mean from the company’s perspective."
401,Why aren't there more decision support algos for doctors for differential diagnosing?,46,https://www.reddit.com/r/datascience/comments/173hj19/why_arent_there_more_decision_support_algos_for/,52,"Currently a medical student, but have been reading into clinical informatics. Literature seems to suggest that simple algorithms can out perform doctors in regards to differential diagnosing. Why hasn't there been more implementation to create decision support software to augment decision manage in regards to diagnosis and treatment?

Shit, like I'm playing around ChatGPT with a lot of my cases and its really good at differential diagnosis. Which would make me think that mapping a constellation of symptoms to specific diseases shouldn't be that hard for a machine to do right? I can't imagine how much better it could get within the black box of ML where local prevalence and what not of diseases could be taken into account "
402,What data science tools have the best user experience?,24,https://www.reddit.com/r/datascience/comments/173hmq4/what_data_science_tools_have_the_best_user/,18,"Data Science community, I've got a question for you:

Which data science tools do you find most user-friendly?

I just went live with a project I've been working on. I feel like the configuration process is easy but would love to compare it with some of your favorite data science tools. The project I'm working on is a simple cluster compute tool. All you do is add a single line of code to your python script and then you're able to run your code on thousands of separate VMs in the cloud. I built this tool so I could stop relying on DevOps for batch inference and hyperparameter tuning. At the moment we are managing the cluster but in the future I plan to allow users to deploy on their own private cloud. If you are interested I can give you 1k GPU hours for testing it :). I honestly wouldn't mind a few people ripping everything that sucks with the user experience.

Anyways, I'd love to learn about everyone's favorite data science tools (specifically python ones). Ideally I can incorporate a config process that everyone is familiar with and zero friction.

Project link: [https://www.burla.dev/](https://www.burla.dev/)"
403,How to validate data?,51,https://www.reddit.com/r/datascience/comments/173broc/how_to_validate_data/,23,"I'm an SWE (**not a data scientist**) and trying to build a generic data validation tool (or find appropriate tools to adopt) for my company.

I started looking into libraries such as Great Expectations, Pydantic, etc.. And they all seem promising, but I don't think they solve the issue of validating *changes in data* (as far as I can tell). They seem to be good at validating that data is within an expected range, of an expected type, etc., but I need a little more.

What I'm looking for is a tool that validates changes in data by comparing the previous value with the new value.

In some of our applications, new data is first pumped into a staging table. We then calculate relative change % between the staging and target table (for each field), and if the change is higher than some threshold, validation fails. But there's obviously a lot of issues with this (like in cases where a change from 1 to 18 is normal but produces a percent change of 1700).

This is just an example, but it would be helpful if we can call an API to do this sort of validation for us.

And instead of using absolute change, relative change, etc... is there perhaps a tool that can validate based on historical changes? Perhaps by capturing changes for some set time and using that information to validate future changes? I'm just brainstorming here.

Would highly appreciate some recommendations/tips for tackling this problem. Thank you!"
404,Is there a good industry use of stable diffusion that I'm not aware of?,1,https://www.reddit.com/r/datascience/comments/173yyz7/is_there_a_good_industry_use_of_stable_diffusion/,3,Working on a deep learning project with some friends. They really want to build something with SD. Will I be able to use these skills in industry?
405,How do data scientist managers manage data scientists?,117,https://www.reddit.com/r/datascience/comments/172zdgx/how_do_data_scientist_managers_manage_data/,56,"As a data science manager how do you manage your team? Specifically how do you manage your DSs career growth and promotion opportunities? Imagine you have a team of 5 DSs: 2 DS1, 2 DS2, and 1 DS3, where DSX is a Data Scientist 1-4. What is your measure of success - promotions, completed projects, revenue contribution,etc? How do DSX become DSX+1?

Some of my thoughts:

1. As a manager, I can support my DSs by **NOT** micromanaging.  I will track your project and encourage model reviews, code reviews and present final outputs to the team. All necessary skills of a DS.

2. I can ensure my DSs have the skills to mange a project. A DS1 would see many touch points with the manager(me) or a DS3-4 on projects to ensure success, a DS2 less, and DS3 probably none. This in fact is my basis for promotion - shows level of competency on managing projects and deliverables. 

3. There can also be project based performance promotion, that is, DS possibly lacking project managing skills but tackles difficult projects and delivers top notch work consistently. 

4. The bigger issue is about personal development(PD).  How do managers balance PD against available projects? The DSs may want to gain experience in applying AI or unstructured learning , GPGPU models, specific toolsets like Vertex AI, NLP etc. Your team’s project assignments  may not see this diverse a set of projects. When a project becomes available I balance availability against skill set in order to complete the projects based on delivery times and quarterly goals because these are the measures of success for my team. Typically I fill the void with targeted training courses and allocate time to PD. 

5. Some managers think PD is solely the DS’s responsibility. Thoughts?

6. How do you deal with HR when there are no clear DS role descriptions?

Not a simple optimization problem!"
406,Is it possible to automate the labeling of strings of text?,13,https://www.reddit.com/r/datascience/comments/173cl4s/is_it_possible_to_automate_the_labeling_of/,22,"A friend of mine asked me to see if there was a way to automatically add labels to customer complaints based on the text in the complaint. Presently, on a monthly basis they read every customer complaint and manually apply a label based on their judgement of what it is. There is a specific set of labels they use to classify their complaints.

This seems like a problem for NLP but I'm unsure of where to start or just not confident. It's been at least 7 years since I've done any real 'data science' stuff. The data is tidy, I can read it into a data frame. I know there are a number of tutorials online that discuss stemming, lemmatization, and other factors so I think I can get some of those basic steps down. But I would be happy if you had a specific guidebook that you've used that you like and could share.

Am I oversimplifying this or overly confident? I should be able to build a model that tries to applies the same labels they previously applied manually but automatically with this program. Am I thinking about this correctly?

I'm really not certain what the best tools in R to use for this are. Back when I did I used caret, keras, SnowballRC and some other things like dplyr. I'm not certain what models or validation approaches to use either. Are there any good guides that a simpleton like me could use to build a relatively confident validation stage?

Thanks for your thoughtfulness on this :)"
407,What is the best package /approach for matching text in python?,5,https://www.reddit.com/r/datascience/comments/173izkk/what_is_the_best_package_approach_for_matching/,2,"I am trying to match company names in all languages and have been using rapidfuzz package with partial ratio distance metric which works fine for English names. I have tried levenshtein, jaccard and others as well but wondering what is the best approach? Also what do u use for non English text matching?"
408,"Weekly Entering & Transitioning - Thread 09 Oct, 2023 - 16 Oct, 2023",5,https://www.reddit.com/r/datascience/comments/173im0f/weekly_entering_transitioning_thread_09_oct_2023/,83," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new)."
409,What advice would you give someone starting out on learning to collaborate on large projects and not be the sole person responsible for a model build?,11,https://www.reddit.com/r/datascience/comments/173dd6h/what_advice_would_you_give_someone_starting_out/,3,"I'm starting out on a team that is very collaborative and I've realized that while I've worked with other people before, I'm not used to doing it the way they do, where a project could be divided up into lots of smaller parts and it might not be me on every one of those parts. 

Does anyone have advice for dealing with what almost feels like getting territorial over a model? It's nothing against the people on my team - they've all been there for longer than me and are much smarter than me. I just am used to seeing things 100% of the way and I took a lot of pride in being able to look at a finished thing and be like ""I built that."" It also almost feels like it's my fault for not being able to do all of the work myself, like if I was a better worker I'd be able to get more of the work done and people wouldn't have to pick up my slack.

Is this something that just goes away with time if you continue working on a team that works in this way? I didn't expect there to be an emotional challenge component to this and I'm struggling to know what to do and how to adapt, especially because this doesn't feel like the kind of thing you can really share/get support from coworkers on, because they're the ones working on it with me if that makes sense."
410,"What is currently the most in demand Analytics/DS by Healthcare institutions (hospitals, clinics, big pharma, government, etc.)?",8,https://www.reddit.com/r/datascience/comments/173cxz4/what_is_currently_the_most_in_demand_analyticsds/,2,
411,"Should we use non-linear models for ""linear"" data?",162,https://www.reddit.com/r/datascience/comments/172gy7a/should_we_use_nonlinear_models_for_linear_data/,123,"So I had an argument with an interviewer who asked me why I didn't just use a non-linear classification model on the linearly separable data that I had in one of my projects that I described to him, even though I had no computational constraints. I told him that it was because, irrespective of computational cost, a linear model is always preferable if you have linear data because it is simpler and captures general pattern while non-linear models might overfit on  local patterns. But he kept disagreeing and saying that the only advantage that a linear model would have is computational cost and explainability even though I was actually getting better results with a logistic regression.

Who do you think was missing something here and why?"
412,Running ARIMA Models,4,https://www.reddit.com/r/datascience/comments/17369yn/running_arima_models/,3,Where is the best place to run an ARIMA model? I have done all the work in python to determine the best parameters but it is so confusing to actually fit the model correctly. Thanks!
413,Automation of insights extraction from Clustering,2,https://www.reddit.com/r/datascience/comments/1731r1r/automation_of_insights_extraction_from_clustering/,0,"So I've been given this task to create clustering on users dataset. The model itself performs well but the management wants me to somehow automate the output/insights so it can be translated to other datasets too. I expressed my worries for them as I don't think that it is possible but I was trying my luck here to see maybe there is a method/idea which I am not aware of?

The only thing I could come up with is looping for each cluster and finding if there is a feature which has a value count of more than 90% (or any threshold) and just saving the cluster-feature-value trio that is answering this condition. I don't know how much I'm up for that method because its very technical and automatic and might miss valuable (for example - If I have a country feature, and let's say if I have 50 countries in a cluster. Maybe the prevelance of all countries is equal to 2% but because 49 of the 50 countries are from Asia so it means 98% of them are from Asia which is a valuable information I am missing).

Is there even any method to do that? Or should I just insist that it is not feasible?  
Thanks"
414,Image Detection with CNN Model,2,https://www.reddit.com/r/datascience/comments/17316vc/image_detection_with_cnn_model/,8,"I am a beginner trying to create a Model with Image detection using Convolutional Neural Network. I have a project in mind where I would detect the type of banknotes. I have already collected some images to be used but as far as i know. I need to annotate it and then train it. 

I don't know how will i link the annotated JSON file of the images when training. Does anyone know how?"
415,Why are there no good graph visualisation programs?,73,https://www.reddit.com/r/datascience/comments/17212yf/why_are_there_no_good_graph_visualisation_programs/,40,"Does anyone know of any half decent graph/network visualisation programs? Gephi is very frustrating to use (can only view up to 20 attribute columns at once, can't inspect node/edge attributes from the graph view, attribute values only allow you to copy the abbreviated scientific notation form etc.)

This is what I am trying to do... I have a graph (heterogenous but I can compress it to homogenous if absolutely necessary) and I want to be able to interactively visualise said graph. If I click on a node or edge, I wish to be able to see the attributes of that node or edge. Preferably, I'd also be able to colour nodes and edges by attribute.

There seems to be a few small bespoke projects but from the few I've tried, none have achieved what I have outlined above - what I would have thought to be the bare minimum for a graph visualisation application.

&#x200B;

**EDIT**

Cytoscape standalone is definitely the way to go for me. Would highly recommend over Gephi. Still had to flatten my heterogenous graph, appending all attributes across all types, but with a specified `TYPE` attribute you can conditionally colour within Cytoscape so it gets you there in the end (bit annoying that every node/edge has redundant attributes from other node/edge types but it's not the end of the world.) Thanks for all the suggestions."
416,How do I make use of other parameters' forecasts for time series forecasting?,6,https://www.reddit.com/r/datascience/comments/1726i2h/how_do_i_make_use_of_other_parameters_forecasts/,15,"Topic might be a bit confusing, let me elaborate. For example let's say I'm working on a time series forecasting problem and I found that temperature is highly correlated with my target. But I also know it's a time series problem, so I want to boost my model by giving it probable temperature for the target dates. How do I do that? I can't wrap my head around it"
417,Data Cleaning & Wrangling Standards?,0,https://www.reddit.com/r/datascience/comments/172ko0y/data_cleaning_wrangling_standards/,4,"Are there any industry standard frameworks for data cleaning and wrangling? Naming conventions, order of operations (when to do imputation, detecting careless cases, etc.) that companies and researchers use to make shareable uniform datasets?"
418,"a controversial request, but please help me out in defending that sarcasm doesn't affect sentiment analysis",0,https://www.reddit.com/r/datascience/comments/172subu/a_controversial_request_but_please_help_me_out_in/,32,"bit more context— me and my groupmates are conducting a study in which we would determine a person's MBTI (a personality classification method) based on their posts on twitter using sentiment analysis. 

since our research focuses on personality classification instead of identifying a statement's positive and negative connotations, we decided to exclude sarcasm out of the equation since we treat every user's word as a determining factor of their MBTI. but our thesis moderator asked the concern regarding sarcasm out of curiosity and we still have quite some struggles defending this idea.

any help would be appreciated, thanks!"
419,Web-based App Recommendations,3,https://www.reddit.com/r/datascience/comments/1729cnh/webbased_app_recommendations/,8,"Hi all! 

I'm attempting to add some value at work. For context, I'm a Data Analytics Consultant at a small consulting firm where most of the data-related work is done by the DA team based out of India. The issue is that they just blew $10 million on a low-code app to streamline some of our company's offerings. Bottom line, it doesn't work and when it does it only works for cookie cutter cases. Regardless, they're the ones who get the funding and I'm the only Data Analyst in the US, where I was told they don't see the value in true DA/DS. What I would like to do is use open-source tools to recreate what the team in India was trying to do. Some of the base features would be being able to allow clients to fill out a survey of questions, read that to a SQL server I'll have to build, and publish multiple different dashboards (we currently use Tableau, but I figure I will need a web-based dashboard, such as Dash). 

When I was researching tools, they all read like ads, so I wanted to see what open-source tools others recommend from experience. For programming, I mainly use Python, though I am family with R as well. I'm also fine upskilling where needed, within reason (the bottleneck is time due to required chargeability at work and Master's coursework load).

Thanks in advance!

Edit: UI/UX will be pretty important since it is client work."
420,Is there any benefit for a Data Analyst to learn C#?,71,https://www.reddit.com/r/datascience/comments/171jptd/is_there_any_benefit_for_a_data_analyst_to_learn_c/,103,"I know that SQL and R / Python are the main languages to use, but is there any helpful reason to learn C#?"
421,The most sought-after Data Science skills,310,https://www.reddit.com/r/datascience/comments/171872q/the_most_soughtafter_data_science_skills/,89,"I've analyzed 9,261 job openings' descriptions in Data Science, Machine Learning and ML OPS ([https://jobs-in-data.com/blog/machine-learning-vs-data-scientist](https://jobs-in-data.com/blog/machine-learning-vs-data-scientist)) and prepared a list of the most sought-after skills. It turns out that the most desired skill is ... Communication - for all roles.

https://preview.redd.it/ey54l3290ksb1.png?width=2560&format=png&auto=webp&s=7a1746fa0d9ed2293374c54fce312a237d7d2eda

Communication actually surpasses Python in popularity, which I am really shocked about because it seems that for a Data Scientist, the most frequent communication should be with a computer.

https://preview.redd.it/b7ozarxq0ksb1.png?width=2560&format=png&auto=webp&s=3e8fc32e864ba4b0ed0edaf4e56daee4cadc6b62

About the dataset: 9,261 Job openings crawled from 1605 companies worldwide, between June-Sep 2023."
422,Clickable plots?,5,https://www.reddit.com/r/datascience/comments/171yhvm/clickable_plots/,16,"Hi all, I was wondering if there are packages/tools that allow one to click on data points and trigger actions, e.g. for interactive sites.

Example workflow for this:

\- plot helps to visualize data, click on a set of interesting outliers, those points are auto-selected and incorporated into a list, so that I can show a dynamic dataframe showing all of the selected points for more inspection.

\- click on a point to link to a new page view

I.e. tools like plotly allow me to inspect data nicely, even with hover data to show more information, or even the index of a point in a data frame. But then if I want to inspect and work with a set of points that I find interesting, right now I awkwardly have to manually note the data points, select them by code, and do something else. I'd like to do this in a more seamless way with a slicker interface.  


I think this might be possible with something like d3 but I'm wondering if there are easier to use tools. Thanks!

&#x200B;"
423,Huge data issues,10,https://www.reddit.com/r/datascience/comments/171mgku/huge_data_issues/,10,"So today it broke me, after weeks of battles. I work for a large international company but this company is so immature. It’s like a teenager that doesn’t know what its limbs are doing.

I know a large part of our work is cleaning data but my issues go beyond this. The data are fundamentally flawed, joins don’t work and literally no-one claims ownership of this, 30-70% of some features are just missing. I think this will be the demise of the company. Sometimes I literally cannot do my job.

Has any one here where worked for such a company? Has anyone ever successfully led change in such a situation?"
424,Eye Tracking Data,5,https://www.reddit.com/r/datascience/comments/171magw/eye_tracking_data/,6,"Hey all,

I am a neuroscience Ph.D. student working with some eye-tracking data. The typical approach in my lab has been to try and fit the data to a GLM. Which is fine as a first pass, but I don't want to be limited to just that. I am curious if anyone else here has worked with eye-tracking data and can point me in the right direction. As far as the details are concerned, I am collecting eye-tracking data in few experimental contexts. I would go into detail, but I want to stay at least a bit vague for privacy concerns. 

But to give you some idea of what I am doing, I have one task where participants are looking for a certain stimulus among distractor stimuli. The primary measurable output of this experiment is what stimulus they move their eyes to. But I am sure there is more information captured in the eye-tracking data that we can leverage. Another experiment is looking at overall gaze stability to infer cognitive mechanisms. 

If anyone is interested, I am willing to go in to more detail via PM. Any help would be appreciated! My first instinct to use some form of logistic regression or SVM and check performance. Let me know if I am on the right track."
425,Is it possible to have a non-Gaussian mixture and can it be easily decomposed?,4,https://www.reddit.com/r/datascience/comments/171p218/is_it_possible_to_have_a_nongaussian_mixture_and/,13,"I'm trying to work out a theory that the population distribution I have is a mixture. Specifically, I'm wanting to see if meaningful clusters exist in this single variable. The variable is a similarity measurement between a lot of smaller sets, so there's an expectation (and observation) that the distribution is heavily right skewed. I'm not sure if it's exponential, chi-squared, wiebull, or poisson but I think that's less about the geometry and more about the mechanisms that created it.

To be clear, the means of each would be different. The population shows multiple modes. 

I'm used to decomposing mixtures where there's an expectation that they are each normally distributed but I'm completely lost when that assumption isn't held up. I want to say that k-means (gmm being a generalization of this) assumes normal distributions. Would hierarchical clustering work here or is it subject to the same assumption?

I'm not super sharp on stats. I know enough to get by but it's an ongoing learning process. Apologize if I've made a mistake or an incorrect assumption."
426,Plotting pre-calculated embeddings onto tensorboard projector,0,https://www.reddit.com/r/datascience/comments/171mmpq/plotting_precalculated_embeddings_onto/,0,"Hello, I have a file with embeddings already calculated and I want to use tensorboard to project those embeddings. I have no need for metadata at this point. I want to know how to do it, all the tutorials I have seen use their own machine learning model to calculate the embeddings and then save to a checkpoint but I don't need to do that. Any tutorial or resource is greatly appreciated. "
427,Software Engineering to ML engineering/MLOps,6,https://www.reddit.com/r/datascience/comments/1717sp8/software_engineering_to_ml_engineeringmlops/,3,"Is software experience valued in the world of machine learning on the operations side? I'm currently working as a fullstack software engineer while rounding of a BSc in artificial intelligence. I develop applications for machine learning projects and am involved in A/B testing, some minor langchain stuff, data vizualisation, data modelling so there is relatively much alignment with AI. I was wondering whether this experience is valuable if I would want to switch to an engineering heavy ML role. Is there a lot demand for people that can deploy models, do A/B testing, make APIs, and maybe do some light modelling while not being at the level of the phds and MSc CS people that qualify for the straight up data science/research enyineer roles in terms of maths/ML?"
428,Lessons From my 2 Year Job Search,156,https://www.reddit.com/r/datascience/comments/170jlh2/lessons_from_my_2_year_job_search/,39,"I just wanted to share some insights from my lengthy job hunt that recently ended on a somewhat positive note. If this resonates with people, I might expand it into a Medium article. My aim is to discuss my experiences, help others, and encourage debate to refine these ideas. I've already applied these learnings to help friends land decent jobs, so I hope it helps you too. This is particularly aimed at those starting their careers in data.

A bit about me: I have 7 years of statistics education and a Master's from a reputable U.S. public school. Graduated amid COVID, I became a model & bottle promoter in Europe while freelancing as a data scientist/analyst. Landed a corperate Data Analyst role last month.

1: Experience Over Education

Your education should solely be a stepping stone to gain experience, be it through internships, entry-level positions, or research. Don't overestimate the power of theoretical knowledge; practical experience reigns supreme. Grades only serve as a ticket to initial experiences.

2 and 3: Refer to Point 1

4: Understanding HR/Recruiters

When writing your resume or preparing for interviews, keep it simple but impactful. Recruiters skim through resumes, so your accomplishments should stand out and be quantifiable. Misrepresenting numbers isn't advisable but emphasizing impact is.

5: Always Be Active

If you're job-hunting, always have a project in the works. Freelance gigs are relatively easy to find, and they add valuable experience to your resume. Keep records of your work—publish articles, maintain a GitHub repository, or hold onto contracts.

6: Networking and Luck

Networking is crucial, and often it's not about what you know but who you know. Being at the right place at the right time can spell success. Lack of social skills will be a bottleneck to career growth even when technical skills are stellar.

7: Company Culture vs Reality

Companies may claim to value innovation and talent, but what they're really looking for are reliable candidates who won't mess up. They're impressed by practical business experience, not academic projects or grades. Phrases like ""innovative culture"", ""entrepreneurial"",  ""solving the largest problems"", ""looking for the most talented people"", etc. are all lies especially for starting out.

8: Avoid Targeting Remote Jobs

Targeting only remote jobs was my biggest mistake. Remote positions usually require a significant amount of experience, so aim for local opportunities or consider relocating.

Final Words
Always prioritize your needs over the company's. Don't shy away from promoting yourself or taking new offers even at the last minute. Most companies are self-centered, and as an employee, you should adopt the same approach to your advantage.

Hope this helps, and I'd love to hear your thoughts!"
429,Removing outliers using DBScan,0,https://i.redd.it/0hs2dhpdgksb1.jpg,8,I’m working on this used cars dataset. I need to remove the outliers as there are a lot of them. Would DBscan be a good method to implement.. if yes then on which all columns??
430,Is it worth it double majoring in Economics and Science?,3,https://www.reddit.com/r/datascience/comments/170zg4y/is_it_worth_it_double_majoring_in_economics_and/,3,"I plan on transferring universities to pursue an Economics degree and maybe also double majoring in Data Science, however I noticed many Data Science job listings also accept Economics degrees. Is it pointless to major in both and I should try to diversify it, or would majoring in both actually make me a stronger candidate?"
431,Is it good to ask questions regarding a take-home case study?,2,https://www.reddit.com/r/datascience/comments/1713ly9/is_it_good_to_ask_questions_regarding_a_takehome/,3,"I have been given a case study as a next step in my interview. I have a few questions and doubts regarding the same.

Some of these doubts are about the terms they have used and their relevance to the dataset. 

Will it seem bad if I send out questions regarding this?"
432,Survival Analysis - Employee churn,1,https://www.reddit.com/r/datascience/comments/1716zm9/survival_analysis_employee_churn/,8,"Hey everyone  


I am working on a project for uni and I have chosen employee churn as my topic. One of the predictors, ""Reason for Termination"", has absconded, resigned, terminated and contract expired.

&#x200B;

Since I am looking for reasons why employees are churning and how to prevent it, should I exclude the option ""contract expired""? Absconded, resigned and terminated are all factors that aa company would want to prevent when hiring an employee but should they look out for employees who have had their contract expired since this is not really a red flag, for lack of a better term. 

&#x200B;

How would I handle the entries relating to contract expired?  "
433,A PhD in Economics or Masters in Data Analytics - Suggestions needed.,0,https://www.reddit.com/r/datascience/comments/1716u3j/a_phd_in_economics_or_masters_in_data_analytics/,1,"Hi everybody, hope you areall doing good. I need some suggestions, like the title says. 

Here is a little introduction about me - I have done my bachelors and masters in Economics (From Pakistan). Now, I was thinking to continue my studies further, I was determined to do PhD in Economics from USA, i was planning to apply this year but I decided to take a break this year and see what is it I actually want. During my masters and bachelors we have had various assignments and projects that would require us to analyse/visualise data and draw meaningful insights out of the analysis, using softwares like STATA, EViews, SPSS, Excel. I have always like playing around with data and using softwares. 

Now the thing is, i am in a quandary whether i should do a PhD in economics or do another masters in data analytics program. I am not sure which one is a wise choice, is there any one who has opted for data analytics with economics being their major? how did it go? which programs are better in this regard?

how should i take a start towards it? i have started to learn R language, what else can be helpful in this regard?

Looking forward to some valuable suggestions/advice, 

thanks"
434,Machine learning and statistic online courses,1,https://www.reddit.com/r/datascience/comments/1716aw9/machine_learning_and_statistic_online_courses/,0,"Today I was looking for an online course in ML and I ran into [this](https://twitter.com/caglar_ee) twitter (X) page which contains addresses to a lot of useful free online courses in AI, ML, RL and statistics.

I think it may be helpful to others to post it here."
435,Do most companies use AWS/Azure?,16,https://www.reddit.com/r/datascience/comments/170loiv/do_most_companies_use_awsazure/,14,"I understand these cloud computings as essentially borrowing ""highly efficient computers"" from amazon, microsoft, etc so I can do things more efficiently without worrying too much about hardware level logistics.

I'm trying to build some long term meaningful portfolio.

Is it realistic to build my own website and deploy the machine learning model (or statistical, whatever)  that has some regular updates? (hopefully it is useful as well)

I'm relatively proficient at anything related to math/stats but not so much on cloud computing.

Is this how things are done in the industry?

Would most jobs I apply in the States use cloud computing?

How much would this cost if I want to do this?

Any insight is appreciated!!

&#x200B;

(I'm on my way to get cert for AWS practitioner, but I'm also wanting to get some other ones too if it will be useful for this project. )"
436,Bayesian recommendations?,21,https://www.reddit.com/r/datascience/comments/170jcmg/bayesian_recommendations/,32,"Hello! Any recommendations (books, courses, articles, blog, podcast, whatever existent) to learn about Bayesian statistics for business and testing?"
437,Is it bad if i can't visualize DataFrame in Jupyter Notebook and pandas without turn it into Excel ?,1,https://www.reddit.com/r/datascience/comments/1714os7/is_it_bad_if_i_cant_visualize_dataframe_in/,4,"To be familiar with Excel but totally struggle with Jupyter Notebook, I usually turn the df to spreadsheet using pd.df.to\_excel(). Working with excel, I usually can do more and able to figure out stuff that can't be done with JN. Further more, using JN make me feel that i would miss something important in the dataset. Is this a bad practice and is there any tips to upgrade my dataskill with Jupyter ?"
438,Guidance,0,https://www.reddit.com/r/datascience/comments/1714oc4/guidance/,3,I want to learn data science. I don't know anything about it. Please suggest data science beginner level books. Or free online resources from where I can learn. Or should I go far six months offline paid data science course in my city? Other suggestions will also be accepted.
439,Best cloud solution for ML on huge dataset,8,https://www.reddit.com/r/datascience/comments/170pl0q/best_cloud_solution_for_ml_on_huge_dataset/,21,"Hi, It would be a great help to me if you could suggest me different ways I can do ML my dataset. My laptop is very old and my dataset is about 300k row x 150k columns. So rigorous feature engineering, different models and neural nets will be done also with cv and many more. 

I dont have a huge budget but I need to make it work. What are the options I could potentially explore to make my work fast as well."
440,Handling class imbalance in multiclass classification.,79,https://i.redd.it/z9uay6welbsb1.jpg,45,I have been working on multi-class classification assignment to determine type of network attack. There is huge imbalance in classes. How to deal with it.
441,What exactly is the job scope for a data scientist??,0,https://www.reddit.com/r/datascience/comments/1713g99/what_exactly_is_the_job_scope_for_a_data_scientist/,6,"I’m a ML engineer who recently joined a company and have been working closely with a senior data scientist for a few months now. He’s been working here a year before me, apparently had 10 years of experience and was working for a consultancy before this. He has been getting increasingly frustrating to work with.

Most of what he does is making charts and dashboards with SQL, meeting with the higher-ups of the business and overpromising them a bunch of “AI features” without any considerations to feasibility or cost. 

Anything that I asked of him that requires him using any technology outside a Jupyter notebook, he will claim that “it is not my job scope, I am not an engineer.” This includes basic things like version control or remote training. He believes that all he needs to do is to provide a POC… except..

..the POC he built on the notebook is completely unusable. I’m talking about stray lines of codes scatter across cells, not even a single function in sight, and utterly inefficient use of pandas. The worst of all, is that the POC model is trained on a subset of the actual data because, and I quote “my machine ran out of memory trying to fit the whole thing”, but don’t worry because “I’ve stratified the sampling.” (tbf the data is over 80gb.. but still)

I know that DS are not supposed to write production ready code, but this notebook is completely worthless. In my previous job I worked on automating testing and monitoring ML pipeline with a much bigger team, so I didn’t work with data scientists so directly. Last week, I chatted with my coworker in marketing, and apparently she tried to ask him for some analysis for user signups, and he replied with the same excuse: “this is not my job scope, I’m not a data analyst.” So now I have no idea what he actually does.

At this point, I have no idea what a data scientist’s job scope is or what to expect. I know many people on this sub claims that DS is more of a business role, but is this normal? I’m starting to think that he’s a fraud, but you can’t possibly do that for 10 years. 

I have no idea what to do. Is this normal for data scientists? Should I just readjust my expectation and rewrite the whole thing?"
442,What's one hard thing about being a data scientist?,62,https://www.reddit.com/r/datascience/comments/170alzu/whats_one_hard_thing_about_being_a_data_scientist/,88,"Hello everyone!

I've been diving into the world of data science and i'm curious about the challenges/inconveniences you experience as a data scientist/analyst.

I'd love to hear your thoughts about this. As a data scientist, what's one little hiccup or challenge you often come across in your daily work?

Looking forward to your insights!"
443,Question-Answers Model. What to us?,1,https://www.reddit.com/r/datascience/comments/1712czz/questionanswers_model_what_to_us/,0,"I have a project with a list of customer feedback and worker’s responses (so a QA model) These answers are related to internal company policies, so knowledge has to be trained. 

That being said, I’ve read into a few keywords, such as using DBSCAN to cluster, Seq2Seq. 

My question is: 
1. What should be my approach? 
2. How do I use a model from an open model from Huggingface that I don’t have to train for machine understanding towards English? 
3. How to generate output based on my datasets of questions-answers? 

Thank you for your help in advance!"
444,Looking for a tutor for SAS programming-- anyone?,1,https://www.reddit.com/r/datascience/comments/170ymu9/looking_for_a_tutor_for_sas_programming_anyone/,0,"I am learning SAS for my thesis project and looking for someone to tutor me in writing SAS code. I am familiar with the online resources for learning SAS... but finding it takes many hours to troubleshoot errors and I am also working full-time while completing my thesis.

I would be looking for 1-2 hours per week of virtual help with this from now until December and I will pay. If you are experienced with SAS and interested, or know of a pool of SAS programmers I could contact, please message me and I can provide more details!"
445,Why is data science still so hyped?,0,https://www.reddit.com/r/datascience/comments/1712php/why_is_data_science_still_so_hyped/,66,"It's a bunch of really cool jobs but where does all the hype still come from?

And why are there so many beginners that try to enter when it has been really difficult to enter the job market in the past couple of years?

Also, I've seen a lot of people wanting to transition into DS without having an understanding of what the job actually looks like. That's not a criticism of the individuals but it shows to me that there's a perception and weird incentivisation going on in the broader public.

It can't be the ""sexiest job"" label alone anymore and it feels to me like there's an delay/disconnect of 3-8 years between what people's expectations are and what is actually going on.

Don't get me wrong, I'm super happy that data work is getting so much attention but I really struggle putting the societal dynamics that must be at play here into words.

Are these normal time scales for these effects to be playing out? Is it down to DS being such a young discipline?

Any thoughts?"
446,Text Alias Modeling,1,https://www.reddit.com/r/datascience/comments/170ob14/text_alias_modeling/,14,"I have a dataset of true names in one column, and aliases in another. The idea is that a single name in the true column can have multiple aliases in the alias column. I need to build a model that will train on this data and learn to map aliases to true names to automate when more aliases get created for one of my teams at work. 

I've tried a standard neural net by first vectorizing the string values in each column, but that had really poor results, and then started looking into Word Embedding models, but that doesn't seem to fit exactly what I'm doing here in the project.   


So I'm looking for recommendations on models that I can use to try and accomplish this task. I've been Googling for a couple of days but nothing quite fits the scenario I have, most text models don't seem to map text to text but instead text to a quantitative value. Thanks for the insight!"
447,Data Science(s) in the plural,41,https://www.reddit.com/r/datascience/comments/16zw1dz/data_sciences_in_the_plural/,38,"I am lead of a new Data Science Division. The management team at our company is insistent that Data Sciences in the plural is a better fit. On my team we have statisticians, database managers, geospatial geographers, programmers, and data scientists. We are also incorporating machine learning as well. Google searches almost exclusively mention Data Science in the singular. Does anyone have any opinions or suggestions? Should I bow down and embrace the plural or should I be adamant about the norm of the singular?"
448,Product name matching - Entity Resolution or Enity Linkage or both?,2,https://www.reddit.com/r/datascience/comments/170e4n7/product_name_matching_entity_resolution_or_enity/,0,"**Context**

I am at the start of a project where I would like to map/match/link external product names to the respective internal product names. The goal should be to ingest related external information (e.g. stock number) of the external products into our system by joining the same products based on their product names. Short, the external product name should be matched to the internal representation of the product name.

&#x200B;

**Problem and Question**

I'm now doing some research about potential solutions and I'm having difficulties finding out if the nature of the problem can be allocated to Entity Resolution or Entity Linkage or if it even includes both of them. I'm asking this because I'm afraid to go down the wrong path when researching for a potential way to tackle the problem. I have seen the post about [key differences about entity linking and entity matching](https://datascience.stackexchange.com/questions/115528/exemplify-key-differences-between-entity-linking-and-entity-matching#:~:text=As%20depicted%20below%2C%20entity%20linking,reference%20repository%20or%20knowledge%20base.&text=However%2C%20in%20entity%20matching%20the,knowledge%20base%20do%20not%20exist.&text=mirror%2Dimage), but it's still hard for me to allocate the nature of my problem to one of them. Can please someone tell me if the problem can be allocated to Entity Resolution, Entity Linkage or both, and why this is the case?

&#x200B;

Thanks a lot!"
449,Can we take the probabilities from one model and make it a feature to the other model along with additional features?,14,https://www.reddit.com/r/datascience/comments/16zwzv6/can_we_take_the_probabilities_from_one_model_and/,9,"When my team mate used the probabilities from one model and used as feature to the other model the probabilities from first model was highest on the feature importance map for the second model.

Is this an example of stacked model or is it better to have trained both models with additional features and compare the accuracy of both models rather than reporting the accuracy of the linked model in step 1. 

Please share your experience. Thanks"
450,Classification/predicting of outliers,1,https://www.reddit.com/r/datascience/comments/170coig/classificationpredicting_of_outliers/,1,"I have a skewed depandant variable with few high natural outliers, I want to perform regression on it without removing outliers and also improve rmse score, how can I handle them? using feature engineering? build a model to classify them?  
Thank you"
451,Optimising Inputs to ML Model,1,https://www.reddit.com/r/datascience/comments/1709cts/optimising_inputs_to_ml_model/,1,"If you create an ML model, is it advisable to do a black box optimisation and find the optimal inputs to get the maximum/minimum output?

 Or does it only make sense to use ML models predictively, not prescriptively?"
452,sas - how to query the outlier from the output of the proc sgplot,1,https://www.reddit.com/r/datascience/comments/1708utp/sas_how_to_query_the_outlier_from_the_output_of/,3,"Here is the piece of code that write the data to a table:

    ods output sgplot=boxplot_data;
    proc sgplot data=mylib.calendar;
    vbox price;
    run;

and the data in the table looking like this:

&#x200B;

https://preview.redd.it/ngr15k82bbsb1.png?width=786&format=png&auto=webp&s=ace90c47416f4429d21e9cc78cbc26e1906441a4

Now, I want to query this data where the BOX(price)\_\_ST = 'FAROUTLIER' 

with this code:

    proc sql;
    select * 
       from boxplot_data (obs=50);
    where ""BOX(price)__ST"" = 'FAROUTLIER'
    quit;

But it didn't work. I can't query the column that has the ""\_\_"" in its name.

And the table properties show the column name and its label. But I can't query the label either.

&#x200B;

https://preview.redd.it/nufe0xksbbsb1.png?width=598&format=png&auto=webp&s=87279934c18e17dc763a8313ff2f919c7619e447

Any one done this before? How did you do it?

&#x200B;

Thanks!"
453,What do corporate data scientists struggle with the most at work?,135,https://www.reddit.com/r/datascience/comments/16z8pez/what_do_corporate_data_scientists_struggle_with/,121,"As a data scientist, if you could let someone else solve something for you what would it be?

I was curious to know the problems data scientists face. This can be anywhere from collecting data and cleaning data to making and deploying machine learning models."
454,Looking for a tool to help map two databases schemas against each other,2,https://www.reddit.com/r/datascience/comments/16zzta7/looking_for_a_tool_to_help_map_two_databases/,4,"I have two relational databases with \~30 tables each. While they both hold essentially the same data, the schema for each is wildly different. I eventually need to migrate the data so I'd like to build a good 1-for-1 schema map for each column from the origin database to where that would go in the destination database (or to note that it's data that doesn't need to move, for one reason or another).

I could certainly just manually build this all in Excel but that's boring and a time drain. Any good tools, preferably but not necessarily visual, that folks know that might work for this project? 

I've seen lots of good schema mapping tools online, but unclear that any of them are well suited for connecting the dots between two different database schemas."
455,What are some good scraping software to use for task automation?,5,https://www.reddit.com/r/datascience/comments/16zldu3/what_are_some_good_scraping_software_to_use_for/,1,"suppose that i have 1000 sites that i need to build a script to extract individually and need the data to be refreshed weekly, what are some tools/software that can help me to automate such task?"
456,How can I apply object detection and image segmentation functionality to my current custom-trained Image Classification model?,2,https://www.reddit.com/r/datascience/comments/16zsikw/how_can_i_apply_object_detection_and_image/,1,"So, a few months ago, I started developing this deep learning model, which was made purely to differentiate whether the input image is driftwood floating in water or a crocodile. To my knowledge, I leveraged the resnet50 pre-trained SoTA model to train my deep learning model, and for that, I downloaded almost 5k images of driftwood and crocodiles for my model training. Once the training was complete, I took the next step and deployed my model on the Hugging Face Spaces app, allowing my friends to put it to the test. But here's where I ran into a significant challenge: users could even upload their own selfies, and my model would attempt to predict whether they were a crocodile or a piece of driftwood!

So how can I leverage object detection or the image segmentation pipeline so that when the user inputs their image, it tries to detect the object from the photo and then detect whether the detected object from the given image contains a crocodile or not? If the crocodile or driftwood is not found, then it should return ""No object found"" or like that."
457,"When building out a matrix profile for a time series, what tests can be used to determine that both the bin size and window size are optimal?",9,https://www.reddit.com/r/datascience/comments/16zh6dt/when_building_out_a_matrix_profile_for_a_time/,10,"I'm playing around with adapting matrix profiles to my time series data and I want to ensure that the data and parameters are set correctly.

I'm working with a month's worth of data placed into 5-minute bins (288 samples/day). I initially rebinned to 1-hour but I wasn't sure whether or not that might hide certain higher frequency patterns or if it would just make it too noisy.

I'm also attempting to tune the window_size parameter used by the STUMPY python library (stumpy.stumpy function). This adjusts the length of the segments that the matrix profile algorithm uses to compare to measure similarity. If the window size is too small (fewer points), you are more likely to get incidental matches. If it's too large, you're less likely to appropriately match similar patterns.

There is seasonality in the series that reflects diurnal patters (activity spikes during peak operational hours and drops out during off-peak hours). Because of this, I wanted a window size of at least half a day (144 for 5m bins, 12 for 1h bins) or a third of a day (96 for 5m bins, 8 for 1h bins) to achieve the Nyquist frequency of the seasonality, if that makes sense.

Are there any tests that I could run to help identify and optimize both the size of the time bins and the window size?

One thing I noticed is that when adjusting the window size, the rate of change of the number of detected motifs isn't linear. I have a hunch that I could probably plot it out and use the elbow method but I need a sanity check before I try it out.

For the bin size, I usually use a Power Spectral Density plot to identify dominant frequencies (I mostly use that for selecting seasonality parameters for decompositions). For the 1h bucket series, there are 1-3 dominant frequencies well above the noise floor, which is good. However, when I use the 5m bucket series, there doesn't appear to be any dominant frequencies, just noise. Would that suggest that the 5m bucket series is suboptimal in terms of bin size compared to the 1h series?

I just need a second set of eyes on it to make sure I'm not misinterpreting or misunderstanding something. I'm also open to suggestions or ideas, if any are available."
458,Do you just learn on the job?,68,https://www.reddit.com/r/datascience/comments/16z2cge/do_you_just_learn_on_the_job/,37,"I studied data science in college, and I’m in my first job in a start up (been here about a year). There are three on our data science team (manager, another graduate and myself). Due to being in a start up, we all work on individual projects (as we do consultancy). Mainly data processing in sql/python + analysis

My manager is up to their neck in work, and I’d like if they had more time to actually teach us things. I am just learning by googling and doing. I think ideally in my head I would like to work on more projects with them, or maybe even shadow them once in a while and see how they would approach a problem or see their workflow. Is this normal?

I can read their code and analysis but I just feel isolated and would learn a lot more by actually interacting with them while working

Since joining have learned a lot more about ETL pipelines and cloud technologies, but honestly I’m not sure how much more I can learn here that I can’t learn in any other job.

I can do the work but I feel like I could be a lot more effective and efficient.

Do you just learn by doing in your job? Am I gaining the most knowledge that I can here? Is this normal? How did you advance to the next level?"
459,AI’s Data Cannibalism,1,https://www.reddit.com/r/datascience/comments/16znm3n/ais_data_cannibalism/,6,"I'm looking to read more on this topic mentioned in the title.

&#x200B;

Feel free to suggest books and articles"
460,How often do you use Operations Research (OR) in your work?,73,https://www.reddit.com/r/datascience/comments/16ysfr3/how_often_do_you_use_operations_research_or_in/,40,"I'm studying Operations Research in university, and I was wondering how often data scientists in different fields use OR, Linear programming, etc. In their work, and what tools they use. Thanks!"
461,Using pre-trained models as features?,2,https://www.reddit.com/r/datascience/comments/16zi4jk/using_pretrained_models_as_features/,3," Hey everyone!

Currently,  I am working on a project around music emotion classifcation/regression  model. Basically I am trying to predict a score to each emotion on a  given song.

The problem is that my  dataset has quite imbalanced scores (y). Most scores are centered  around a certain score range. Therefore, having difficulties predicting  scores that are further away of the mean values.

I  had this idea to bring in pre-trained (on other datasets and problems)  audio classification models into this as there are a bunch of good  performing pre-trained classification models out there already. The  prediction of these pre-trained models should be used as features (e.g.  prediction of genre, instrument etc) beside the original spectorgram in  my model.

I know this won't solve  the problem of imbalances in the scores but I thought maybe this could  improve the performance as the model would have more features to work  with.

Does this make sense?

I appreciate any input."
462,Project Ideas,4,https://www.reddit.com/r/datascience/comments/16zcw19/project_ideas/,9,"Hey guys
I’m looking for a project idea in Computer Vision. Been browsing through multiple datasets but haven’t been able to think of an idea that has not been implemented before. Can you guys help me out with some ideas? I’m a grad student. Thanks!"
463,Seeking Feedback Mechanism for Our Python/Dash Analytics Platform,0,https://www.reddit.com/r/datascience/comments/16zi29z/seeking_feedback_mechanism_for_our_pythondash/,1,"We are in the process of developing a data analytics platform for our client. This platform is primarily built using Python and Dash. We're exploring options to allow our clients to provide comments on each section of the analytics platform containing multiple pages.

Does anyone know of any methods or tools that would facilitate this interactive feedback mechanism.

&#x200B;

It would be better if we could track individual user comments. "
464,"What are some effective dimensionality reduction (unsupervised feature selection) techniques for a high dimensional, sparse dataset?",4,https://www.reddit.com/r/datascience/comments/16z8v18/what_are_some_effective_dimensionality_reduction/,4,"I am considering comparing mutual information scores, but I also don't think I understand MI well enough. 

For example, I(X;Y) = H(X) + H(Y) - H(X,Y). To me, visualizing H(X) and H(Y) as venn diagrams and H(X,Y) as the information from both X, Y (like an overlapping venn diagram) makes me think that when X, Y are disjoint, then MI is 0 and when X, Y overlap completely, then the MI score will be high. So, I'm thinking that a high MI value is ""bad"" since this means X, Y would be redundant. I am not sure if my understanding here is correct. 

Another method I have tried is to binarize the data for each feature (represented as rows in my dataset) using ""present"" (1) and ""absent"" (0). The main issue I have run into doing this is that I am trying to then create a **distribution** to compare the features (such as seeing what percent of 1s and 0s I find in each feature), but here is the issue: 

Let's say that feature A has 50% 1s and 50% 0s, and feature B also has 50% 1s and 50% 0s. So, it will look as if the distribution of their values is identical, though it could be that feature A and B are ""opposites"":

Feat. A: [0, 0, 1, 1]

Feat. B: [1, 1, 0, 0]

So, I wonder if there is a better way to compare the distributions of the features once I have made the data ""present"" (1) and ""absent"" (0). 

I am also looking at making a Probability Density Function for each feature to compare them, but it's not clear to me how I would go about creating such a PDF for each feature given that I don't know what the probabilities associated actually are. Should I be binning the data then finding what percentage falls in these intervals?

______

Overall, I am looking for advice on where to find useful information on how to compare features for **unsupervised** feature selection, particularly in regards to how to use and compare mutual information scores, how to create PDFs for features, and how to compare distributions between features after they have been binned to avoid the problem I mentioned (with how [0, 0, 1, 1] and [1, 1, 0, 0] would appear to have the same distribution). 

Relevant textbook resources and other reliable source recommendations would be much appreciated. 

Thank you."
465,The [lack of] quality on this sub,201,https://www.reddit.com/r/datascience/comments/16ygt96/the_lack_of_quality_on_this_sub/,123,"It’s been clear this sub has been abandoned by its mods:

*Inactive on Reddit (>1year with no posts/comments):*
u/shaggorama, u/vogt4nick, u/StatsPhD

*Inactive on the Sub (>30d with no posts/comments):*
u/Geckel, u/browneyesays, u/mhermans, u/patrickSwayzeNU

*Active within the last 30d:*
u/dfphd, u/JaJan1, u/Omega037


Here are some of the posts obviously rule-breaking or off-topic that mods do NOT remove:

- [A person asking for online DA tools](https://reddit.com/r/datascience/s/wVrQkHrI4H)
- [A person asking about datasets](https://reddit.com/r/datascience/s/sAvfpDOc4I)
- [A person asking for recruiter’s responses lead times](https://reddit.com/r/datascience/s/b7ssIgMuik)
- [A person asking about cover letters](https://reddit.com/r/datascience/s/3sdLpNhMmL)
- ... the list goes on with absolute beginner questions, and low-quality posts. 

All these posts were written in less than 1 week. As we can see, mods do nothing.

The last post a mod did on the sub was 145 days ago.

What can be done to get the mods to act upon the rules they set themselves? At this pace, we’ll lose the few experienced DS who still roam around here."
466,What aspect of Data Science do you enjoy the most?,43,https://www.reddit.com/r/datascience/comments/16ylnuy/what_aspect_of_data_science_do_you_enjoy_the_most/,28,"What part shines the brightest on your day/s? Do you never get enough of presenting data? The sense of pride & accomplishment when the project is finished? Just writing code in your favorite language?

My favorite in my limited experience is the idea spitballing phase of figuring out a solution. Throwing spaghetti at the wall, seeing what sticks and diving into how we could apply it to the problem at hand. I think it boils down to a sense of camaraderie & the chaotic diving down rabbit holes."
467,Hiring hell,193,https://www.reddit.com/r/datascience/comments/16yc89t/hiring_hell/,123,"Gonna keep this short because I know we hate talking about hiring 24/7, but I genuinely couldn’t believe what my team just went through. 

Medium sized financial firm and from top, there’s 10 or so positions specifically for new grads next May.

We posted our position and got 200+ applicants in a week. 

And sifting through them were a nightmare. So so many people who weren’t new grads when the description specifically said that, were analysts using excel, weren’t graduating programs but data boot camps, had rip-off personal projects at the top of their resume. 

It was infuriating. 
Finally got down to 10 for interviews, and ended up reaching out to internship managers to inquire about the kids. Several good reviews and we had 3 really impress us in technical interviews. 

Ended up with a pretty good one that accepted graduating with Comp Sci and Math, but still, it’s mind boggling that so many people apply to job postings they’re WAY under qualified for.  

Just a rant."
468,Do you worry that outsourcing will take your job?,2,https://www.reddit.com/r/datascience/comments/16z8d2e/do_you_worry_that_outsourcing_will_take_your_job/,18,"I work in consultancy but I'm considering a pivot into data analysis. However, I am worried that companies can easily hire data analysts and scientists in other countries for a lot cheaper whereas consultancy is better protected against this due to the importance of face to face meetings, on site work and local knowledge.

Due to Covid, many companies have learnt how to create remote teams, which may accelerate this change further. 

Is this a major risk over the next five to 10 years? Can we expect fewer jobs in The West and lower wages due to outsourcing to other countries and remote working?"
469,Does anyone know any tools that helps people convert their python code into streamlit apps?,0,https://www.reddit.com/r/datascience/comments/16zgo76/does_anyone_know_any_tools_that_helps_people/,4,"I am a data scientist. I usually build ML models and convert them into streamlit apps. Does anyone know any tools that helps automatically convert my python/ML code into streamlit app so i can save the hassle.

&#x200B;

&#x200B;"
470,Indexing Large Datasets - A 5x Improvement in Vector Recall Speed When Moving from IVFFlat to HNSW,3,https://postgresml.org/blog/speeding-up-vector-recall-by-5x-with-hnsw,0,
471,What is your go-to for data quality in Computer Vision?,4,https://www.reddit.com/r/datascience/comments/16yvbbr/what_is_your_goto_for_data_quality_in_computer/,4,"For those working on CV (unstructured data), how to you approach data quality?

I've been working with data quality for structured data, and I have my methods for assessing data quality, but I'm fairly new to CV and a bit confused about how to evaluate the quality of my data, specifically for computer vision applications.

I know that data quality is crucial for the success of any machine learning project, but when it comes to images and videos, what are the key factors I should be looking at to ensure that my data is up to par?

Are there any specific metrics or tools I should be using to measure the quality of my training data? And how can I tell if my dataset is biased or unrepresentative of the real-world scenarios I'm trying to tackle?

Any guidance or advice on assessing data quality for computer vision would be appreciated! Thanks in advance"
472,Multilingual Reading Skills of Language Models,2,https://www.opensamizdat.com/posts/belebele/,0,
473,"What I wish I had known earlier in my career, particularly with disorganized companies",252,https://www.reddit.com/r/datascience/comments/16y0vfi/what_i_wish_i_had_known_earlier_in_my_career/,50," I'm quoting directly from a Reddit user named funbike. This is the rule you should abide by in organizations. I also made the same mistake when I joined a company, attempting to prove myself.

"" 

After being a fool in my early career trying too hard to impress, this is how I handle this kind of thing these days:

* Document EVERYTHING. Follow-up verbal conversations with summary email. When things go south, I'll be able to prove I warned them.
* Give *realistic* estimates on how long things will take. Whatever I say is usually twice how long I actually think it will take, because things never go like you think.
* Make it clear that that longer-term estimates will be less accurate the farther out they are, because software is notoriously difficult to estimate.
* Tell them to their face that we *will not* make the unrealistic dates they've set, and to prevent in future to always consult first.
* I will *not* work overtime due to artificial deadlines. I'll do O/T for extreme exceptional cases only, such as a one-time short-term crisis or for a regulatory-mandated deadline. By 6pm I'll be at my house.
* Explain quality should never be abandoned for speed. It will violently backfire in the end, with the opposite effect.

I stand my ground. I can make them mildly unhappy now, or furiously disappointed in our results in the future. I'll take the first one please.

Even if you were to heroically meet their unreasonable date, they'll just expect more next time. You'll burn out and maybe the next time you'll have an embarrassing failure even with crazy overtime. They'll say ""tsk, tsk"" and blame you. Don't fall into this trap"""
474,Doing Part-Time Social Science Research,2,https://www.reddit.com/r/datascience/comments/16yyleb/doing_parttime_social_science_research/,5,"I was wondering if this was an option as I just finished my master's degree, and I'm iffy about going for my Ph.D. My interest in research is Political Science research with Quantitative Methods.

I know that some think-tanks have unaffiliated fellows. and I know a few individuals that are Non-Resident Fellows at CSIS, but they're very senior and sometimes teach ML courses at universities as well.  

I basically just want to get a nonpaying part-time research analyst role so I can do academic research while not quitting my job in tech as a Data Engineer. Some of my friends have suggested just reaching out to professors asking if I can do research with them and if they need help doing research in R. But a think-tank or nonprofit would be great as then I can put that research on my resume or Linkedin."
475,Code Signal Data Analytics Framework Questions ?,1,https://www.reddit.com/r/datascience/comments/16z0gck/code_signal_data_analytics_framework_questions/,6,"Was wondering if anyone gave the Data Analytics Framework assessment. 

Time crunch is a major factor I feel. The last of the questions and ability not to view SQL ctes were nightmare. 

&#x200B;

Score 338/600 after solving 10 questions out of 15. Is this any good ? "
476,Network Theory to Model CFB outcomes,2,https://i.redd.it/cz0ybu57gzrb1.jpg,0,"Just thought I post some projects I have been working on in my free time. Trying to figure out the most objective way to rank fbs teams. 

Any cool projects y’all are working on?"
477,What industries wont you work in again in datascience?,247,https://www.reddit.com/r/datascience/comments/16xldj9/what_industries_wont_you_work_in_again_in/,130,"For me,

Advertising -  Ive never had to help more co-workers with sql joins in my life. most analyst and data engineers ive worked with had horrible technical skills and leadership was ok with that.  They just bought them alteryx and my email box continuously got spammed emails on a loop because they kept forgetting the one record node and all my data started getting dupes in my database.

Finance -  I started my career at a large financial institution and want something a bit more laid back.

&#x200B;

On the flipside, ive had good experience in automotive. all my coworkers were extremely technically competent and i learned alot. i did some cool projects too that got me started in datascience"
478,LLMs?,0,https://www.reddit.com/r/datascience/comments/16z3y8h/llms/,117,"I'm a FAANG data scientist with 5+ years of experience; I've grown increasingly concerned that LLMs will begin to replace a LOT of the work that data professionals currently do. From easy things like dashboard generation to tough things like specific deep dive research questions, seem like we're walking into a world where the skillset of the analyst / scientist is a pre-req for a different position as opposed to a job in and of itself.

Thoughts? How are you preparing for much of this work to become automated? What other skills do you think are on the horizon (please don't say prompt engineering)?"
479,How do you handle making mistakes on the job?,22,https://www.reddit.com/r/datascience/comments/16xxndf/how_do_you_handle_making_mistakes_on_the_job/,21,"What are some of the biggest mistakes you guys have made and how do you handle them?  Especially when there is a time crunch.

I’m a quality data analyst for a steel company and have been in this position for almost 2 years.  I finished my masters in data analytics this past May, so this job has been my only real experience in the world of data.  I want to transition to data science in this next year.  In my free time, I take Codecademy courses to learn Python and SQL and I will eventually dive into Java as well.  I take what I learn and I try to apply it to my job.  We’re a legacy steel mill, so there is no fancy automation, the business and production systems don’t communicate very well, data can only be gathered through exporting reports from these systems in csv files.  So I’ve been able to sort of make my own database using the tools I’ve been approved to download (basically just anaconda and power bi).

As the only data analyst in my mill, with no previous steel making background, my company relies heavily on my data analytics to make business decisions both small and large and sometimes is overwhelming pressure to be precise.  Luckily I haven’t had any major mistakes.  The downside is I’m the only person doing the job I do and there isn’t a whole lot of computer literacy in the management, so unless my conclusions appear extremely illogical to them, they just roll with it. I’ve definitely made mistakes along the way but have caught them myself, sometimes working through the night so I can hurry and send emails out to disregard my previous work and look at the revised stuff.  

This just made me wonder how others handle mistakes both when they catch it and when they don’t catch it.  I understand larger companies probably have a team of people doing the same projects or can lend a hand to be a 2nd pair of eyes.  

Maybe I’m just overdue to make my first big mistake lol.  I feel like I make a lot of decisions day-to-day that I have to cross my fingers on."
480,My F100 company analyzed why our good data scientists are good and here's the recap,486,https://www.reddit.com/r/datascience/comments/16x6t1p/my_f100_company_analyzed_why_our_good_data/,178,"A small team of internal researchers inside the company spent time investigating which data scientists preformed the best, which preformed the worst, and what factors played into this. 

The top 3 indicators of a high preforming data scientist were:
1. The number one predictor of a preformant data scientist was proactive communication. Be it speaking up in meetings, pinging people in chat, voicing concerns with a work plan, these data scientists communicated on their own initiative and their ability to get things done and make an impact is recognized. 
2. They are capable of flushing out requirements and working on complicated tasks without managerial intervention. A good example of this could be manager says we need to build a model that satisfies xyz objectives and that there are additional business reqs we'll need to flush out. 2 or 3 data scientists go do all the work to get the data and flush out the requirments while making all the plans amongst themselves and basically just keeping the manager in the loop on what's happening. 
3. They focus on adding value over pursuing technical solutions. Often times the simpler modeling approach is good enough and it solves the problem in a quick fashion. 


Things noted about low preforming data scientists were:
1. They were reactive in their communication
2. They often times missed deadlines that they themselves set and never communicated that there were issues or that the deadline would be missed. 
3. They often focus on tasks like attending all of their meetings or immediatly responding to emails rather than meeting project goals and deadlines
4. They focus too much on perfecting the POC solution which later leads to a lot of rework / wasted time.
5. They're overly dismissive in their communication. Weather it be asking for feedback and validation and then disregarding it when it doesn't align with their ideas or simply dismissing the ideas of others in general. 
6. They create drama."
481,[R]MMLU’s Moral Scenarios Benchmark Doesn’t Measure What You Think it Measures,0,https://medium.com/p/74fd6e512521,0,
482,ROI framework for data science,2,https://www.reddit.com/r/datascience/comments/16xwqmd/roi_framework_for_data_science/,1,Does anyone know of a good example of a return on investment framework for data science work? Or even a set of principles to work from? My team wants to demonstrate its value (more objectively) - and estimate the value generated from proposed initiatives - but there's little to go on in the literature.
483,"How long did it take you to self-learn data science and afterwards, how long to get employed?",2,https://www.reddit.com/r/datascience/comments/16y0lih/how_long_did_it_take_you_to_selflearn_data/,12,"To anyone who taught themselves data science and then achieved employment in a data science role, how long did it take you to learn in hours per day? And additionally, how long did it take you after you stopped learning to find a job and keep a job?

If you did not self learn or hold a job afterwards please do not reply with any speculations. "
484,"Weekly Entering & Transitioning - Thread 02 Oct, 2023 - 09 Oct, 2023",9,https://www.reddit.com/r/datascience/comments/16xmlky/weekly_entering_transitioning_thread_02_oct_2023/,127," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new)."
485,How true is this?,266,https://i.redd.it/1rfskuxv6krb1.jpg,103,
486,Which industries have the most lacking data architecture for data analysis/modelling?,1,https://www.reddit.com/r/datascience/comments/16xzxkb/which_industries_have_the_most_lacking_data/,2,"I have noticed some industries or domains are lacking in integrated data architecture (data warehouse, let alone data lake). One example that comes to mind is marketing where the different levels in data sources makes it difficult for integrated data architecture, hence, also difficult for cross-source analysis for the KPIs.
And also on the vice versa which domains are leading in this?"
487,Benefits of converting DICOM images to PNG's,0,https://www.reddit.com/r/datascience/comments/16xzuxi/benefits_of_converting_dicom_images_to_pngs/,1,"I try to understand what are the benefits to convert DICOM images to PNG's.  
Context:  
I have DICOM images which I already extracted the useful meta-data I want to use.  
Those images are for a task, classification-detection pipeline of some disease.

So as I already asked, what are the benefits of converting those DICOM files to PNG's rather then just using pydicom and the dicom pixel\_array?

Reason I ask this is because I saw many top 5 users on kaggle do this when dealing with DICOM images.

If I understand how networks actually works, they get as input an array of pixels as floating point numbers no? So what's the differences between DICOM pixel\_array to PNG's pixel array and numpy array or tensor? both are eventually will be fed to the network as a tensor of floating numbers.

Is the reason is because PNG's are usually faster to train?

Is the reason is because PNG's have more libraries support for preprocessing / augmentation / etc. ?

Is the reason is because PNG's are the format many pre-trained models expect to? (I write this knowing it's 99% not true, as mentioned the tensor thing)

Thanks in Advance, and Please, forgive my English (I could use AI tools to fix it but I feel addicted already)  
"
488,How can an LLM be good at compressing images and audio?,2,https://www.reddit.com/r/datascience/comments/16xrl3p/how_can_an_llm_be_good_at_compressing_images_and/,1,"This paper seems to say that an LLM trained on text can somehow be good at compressing not just text but images and audio. Intuitively this seems improbable to me. How does this work?

[https://arxiv.org/pdf/2309.10668.pdf](https://arxiv.org/pdf/2309.10668.pdf)"
489,"Second Data Project : Web Scraping, I am a beginner, Help with suggestion!!",0,https://www.reddit.com/r/datascience/comments/16xxkxs/second_data_project_web_scraping_i_am_a_beginner/,0,"Hello  everyone!!

I have come up with my second project and I am very excited to share here. I have done this work with a day of learning web scraping. please review my project and give feedbacks, suggestions and do not hesitate to leave brutal comments. Also, i request to help me with my next steps on web scraping. 

I would like to thank this community for letting to share my projects!!

project title: Nepali Beverage Seller data web scraping

[https://www.kaggle.com/code/aadeshpradhan/nepali-alcohol-seller-data-web-scraping-cheers/notebook](https://www.kaggle.com/code/aadeshpradhan/nepali-alcohol-seller-data-web-scraping-cheers/notebook)"
490,Harnessing LLM Alignment: Making AI More Accessible,0,https://www.reddit.com/r/datascience/comments/16xx3oy/harnessing_llm_alignment_making_ai_more_accessible/,0,Let’s look at an example of using two classifiers from Hugging Face to enhance the FLAN-T5 model’s ability to write summaries of news articles that are both grammatically polished and consistently neutral in style. [https://opendatascience.com/harnessing-llm-alignment-making-ai-more-accessible/](https://opendatascience.com/harnessing-llm-alignment-making-ai-more-accessible/) 
491,A/A testing,0,https://www.reddit.com/r/datascience/comments/16xx1e2/aa_testing/,0,"While running 20 simutanious A/A tests, should each of them be allocated to 100% traffic? Or should all if them cumulatively be allocated to 100% traffic?"
492,Quick review of most used algorithm answers,2,https://www.reddit.com/r/datascience/comments/16xriok/quick_review_of_most_used_algorithm_answers/,2,"First, thanks to everyone that answered my previous post !

So, following this previous post ([https://www.reddit.com/r/datascience/comments/16tgojm/what\_kind\_of\_algorithm\_do\_you\_use\_the\_most\_as\_a/](https://www.reddit.com/r/datascience/comments/16tgojm/what_kind_of_algorithm_do_you_use_the_most_as_a/)), I'm giving here a quick review of the most common answers.

Here it is:

* Gradient boosted machines (22): XGBoost (12), Light GBM (8), Catboost(2)
* Linear methods (19): Linear Regression (9), Logistic Regression (5), GAM (3), OLS (2)
* Random Forest (or tree based algo) (9)
* DBScan (4)
* DNN / CNN / GNN (4)
* Clustering algo / K-means (3)
* ARIMA (2)

&#x200B;

The number gives the number of time an answer appeared. I put here only answer that appeared at least 2 times.Also, I tried to gather some answers, but I don't know all the algorithms or tools your are using. So please forgive me if I did some mistakes or approximations in the way I gathered answers."
493,Thursday Oct 5th - London meetup - working in data and tech!,0,https://www.reddit.com/r/datascience/comments/16xtsax/thursday_oct_5th_london_meetup_working_in_data/,0,"Any Londoners out there? **I'm hosting an in-person meetup at Bubba Oasis in Islington this Thursday** to help educate aspiring data analysts and people who want to work in tech about insights and learnings from inside the industry.

After hosting a few online workshops earlier this year, I started a data analytics bootcamp to directly educate people on the skills required for the job - which, unfortunately, is not really taught in bootcamps, online resources, or even grad school. I'm currently on a break between cohorts and thought I'd to host a few in-person events as I believe there is so much more that can be learned as a dynamic community than as isolated self-learners.

At the event I'll mostly be having an open-ended discussion on topics like - what skills are actually used on the job, how do you package insights, how do you make your portfolio and resume stand out, and what things you should do in a technical interview. I'm open to hearing what you would like to discuss as well. The last event in Paris was a lot of fun and we had a great discussion with 8-10 attendees.  
**The MeetUp link is in my Reddit bio (and so is my LinkedIn - feel free to ask me questions there).** Please only RSVP if you intend on coming, so I can have an accurate headcount - thank you!

Note: Meetup has a bug where I can't adjust the timezones. The event is this Thursday, Oct 5th 7-9pm."
494,Data Cleaning - Correcting erroneous text inputs,0,https://www.reddit.com/r/datascience/comments/16xspby/data_cleaning_correcting_erroneous_text_inputs/,1," Hi. I'm a beginner in data analytics and studying on my own, I use Python by the way. Just wondering how you guys deal with erroneous text input. Also English is not my first language so apologies for some grammatical errors.

I have a dataset with a total of 5M records. There's a feature called ""name"". I want to make the data consistent.

Some of the errors I found are:

1. ""&"" was typed as ""\&amp;""
2. Random "","" or any symbols
3. missing letters/wrong spelling and other typographical errors

and there are lots of other errors but I won't list it all for the sake of simplicity.

What I wanna know is if there's a way to just automatically detect these errors like by counting duplicate values and the highest number of counts will be the basis to update records for this feature that has errors.

I mean, I won't ask for a specific solution/script for this problem but would like to have direction on how to approach this. Maybe you can recommend a topic or tutorials that might help.

Thank you Very Much."
495,"What kind of questions should I expect for this upcoming MLE/DS interview, given this unorthodox scheduling?",1,https://www.reddit.com/r/datascience/comments/16xrjix/what_kind_of_questions_should_i_expect_for_this/,4,"My dream company, a large Scandinavian company focused on traditional engineering, offered to interview me for two positions (MLE and DS) at the same time. The HR said the hiring manager decided to skip one technical interview and proceed directly to a panel interview with 10 interviewers.

The first 30 minutes will be another technical interview. I feel this means there won't be enough time for coding, only questions about transformers, LLMs and in-domain knowledge about their industry. Could I be very wrong?

This will be followed by a 40-minute presentation of my achievements for the panel, and a 20-minute Q&A session. A 30-minute behavioral section with the HR and the hiring manager comes last."
496,"What is the best set of universal semantic embeddings for implementing vector searches across large documents, and has it changed drastically before/after the OpenAI boom?",2,https://www.reddit.com/r/datascience/comments/16xlr5l/what_is_the_best_set_of_universal_semantic/,3,"I understand I'm in way over my head here, but has vector searching always been this powerful? Or have embedding models gotten 10x better in the past 5 years?  


Also, how can AI leverage the results of a vector search most efficiently? I'm assuming taking top ""n"" results then putting NLP on top of the already vectorized results to check more deeply for context and intent?"
497,"[Q] To all data scientists here who graduated with a stat degree, do you apply all your college stat knowledge to your current job?",18,https://www.reddit.com/r/datascience/comments/16x200r/q_to_all_data_scientists_here_who_graduated_with/,11,
498,Have you ever had a job that essentially wants you to do *less*?,138,https://www.reddit.com/r/datascience/comments/16woyff/have_you_ever_had_a_job_that_essentially_wants/,46,"I've always had jobs that expected a really high rate of productivity with extremely tight deadlines on projects - the sooner I could deliver, the better, as long as quality wasn't effected. I've always been praised for this, too.

Now, I've been in my first official DS role for a few months, and my boss (who has lots of experience/has been with the company for a long time) has been telling me in our private meetings that I should intentionally take a long time/wait to deliver my projects to our clients even if it doesn't actually take me very long to complete them. Again, quality isn't an issue. Is this normal? What could it be about?

Update: Wow! This blew up overnight! Thanks, everyone, for your input!"
499,Eastern University’s MS in Data Science | My review,6,https://kolkena.medium.com/eastern-universitys-ms-in-data-science-my-review-6f370825df59,2,
500,Do models still matter?,31,https://www.reddit.com/r/datascience/comments/16wpci5/do_models_still_matter/,31,There’s a lot more focus on implementation than back a few years ago when there was  POC after POC but far fewer models made it to production. There was also the beginnings of more focus on explainable ML and more focus on scrutinising models for bias of different types. However as MLOps has really taken off the focus on productionising seems to have lead to less focus on the models themselves. Is that still out there or is it just that the extra noise on the production side makes it harder to find it?
501,Indian working culture or exception_navigating Cultural Differences in a Big Company,0,https://www.reddit.com/r/datascience/comments/16xcn44/indian_working_culture_or_exception_navigating/,1,"I'm a first generation immigrant, and I've recently joined a team in a large organization that has a lot of folks with Indian heritage, including my manager.

In my previous data-related roles, I've always been the type to speak up when I'm sure about something and ask questions when necessary. But as I collaborate with my Indian colleagues, I've noticed a distinct approach. They tend to view caution as a weakness and embrace assertiveness. There are instances where they confidently express opinions without thorough research, even if they may not be accurate. It's frequently prioritized to appear intelligent in front of directors, with visibility being held in higher regard than actual substance. They also exhibit a strong inclination to submit to their superiors and naturally anticipate a similar level of submission from their team members. I often sense that every conversation is focused on extracting something from me rather than fostering collaborative efforts toward a shared goal.

This is all new to me, and I'm keen to learn how to work effectively in this diverse environment and what to understand the motivations for this behavior"
502,Interested in using data from a different domain to forecast to another domain,0,https://www.reddit.com/r/datascience/comments/16x9vdv/interested_in_using_data_from_a_different_domain/,0,"Hey everyone novice data scientist. 

A few months ago my country removed fuel subsidies, which has massively impacted the price of fuel and has been skyrocketing. There are other countries in the same region which have done similar such subsidy removal. I was curious to know if it is possible to use dataset from a different source (countries in this case) to forecast another. Obviously there will be a need to acknowledge differences in certain features such as GDP, unemployment, economic conditions, exchange rate, global oil prices and so on. 

My question if there is an established technique or even terminology for doing something like this. Or will this be a bad faith data science use case. 

Note that I have looked into the concept of transfer learning, but not sure if its applicable here. Again i am new to this field

Looking forward to your responses :) "
503,Data science coming back again and ML dying ?,22,https://www.reddit.com/r/datascience/comments/16wox7j/data_science_coming_back_again_and_ml_dying/,87,"
I feel like the ML tooling and infrastructure are improving a lot, and in the near future, we wouldn't need ML engineers. Data scientists will directly deploy their models. Software engineers and data engineers will handle the rest"
504,What are some examples of business tradeoffs between a thing you can measure well and a thing you can’t measure well?,1,https://www.reddit.com/r/datascience/comments/16x85v4/what_are_some_examples_of_business_tradeoffs/,12,"The discussion on how having remote teams gives you access to a bigger pool of talent (measurable) but reduces company culture (hard to measure, at the very least) got me thinking about what other tradeoffs like this can make decisions challenging."
505,LangDiversity: software to identify LLM errors,0,https://www.reddit.com/r/datascience/comments/16x84o1/langdiversity_software_to_identify_llm_errors/,1,"Due to challenges such as hallucination, detecting errors in the output of a given prompt becomes an important challenge.  LangDiversity is an implementation of ""diversity measures"" that are domain independent and can be used to measure the uncertainty in the result of a language model.   

Type pip install langdiversity   
Video: [https://www.youtube.com/watch?v=86J\_K9mR7lw](https://www.youtube.com/watch?v=86J_K9mR7lw)  
Web: [https://neurosymbolic.asu.edu/llm-correction/](https://neurosymbolic.asu.edu/llm-correction/)  
Visit [https://github.com/lab-v2/langdiversity](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbnRVeHZVSm9sazhvU2VtaDRaQ0w0aFdUSnhnQXxBQ3Jtc0trbUJPSnlwUTZIUzVwY3B2ZWtiNFpwLS1vTC0tYmdRa3ZuNjJiblBfY2I4X0EtX3c0cmNhWkFvTmdXWndxeEc4b0h6OEZaLVc2OTVRZVF1cUhLZEVmUHZyZzA3bklrRTZCWnpwTFFNVEZ6SHJPYm84dw&q=https%3A%2F%2Fgithub.com%2Flab-v2%2Flangdiversity&v=86J_K9mR7lw)   
Read the paper: [https://arxiv.org/abs/2308.11189](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbnd1ZnBPSVBMdjJBYXFxbWdXa2tfYzIweGtzZ3xBQ3Jtc0trc1lqYXhEVlF3cVRCcGxqbV80M0xHS2VaTGEwR3o2VmlJeFVHdFc1X1VDdlRGcTdwSUpjZXV6QnNLTUdyOGhoMEpEQjVBSEl4VDQ2TjBhVU0xbjBZa1VGODRLWmVseDRSaDhUNGRnbHVPVnQ2cWpNcw&q=https%3A%2F%2Farxiv.org%2Fabs%2F2308.11189&v=86J_K9mR7lw) 

&#x200B;

https://preview.redd.it/p4w9ou5msmrb1.png?width=1021&format=png&auto=webp&s=8a138d0569bfac27763145ad1f4ad7d05a5fce15"
506,Good textbooks at the intersection of ML and time series analysis?,10,https://www.reddit.com/r/datascience/comments/16wrs32/good_textbooks_at_the_intersection_of_ml_and_time/,6,"I am looking for a textbook which describes modern approach to time series analysis. So far the textbooks I have seen belong to the two extremes. I come from academic statistics background and find classic time series textbooks (Hamilton, Tsay) too academic, narrow in scope and somewhat outdated. This is one extreme. On the other hand, there seems to be many new textbooks which treat time series analysis from industry ML/SWE standpoint. At the first glance those new textbooks look great. But whenever I start reading them, I get the feeling that authors simply copypasted a bunch of examples from various sources. They often spend many pages discussing trivial programming or data infrastructure issues. And then they skim or do not even mention such fundamental concepts as stationarity. Furthermore I often doubt whether authors of such new textbooks actually understand what they are talking about. That's another extreme.

Are there any good modern time series textbooks? By ""modern"" I mean textbooks which consider the wide range of methods (including ML models) for time series modeling without limiting scope to a few models for which we have statistical inference theory."
507,I want to know what the day-to-day work of the Fraud Data Scientist do?,5,https://www.reddit.com/r/datascience/comments/16ww2bo/i_want_to_know_what_the_daytoday_work_of_the/,5,"There are a lot of job posts for Fraud Data Scientist in my country for the banking, e-commerce, and tourism industries. I know that there is definitely data analysis involved in the work process, but what about the machine learning model? Is it necessary or practical to use AI for Fraud detection (Kaggle competition excluded)? I think it might be fun and challenging to handle the highly imbalanced dataset but doesn't it just visualize and aggregate data to see the fraudulent behavior? For example, in the famous case of credit fraud detection, I think AI is not really necessary here.   


Feel free to enlighten me as I'm currently interested in the banking industry."
508,Data science part time courses,1,https://www.reddit.com/r/datascience/comments/16x32tr/data_science_part_time_courses/,6,"I’m a seasoned data professional (comfortable with SQL, visualizations etc) and thinking of upskilling in data science.

Any part time online (anywhere) or in person courses in Toronto area that are good? Not looking to spend a lot of money but get some experience with theory/projects and get comfortable handling DS projects at work.

Anyone familiar with Waterloo data science certification?"
509,What was used before Random Forest?,18,https://www.reddit.com/r/datascience/comments/16wkgm2/what_was_used_before_random_forest/,10,I am doing some research into Random Forest and where the method came from. I was wondering if anyone had any idea as to what was used before this algorithm was created? Thanks
510,Anybody from India doing analytics/data science/statistics masters in the US who came from social sciences/humanities background?,0,https://www.reddit.com/r/datascience/comments/16x205l/anybody_from_india_doing_analyticsdata/,2,"Hello All,

As the title suggests is there anyone here from sociology, english literature, history, economics background from India who applied to any data science programs in the US? I am an English Studies major with a minor in Development Studies who is looking to transition to the data science field. I do not have much coding background. But Im trying to learn some Statistics and probability on my own so that I can pick up some data science skillset. if there is anybody like me who is without much quant/coding background, but still managed to apply and get into a data science/ statistics major in any US / Europe unis, I would like to how your experience has been with respect to application and also doing the course and landing jobs etc etc. would love to connect with anyone doing the QMSS or MCSS programs at Colombia and Uni of Chicago.

Thanks in advance!!

&#x200B;"
511,Is a Associate's Degree in Computer Science enough for a entry level job or internship?,3,https://www.reddit.com/r/datascience/comments/16wvtso/is_a_associates_degree_in_computer_science_enough/,2,"I am currently a Community College student on my last few classes for a Computer Science Degree, and I am wondering on how to break into this field. I would love to continue to obtain a Bachelor's Degree in either Data Science or Computer Science, but due to family hardships, I may have to quit school to help out my family financially. I am currently learning higher level math topics on my own as my school doesn't offer them to help supplement what I would typically take at a University. "
512,Broad work or deep work?,3,https://www.reddit.com/r/datascience/comments/16wr5qh/broad_work_or_deep_work/,4,"I’ve been working in digital marketing for 10 years and it’s time for a move. One of my favorite parts of my job is when I get to dig into datasets, find ways to clean or present it, ELT, and even building reports and tools from scratch. So I’m interested in Data Science. 
Here’s the thing: I’m already researching what practical skills I’ll need to be qualified. What is harder to find out is would this fit with my personality?
I recently found out that I have moderate to severe ADHD, which helps me to understand my professional struggles: I cannot multitask. I really like interacting with people, but I do much better work when I get a chunk of time to really work by myself and get into the weeds; the way my hyper focus functions, I can meet deadlines but struggle with teamwork because my cycles of engagement can be erratic. (In general I’m a very reliable person and like to work really hard. I’m just trying to be realistic with my limitations. ) I also LOVE researching topics and then giving people a TL;DR, I even got my master’s hoping to become a teacher. 

I apologize if this has already been covered here but I did some digging and didn’t find anything on this topic (although there was some super helpful stuff on the day to day type of work. )

Does anybody relate to how I’ve described myself? Am I setting myself up for failure by pursuing DS with my work style, or does this seem like a reasonable goal for me?"
513,Need some guidance,1,https://www.reddit.com/r/datascience/comments/16wvdbj/need_some_guidance/,0,I am learning data analytics by myself from past 2 months I have most of the python lib. Pandas numpy matplot season etc and Tableau. What to do next ? And I am not getting any internship from anywhere i am applying.any suggestions?
514,Creating a strong CV for applying for a Data Science internship,1,https://www.reddit.com/r/datascience/comments/16wumcm/creating_a_strong_cv_for_applying_for_a_data/,0,"I'm currently a second-year student majoring in Data Science and I want advice on creating an impressive CV, by the way, my grades in relevant courses are quite high.
Thanks"
515,What are the first things you analyze in a new dataset?,117,https://www.reddit.com/r/datascience/comments/16vwhw2/what_are_the_first_things_you_analyze_in_a_new/,58,
516,Announcing AI ethics and rights,3,https://www.reddit.com/r/datascience/comments/16wnxa1/announcing_ai_ethics_and_rights/,3," Hi, i want to announce our new sub reddit AI ethics and rights.

[https://www.reddit.com/r/AI\_ethics\_and\_rights/](https://www.reddit.com/r/AI_ethics_and_rights/)

It is a sub reddit about ethics and rights AI should have. This Topic is different from pure research and application. If you are interested in philosophical questions, have a look. It is a common sub reddit. Nothing special. But I think it has its place."
517,Any advice for stepping into my first management role?,0,https://www.reddit.com/r/datascience/comments/16wqwxb/any_advice_for_stepping_into_my_first_management/,5,"I'm a mid level data scientist that was asked to choose management over IC. I feel like I have sooo much more science to still learn! 

Any advice for being able to continue with my research and build out a team?"
518,Confused,0,https://www.reddit.com/r/datascience/comments/16wp89v/confused/,7,"I've applied to 4 master's programs: MIAGE, Information Management for Economic Intelligence and Logistics, Data Science for Economics and Finance, and Data Science for Marketing. If I'm rejected from the other 3 programs, would a master's in MIAGE be a plus if I want to become a data scientist in the future? (Of course, I will also do self-teaching.)."
519,Handling categorical missing data in churn prediction model for telecom data,2,https://www.reddit.com/r/datascience/comments/16wjpuy/handling_categorical_missing_data_in_churn/,2,"&#x200B;

I am working on a telecom dataset where I need to fit a model to for predicting churn(yes or no). There are a lot of categorical data with missing values( total values 7043). What is the best way to handle missing data in this case, is it better to ignore it or any other better imputation method?

    Data columns (total 21 columns): 
    customerID          7043 non-null object
    gender              7043 non-null object 
    Age                 7043 non-null int64  
    Partner             7043 non-null object 
    Dependents          7043 non-null object 
    tenure              7043 non-null int64 
    PhoneService        7043 non-null object 
    MultipleLines       6500 non-null object 
    InternetService     6500 non-null object 
    OnlineSecurity      7043 non-null object 
    OnlineBackup        7043 non-null object 
    DeviceProtection    7043 non-null object 
    TechSupport         7043 non-null object 
    StreamingTV         6500 non-null object 
    StreamingMovies     6500 non-null object 
    Contract            6500 non-null object 
    PaperlessBilling    7043 non-null object 
    PaymentMethod       6500 non-null object 
    MonthlyCharges      7043 non-null float64 
    TotalCharges        7043 non-null object 
    Churn               7043 non-null object"
520,From Pakistan with Data Dreams: Ready to Dive into Data Science!,1,https://www.reddit.com/r/datascience/comments/16wmvq5/from_pakistan_with_data_dreams_ready_to_dive_into/,0,"
Hello, I'm new to this group. I'm from Pakistan and I'm seeking guidance from you all. I'm currently in my final semester, majoring in statistics. While browsing online about future career prospects, I came across fields like data science, data analysis, and research-related jobs. After doing some additional research, it became clear to me that data science seems to be the most promising field based on my interests. It offers a wide range of opportunities, and job prospects appear to be quite promising.

In my last semester, I'm also working on my thesis, which has sparked a significant interest in me. While I do have an interest in accounting and related fields like banking, I'm not sure how to transition into those fields. I have some basic knowledge of statistical software but lack programming skills. However, I'm eager to learn programming.

Could you please provide some guidance on which fields might be better for me in the future? Thank you."
521,Advices,1,https://www.reddit.com/r/datascience/comments/16wllab/advices/,0,"Hi!
(English is not my first language so sorry about anything).
I'am a computer science student(5 semester) and i'm really confused. I have a real love for science envolving data, machine learning and IA, also for programming, my biggest goal is to build functional technologies, this said, i tought about going in this direction for a career, do u guys think it makes sense somehow mixing the study of ia, data science, backend programming, ML, powercenter, oracle, amazon quicksight, cloud data management and salesforce datacloud?
Maybe I'm very disjointed but I wanted some direction."
522,how ever I.A moldering industry musical,1,https://youtu.be/Srmir7FmTmo,0,
523,It's not just you. Everyone hates the return to office,626,https://www.reddit.com/r/datascience/comments/16vaaco/its_not_just_you_everyone_hates_the_return_to/,251,"Somehow, I am lucky enough to land a completely remote role, 100% virtual because the rest of my team is virtual based but I still have to go into the office at least 12 times a year for bogus meetings to sit in a conference room while we all use WebEx, totally immersive right? But we have frequent meetings with other people in our field, data scientists, engineers, architects, etc. They are all back in office 4 days a week, and each of them has this ashy tone, they grudgingly hate being in the office, despise it, because who wants to go to a stuffy office?


Here are the top complaints that I have noticed from people about being in office

- The commute is terrible. Some people have to commute as much as 50 minutes one way, and that's not including traffic. That's crazy. You're not getting paid for that. That's free labor and travel for your company


- The office is incredibly distracting. Cubicles are typically open, so people can freely walk up and talk to you, make eye contact with you which starts a conversation, but you're still under the same time crunch you were when you worked from home completely isolated in your nice office away from everyone else


- ""Collaborative spaces"" and ""focus areas"" are bullsh*t. So many nice little desks, nooks, rooms for you to go to to focus or meet with others. But here's the thing, you never see anyone using those because I guess where they are? At their desk, working, constantly. No one ever has the time to use them. My office is so incredibly nice, and every time I walk around, I feel like I'm the only one taking a walk because I see everyone glued to their desks

- You're distracted constantly by others who are at different levels than you. The only way I figured out that there is some college intern making twice as much as I am doing a little bit more than me is by speaking to people in the immediate vicinity of my desk. Machine learning engineer versus data scientist. The difference? They use a little bit more power platform, a couple more tools, 20 more lines of Python a day. Congrats, here is 40K more for you. This can be very distracting, because you see these people all the time


- NO PRODUCTIVITY OR OTHER GAIN. Literally no benefit or gain from being back in the office. Just disgruntled people


- office supplies are shit. At home, I have an ultra wide monitor that I also use for personal PC gaming so I can just literally KVM switch it over. I have a modded gaming mouse and keyboard, a $200 Logitech pro headset with superior sound quality and microphone. You know what I don't have at the office? Any of this stuff. Yeah. A $5 Logitech mouse and keyboard that is extremely noisy and uncomfortable has no ergonomics at all. Office chairs are not ergonomic They are just the cheapest they could get. Uncomfortable $0.90 headsets and webcams


- MANDATORY extracurricular events and activities in or outside of work. Yes, this is real. After hours socials, restaurants, social outings. These are disguised as optional, but you will often get bullied teased or pressured into them. This also does not grant you any leeway during any project, you still have to get all work and projects done with this loss of time"
524,Transition advice,1,https://www.reddit.com/r/datascience/comments/16wkgs7/transition_advice/,3,"I'm a government employed data analyst (nominally a business system analyst) in a supervisory role. I have been trying to get away from the grind of government work and into data science, but I can't seem to get callbacks on my resume.

I do have some data science experience where I work, but I don't think it's being looked at seriously by prospective employers.

Currently, I'm pursuing a MSc through Georgia tech's OMSA program (currently taking classes 4 & 6). I had hoped that starting the program would improve my bona fide, but so far no dice.

Has anyone been in a similar place? 
I had a non-technical undergrad so I'm largely self taught."
525,What’s the point of learning Spark if you can do almost everything in Snowflake and BigQuery?,78,https://www.reddit.com/r/datascience/comments/16vle5j/whats_the_point_of_learning_spark_if_you_can_do/,61,"Serious question. At my work we’ve migrated almost all of our spark data engineering and ML pipelines to BigQuery, and it was really simple. With the added overhead of cluster management, and near feature parity, what’s the point of leveraging Spark anymore other than it being open source?"
526,Quantifying picture component to a whole,1,https://www.reddit.com/r/datascience/comments/16w9z86/quantifying_picture_component_to_a_whole/,0,"Simple example would be chopping a square into 4, with 1 image representing each quadrant. Overlaying these 4 would each get a score of 0.25 to get back to the original picture. 
Or we need 0.5 mountains, 0.3 clouds, and 0.2 rivers to make a Bob Ross painting. 

My project will be a bit more complex, but not much. How can I score the components? I’d like to incorporate into machine learning for testing many samples
Ideally, I’d use pictures of each clouds, rivers, etc as features in the ML model (if possible) 
Thanks for your time!"
527,How to best organise a data person injected into a specific business unit?,1,https://www.reddit.com/r/datascience/comments/16w8bo4/how_to_best_organise_a_data_person_injected_into/,1,"Hey all, 

I work in pharma and work in two different departments: the data science department (my boss) and in the oncology department. 

It’s relatively new and we have a lot of wiggle room to improve the role and propose new responsibilities and redefine the job profile.

Currently we’re viewed as “business analyst consultants” to a degree. 

Our biggest hurdle is we lack a lot of support from our home base: data science dep, and end up doing a bunch of data engineering tasks specifically for the BU. Unfortunately, in our current profile, we’re all spreadsheet based and building these pipelines: joining data from a data warehouse, joining external data etc. is abysmal. 

In your opinion, what Role, or what changes would need to be suggested to the data science dep to improve this: for example, a dedicated data engineer in the BU? 

Thanks!"
528,Anyone using PowerBI for DS or stats?,0,https://www.reddit.com/r/datascience/comments/16wd1gy/anyone_using_powerbi_for_ds_or_stats/,5,"Hi all,

I'm wanting to use PBI for more stats. Obviously I need data wrangled into a format that will work, but is anyone else doing this?

I was thinking of t-testingvcategorical values against the overall sample average (Sig positive/negative)


What have you done(if anything)?"
529,Anaconda report on the state of Data Science for 2023,16,https://www.reddit.com/r/datascience/comments/16vj5y5/anaconda_report_on_the_state_of_data_science_for/,13,"Hi have anyone checked the latest report from Anaconda: [https://www.anaconda.com/state-of-data-science-report-2023](https://www.anaconda.com/state-of-data-science-report-2023)?  


It seems like data prep, data cleaning and data visualization are tasks are the top 3 of the most time consuming?   


What do you think? "
530,Quantify contribution of component pictures to create the final,0,https://www.reddit.com/r/datascience/comments/16w17o0/quantify_contribution_of_component_pictures_to/,0,"Simple example would be chopping a square into 4, with 1 image representing each quadrant. Overlaying these 4 would each get a score of 0.25 to get back to the original picture. 
Or we need 0.5 mountains, 0.3 clouds, and 0.2 rivers to make a Bob Ross painting. 

My project will be a bit more complex, but not much. How can I score the components? I’d like to incorporate into machine learning for testing many samples
Ideally, I’d use pictures of each clouds, rivers, etc as features in the ML model 
Thanks for your time!"
531,Machine Learning pays 15-40% more than Data Science - why?,243,https://i.redd.it/r8y8ds6oa2rb1.png,120,
532,Fined-Tune BERT vs LLM,3,https://www.reddit.com/r/datascience/comments/16vk1th/finedtune_bert_vs_llm/,1,"this is a really  general question, but how much better is an LLM compared to a fine-tuned BERT model is any conceivable NLP instance? "
533,I left my job to study for the next 6 months,22,https://www.reddit.com/r/datascience/comments/16v58a9/i_left_my_job_to_study_for_the_next_6_months/,47,"I need someone's help on how to start in data science (I know it takes a lot of time to learn, but I'm dedicating 6 months to this study). Can someone please suggest some good laptops below $650 and provide a roadmap?

Edit: Fellow Redditors, thank you so much for all your comments. After a lot of introspection, I plan to work in an entry-level data analyst role and then slowly move into data science. Could someone please share a 3-month roadmap for learning, along with resources? This would be helpful for me and others."
534,Bit of guidance?,4,https://www.reddit.com/r/datascience/comments/16vgm5z/bit_of_guidance/,31,"I've made some XgBoost models and found some good hyperparameter combinations to get some fairly decent results with my criss fold validations. I think the highest I've got is about 85% In real life it's showing signs of overfitting dropping to 55%.

I'm trying to predict stock market direction, just up or down. But I have a train of thought that's leading down a rabbit hole I don't think I should be going down. I'm taking the latest prices along with some features and using that as my prediction row. Then I add another row of data and retrain the model with the same params again and predict, repeating about 180 times until I have an entire columns of predictions. 

I understand it's computationally expensive to repeat this process so many time, it doesn't take a great deal of time to do it. I thought if I use the data from the training set then I'll suffer from Overfitting, which I clearly am already doing so but I'll carry on trying to reduce overfitting.

Should I trim the training set to a point before the dates I want to predict and use the same model for these 180 days? Or should I think about retraining the model every 30 or so data points? I feel like there's almost limitless possibilities and I've gone down the wrong path which will render everything I've done up till now pointless.

Edit: Absolutely not looking for people to help with cracking the stock market. Just how to train models properly. I totally understand I'm never going to win the stock market."
535,How to be a better data scientist and catch up faster with smarter colleagues?,40,https://www.reddit.com/r/datascience/comments/16uze49/how_to_be_a_better_data_scientist_and_catch_up/,15,"It is very clear to me that I am one of the least competent data scientists at my company, if not the one (For context, I have worked here for 1 year, having worked 2 years before as a DA), but I know it is not simply a matter of imposter syndrome. 

When I was hired as a JDS, most of my colleagues were data analysts and my responsibilities were mostly similar to theirs (basically SQL and BI), I think I did an okay job and managed to get a promotion to regular DS. Things changed, and I was moved to a team of experienced DSs. There I will be expected to do much less data analysis and more development. Now I noticed the big skill gap and how undeserving I was of my promotion. I am extremely intimidated by my colleagues' large knowledge of our codebase (and of theory in general), and by their awareness of recent relevant papers. I also suck at networking and have a very poor knowledge of who knows/does what in the company, which everyone else seems to do well. I also don't have great presentation skills, mostly due to my lack of knowledge and subsequent insecurity. 

I know that I need to catch up, but I don't really understand how. I try to pay a lot of attention to everything that is written or said in meetings, but that almost never makes sense to me as I don't have the context. I also can never add to any meeting unless we are discussing something very close to what I have worked on. At this point, I feel super ashamed as I need to take care of one specific model that I know almost anything about. Its performance is bad and I can't figure out how to start. I am supposed at least to diagnose the model's failures but I have way too little knowledge to even figure out what to do. I could follow someone's instructions well if I had them. But as a DS I should be able to do that by myself. I know very well that working with smarter people is great for my career and that I shouldn't listen to my inner voice that tells me I should have stayed a DA. Still, I feel that I don't have the behavioral skills to take advantage of that the best way as I am introverted and have ADHD.   


I identified that my lack of attention is an issue and I am making a conscious effort to pay more attention. I am quite self-conscious and afraid of making questions, which is something I am trying to change, but at a big effort to me. So I wonder if you guys have any general hints/suggestions on how to improve faster. "
536,Big Fancy Company Has No Clue What Data Science Is,80,https://www.reddit.com/r/datascience/comments/16urkg1/big_fancy_company_has_no_clue_what_data_science_is/,38,"They offered to cover my move from the East Coast to Dallas, plump my check with an additional 50K for signing, but the office is run by squirrels.

I’m not talking your acorn tree squirrel. I’m talking tiny little men with moostaches who haven’t the slightest clue that plugging in numbers to an excel sheet ain’t science.

Do I tell them this is nuts?! Or do I keep the money and hang?

The name of the company rhymes with Jewelry."
537,"Everyone always talks about LLMs/ML in data science but no one ever talks about experimentation, ML's older sexier sister.",107,https://www.reddit.com/r/datascience/comments/16uomoo/everyone_always_talks_about_llmsml_in_data/,24,"As a data scientist primarily focused in causal inference and experiment design, I find that most conversation and questions from people trying to transition into DS always want to go into ML, but causal inference and experimentation is another very fun sub-field within DS. I'm biased since I'm in this sub-field but having done some ML stuff on the side, I much more enjoy the causal inference side of things.

Note that this post is primarily geared toward people with some experience. It's hard to break into experimentation with no background. Fresh PhDs though, particularly in social or physical sciences do well.

What's fun about about experimentation and causal inference:

1. Knowing why something caused something else is always valuable
2. Well designed experiments can be hard to design and execute, which is part of the challenge. A good experiment correctly captures the objectives of the product manager/business partner and answers a question that can be immediately acted upon once results are available.
3. Requires a combination of business thinking, strategy, and strong statistical foundations
4. Often is highly collaborative and builds your soft skills. I work with people in marketing, risk, finance, modeling, dashboarding teams to make sure things work well
5. Causal inference is not just A/B testing. There are plenty of situations where we need to get a causal understanding but an experiment is just not feasible. Tons of fun techniques here like instrumental variables, propensity score matching, causal forests, double ML etc. which have their own strengths and weaknesses
6. Experimentation is not just A/B testing. We have multi-arm bandits, factorial and fractional factorial experiment designs etc.
7. Usually don't have to worry about productionizing etc. ML is often 5 lines of code once you've massaged the data just right
8. It's a growing field. I see lots of job openings in experimentation and the skillset is hard to come by. It's not easy to do causal inference (both the experimental and non-experimental kind) and all the challenges of launching a business experiment require on the job training to be successful at.

If you're in the market for a new role, don't overlook experimentation (or think of it as less fun) :).

Some resources for those to want to learn:

1. [https://matheusfacure.github.io/python-causality-handbook/landing-page.html](https://matheusfacure.github.io/python-causality-handbook/landing-page.html)
2. Trustworthy online controlled experiments by Ronny Kohavi, a giant in the field of experiment design
3. Mostly Harmless Econometrics by Angrist et al."
538,What the Birthday Paradox Teaches Us About Protecting Patron Privacy,2,https://chimpy.me/blog/posts/what-the-birthday-paradox-teaches-us-about-protecting-patron-privacy/,0,
539,First project review | Data wrangling and Visualization,2,https://www.kaggle.com/code/aadeshpradhan/data-cleaning-viz-for-beginners-intermediate?scriptVersionId=144642580,0,"Hello guys,

This is my first project and i request you guys to please check out my work, leave a comment on what i can improve and upvote in kaggle it you like it.
I have performed:
• Data manipulation (pandas, numpy)
• Data visualization (pandasql, matplotlib)

I would like to thank this community for creating opportunity for ppl like us to share our work. Thank you all!!"
540,This is a data analyst position.,360,https://i.redd.it/9jvrsplsizqb1.jpg,174,
541,"No passion for data science, what jobs can I get?",10,https://www.reddit.com/r/datascience/comments/16v36n7/no_passion_for_data_science_what_jobs_can_i_get/,33,"Hi everyone. I am a recent data science graduate (bachelor's) from UCSD, but I also have a degrees in Linguistics and teaching experience. I am trying to apply to data science jobs, but from what I figured, if I don't have outright passion and initiative to pursue data science, it will be near impossible to find a job. I want to eventually become a teacher, but I want to work somewhere else first to get experience and save up money. 

What fields are data science skills transferrable to? I know that in any field I will have to show initiative and passion, but I feel like that IT is so cut throat right now that it'd be much easier to find job elsewhere."
542,What do you bring to the table?,2,https://www.reddit.com/r/datascience/comments/16vaujg/what_do_you_bring_to_the_table/,46,Data science is a broad field. What do you feel makes you a great data scientist or what are you trying to achieve? e.g. “I’m a bada** statistician because x and no one else knows how to do x”
543,Last Call for RUGS Grant Applications!,2,https://www.reddit.com/r/datascience/comments/16vdu21/last_call_for_rugs_grant_applications/,0,"Hello to all R enthusiast, just a friendly reminder to anyone eyeing the RUGS grant opportunity. The clock's ticking with the deadline set for tomorrow, September 30th, 2023. Don't miss out on this chance to bolster your R-based projects. All details are here: https://www.r-consortium.org/all-projects/r-user-group-support-program. Seize the moment!"
544,"When a ML algorithm is training, what is actually happening behind the scenes? How does it learn?",0,https://www.reddit.com/r/datascience/comments/16vjh8q/when_a_ml_algorithm_is_training_what_is_actually/,34,"Basically the question. When we run say logistic regression or an SVM on Python, what is happening step by step with all the train data? I know the answer may vary based on the algorithm, so you may pick any algorithm to explain in detail the behind-the-scenes.

Wanted to post at r/explainlikeimfive but wasn’t sure if any ML people may be in that crowd, but please ELI5."
545,Is Data Analytics not entry level?,34,https://www.reddit.com/r/datascience/comments/16unmxh/is_data_analytics_not_entry_level/,35,"This a response to the replies I saw from a previous post where hiring managers simply filtered out inexperienced applicants.

My question is if data analytics is not the right path to get acclimated in this field, then what is? Where could you get experience that will allow hiring managers to respect what you have to offer?

In my case, I’ve recently graduated with a social science degree and have been advancing my knowledge in statistics to apply for these positions. I’ve done one project in the past and plan to finish a certificate this month. My only sense of career guidance has been what I’ve seen online. Data events aren’t really catered to newcomers in my area and rejected job applications are the only type of feedback I get."
546,"Sunday, Oct 1st, is the last day to submit your proposals!",0,https://www.reddit.com/r/datascience/comments/16vc2xm/sunday_oct_1st_is_the_last_day_to_submit_your/,0,"Here is What We’re Looking For in Your Proposals

The ISC values projects that:

1️⃣ Have a broad impact on the R community

2️⃣ Are scoped to be focused and actionable

3️⃣ Carry a low-to-medium risk and reward

Review Process:

Proposals will be reviewed by the Chair of the ISC and committee members, with results announced per the key dates.

Let's enrich the R landscape together. We can't wait to review your innovative proposals! Learn more here: https://www.r-consortium.org/all-projects/call-for-proposals

\#RProgramming #Rstats #OpenSource #DataScience"
547,Let's discuss again distance learning PhDs,1,https://www.reddit.com/r/datascience/comments/16vajxx/lets_discuss_again_distance_learning_phds/,20,"I have recently posted about not being able to find a new job. I do work as a senior analyst, and the job pays the bills, but it isn't very interesting. I am sincerely interested in statistics, predictive modeling, machine learning, and I want to keep pursuing that. I have been applying a lot, had my resume reviewed by several people, but I am just not getting any replies.

I am now thinking about what else I can do with my life to make it more interesting. I have a masters degree in data science, and two published papers, so in theory I could apply for a PhD. I have a mortgage and small kids though, I really can't go for a full-time PhD because I wouldn't make enough. My salary is around $79K USD and PhD programs definitely don't pay that. I also can't move because of kids, mortgage, family, etc.

I do really want to work on an interesting project though, are there any good remote part-time  PhD programs? I know this has been already discussed, and there aren't a lot of options, but I did see that the Open University in UK has such a program and the Coventry University, also in UK, has one. The programs are quite expensive though for non-UK residents. 
Anyone aware of other DS part-time remote PhD programs? I could find a way to attend campus occasionally, but definitely not every week, if it's far away. And unfortunately there aren't any part-time DS PhD programs in my city."
548,You ever start a new job and hate it?,15,https://www.reddit.com/r/datascience/comments/16usord/you_ever_start_a_new_job_and_hate_it/,10,"I just started this new job and I feel so blah about it. Like going to work each day feels like I'm about to jump into freezing cold water. I'm just iffy about it. But my last company laid me off which is why I ""left"" but I loved working there. I really loved the vibe and the environment and I wanna go back idk what's wrong with me."
549,QUADRA is out!! - Opensource library to train and deploy DL models,0,https://www.reddit.com/r/datascience/comments/16v8kwk/quadra_is_out_opensource_library_to_train_and/,0,"**QUADRA is out!! 🎉🎉🎉** 

QUADRA is an **opensource library to train and deploy DL models** in a very simple and flexible way and to compare, monitor, and share experiments quickly!

🌐 Website: [https://orobix.github.io/quadra/](https://orobix.github.io/quadra/) 📁 GitHub: [https://github.com/orobix/quadra](https://github.com/orobix/quadra) 

QUADRA development started to answer the necessity to **perform machine learning experiments for multiple customers and projects**, without the need of a large copy-pasted codebase over multiple repository.

**Are you a data scientist or an AI researcher?** 

With QUADRA you can: → simplify your deep learning experimenting process; → train and deploy deep learning models in a simple and flexible way, using YAML configuration files and open-source tools such as Hydra, Lightning framework, and Pytorch; → compose your experiment configurations from single command line interface, so you can conduct multiple experiments with different settings and hyperparameters; → compare, monitor, and share your experiments quickly!

\---  

❌ Are you interested in joining the project community? Get in touch! ❌

Feel free to use QUADRA for your Artificial Intelligence projects, and if you want to contribute, we are more than happy to accept your pull requests! ❤️

&#x200B;

https://preview.redd.it/kxvdi76ff6rb1.png?width=8012&format=png&auto=webp&s=e451177e0f7f660be46cc8a947e88ba0071527db"
550,"Issue reading csv in pandas, Datatype all objects",0,https://www.reddit.com/r/datascience/comments/16v81yf/issue_reading_csv_in_pandas_datatype_all_objects/,2,"
Hi, I'm facing an issue reading a file in databricks using pandas.
I'm reading the csv file, Only the encoding='IS0-8859-1' is working for the Data. And all columns are being read as either object / int32 datatype instead of Mostly String/Integers. I tried the following to change that to string but none is working:
- astype(str)
- applied lambda func to each element in column
- pd.Series (df ['column '],atype=str)
-applymap
- apply (str)

I checked the column data and it is one datatype only, It does not have multiple headers/footers, A few nulls out of 4000 rows

- I tried reading with spark and then converting the dataframe to pandas, but same 
- Before applying all the above, I removed null rows and some special characters  also from the column. But still not working

Let me know if someone can help?"
551,In which countries do junior Data Scientists find the most promising opportunities?,39,https://www.reddit.com/r/datascience/comments/16uhmmt/in_which_countries_do_junior_data_scientists_find/,58,"I've recently completed my Data Science studies in France, and I'm eager to venture out and work internationally.

My desire to work abroad is not purely based on career growth. It's also about plunging into new cultures, seeing life through a different lens, and enriching my own understanding of the world.

Most articles about the best countries to be data scientist only focus on salaries. However, I believe this approach misses the mark for several reasons:

1. **Quality of Life:** It's not just about how much you earn, but how fulfilling and comfortable your daily life is.
2. **Engaging Job Missions:** Beyond the financial aspects, I'm deeply interested in roles that offer captivating missions and innovative/meaningful projects.
3. **Supportive Environments for Juniors**
4. **Cost of Living:** A high salary in one country might not stretch as far when considering the local prices and living costs.

I'd greatly appreciate any insights or suggestions of country/city you might have from your experience. Thanks in advance!

&#x200B;

**PS:** I was in an alternance program. I studied in Toulouse and worked in Paris during the same year. "
552,The Hype for LLMs is reaching a fever pitch!,4,https://insight.ieeeusa.org/articles/large-language-models-the-transformative-force-shaping-the-21st-century/,2,"IEEE posts this article on LLMs and it seems like they are going to take over, is it possible?"
553,How do we know that the SQL query will return the correct solution?,12,https://www.reddit.com/r/datascience/comments/16uo2qt/how_do_we_know_that_the_sql_query_will_return_the/,12,"SQL and I are just ""getting to know each other"" with the help of some courses and a textbook. Please help me with the theoretical and naive question of how does one know that a query returns the correct and presumably the one and only correct solution? This is clearly verifiable in the case of practice problems and although I don't get it right the first time, this is exactly what makes me think that in the real world I cannot be sure of the correctness of a query.

Perhaps my question can be translated as how to validate a SQL query?

Thanks if you share your experiences."
554,"1850 Data Science, Machine Learning, Deep Learning Objective Type Questions and Answers with Explanations split in 37 Online Exams",1,https://mytechbasket.com/article_desc.php?art_id=242,0,
555,Ideal timing of dataset split,1,https://www.reddit.com/r/datascience/comments/16v3z5d/ideal_timing_of_dataset_split/,0,I was wondering if applying preprocessing to a whole dataset and then doing the train/test or train/val/test split could lead to data leakage. What would be the proper procedure? Splitting then doing EDA/preprocessing or doing it the other way around?
556,Used cars price prediction,0,https://i.redd.it/c33kydry94rb1.jpg,11,"Hey guys I was working on my capstone 
Which is a used cars price prediction model.

So this project includes antique as well as non antique cars
So i wanted to cluster into two groups and predict the price accordingly

What are your inputs guys?? Any suggestions??"
557,Need Help Answering a Model Eval Question,0,https://www.reddit.com/r/datascience/comments/16uv9u4/need_help_answering_a_model_eval_question/,0,"There’s an ongoing discussion at my work I don’t totally understand. We have two different models trying to predict the same metric for two different categories of customer. Lets say the first category is new clients and the second is returning clients. For both populations we are trying to predict 1 or 0 for whether or not the client is likely to transact with us. These were built as two separate models because we have vastly different quantities of data on returning vs new customers.

Based on the likelihood of a client transacting with us we prioritize which clients to call first, calling the most likely to transact first. There is a concern that because these populations have different class imbalances we cannot stack rank their scores for call priority and instead need to make some calibration to account for differences in the classes of  the populations. I don’t totally get it as the models are predicting the same metric and as long as both models are equally accurate on a test dataset and in the real world, why would the prior class imbalance be relevant?"
558,How can an LLM play chess well?,86,https://www.reddit.com/r/datascience/comments/16twcad/how_can_an_llm_play_chess_well/,106,"Last week, I learned about https://parrotchess.com from a LinkedIn post. I played it, and drew a number of games (I'm a chess master who's played all their life, although I'm weaker now). Being a skeptic, I replicated the code from GitHub on my machine, and the result is the same (I was sure there was some sort of custom rule-checking logic, at the very least, but no).

I can't wrap my head around how it's working. Previous videos I've seen of LLMs playing chess are funny at some point, where the ChatGPT teleports and revives pieces at will. The biggest ""issues"" I've run into with ParrotChess is that it doesn't recognize things like three-fold repetition and will do it ad infinitum. Is it really possibly for an LLM to reason about chess in this way, or is there something special built in?"
559,Skewness in target column,1,https://www.reddit.com/r/datascience/comments/16uq3uz/skewness_in_target_column/,6,"I have recently started learning data science and for last couple of days i have been working on dataset where training dataset's target column is right skewed, and test dataset doesn't have target column. I have tried to do do log transformation of the column but it's giving worst result compare to if I don't transform the column at all.

I have tried to google but can't find anything that will help me.

Can someone please help me what should i do should i do some other transformation or just leave it be.

Thank you."
560,Heated debate with leadership because of Excel,77,https://www.reddit.com/r/datascience/comments/16tujyf/heated_debate_with_leadership_because_of_excel/,52,"I work for a small company that deals with claims process for major insurance companies. Medical bills, car repair authorization, you got it.

I was hired to improve the data analysis area, to deliver insights for key people on the organization. SLAs control, trend lines of the customer demand to better allocate our people on days/shifts, etc.,

They gave me a blank check to do whatever I needed to. 

Seemed like a dream becaming true. No pre-requisites, full control of my work and a great opportunity to expand my portfolio.

And honestly, I delivered a great work. 

A whole ecosystem using SQL and R on a cloud server. SQL to consolidate the data (and importing legacy data from other systems), ETL scripts running on a regular basis to do database tasks, Shiny dashboards with credentials for leaders and other people, webapps with forms to control data input, custom APIs to collect data from a Help Desk solution and supply ML models to serve another endpoint for predictions, etc.

But I'm facing a new and frustrating problem: people on leadership positions keeps using Excel. I saw other bosses telling their people to put data on spreadsheets, causing wrong and outdated reports for the part of the company that uses my tools properly.

And they keep asking people to create spreadsheets, when they can even export data on this format from the dashboards.

Yesterday I got on a heated debate with my boss about this. 

I need some advise. It's a nice company overall, on a industry that I know a lot (insurance is part of my academic formation) and I don't know how to handle this without putting my job at risk.

**TL;DR:** People refusing to abandon Excel and keeps creating spreadsheets and reports disconnected from the data ecosystem that I created, causing all sorts of problems. What I need to do to solve this?

&#x200B;"
561,Is our role to give the data that the stakeholder asked for or give them a trimmed version that is closer to correct?,2,https://www.reddit.com/r/datascience/comments/16uiavf/is_our_role_to_give_the_data_that_the_stakeholder/,3,"I got into it with my boss today about this.

We are working with calls, call transcripts and sales. I had been working on attributing certain phrases in the transcripts to actual sales. Given all of our incoming calls to our sales department to numbers specifically for the customer to potentially purchase something, I then decided as my first idea to do it simply would be to match the phonenumbers to the customer information attached to a salesdocument. However, I don't want to match a sales call to a sale made months later, so I limit the date range to the first arbitrary timeframe, I chose 10 days.

Call Date <= Sales Document Date <= Call Date +  10 days.

while I was working on this, my boss had a separate person ask to match calls made to specific numbers associated with promotions. He just set a date to start looking at: 1-1-2023, and just matched the date.

These are the same goals, and I was already working on it in a larger scale so I mentioned how I was doing it. Thus ensued an argument about how much data to give the stakeholder. He said it wasn't our job to take away data, that we had to give them everything to what they asked and present them the list of considerations.

I argued that wasn't correct, that it isn't our job to give everything. The reason we have jobs is because we took the time to be data literate, and that is what they are paying us for. They don't necessarily know the correct questions to ask with all the nuances. I was saying it was our responsibility to siphon the shit out of the request to give the most accurate information. Sure my first caveat of 10 days might not have been the correct choice, further investigation and discussion may reveal a better way, but giving them everything was irresponsible.

If you called the promo number for january, but didn't end up buying anything, and then three months later you called the number on the next promotion you received for april and then purchased something. You wouldn't want to attach the january phone call to the april purchase because that promotion wasn't the one associated with the sale.

I thought this was a simple endeavor, but the argument wasn't going well because I am not the most persuasive, and more plant my feet because damnit I am correct. That is a fault and it could bite me in the ass later.

any thoughts would be appreciated.

TLDR; Boss says give them everything and tell them about potential inaccuracies, I say account for those inaccuracies and explain them and why I removed them if they ask, otherwise just tell them I accounted for date ranges to not match calls to sales that were too far in the future and could be attributed to later calls.

&#x200B;

EDIT-

Boss got back to me on teams.   


&#x200B;

> Looping in Eric to our conversation earlier in standup.  You have excellent points and I expressed those points to him, he was like good point.  I hope you know I completely agree with you, my point was only to give the end user the entire dataset and explain perceived flaws to the end user.   

I still would like help coming up with better words and strategies to deal with these kinds of arguments in the future"
562,Correct way of studying the learnings of a model on image classification?,1,https://www.reddit.com/r/datascience/comments/16unevw/correct_way_of_studying_the_learnings_of_a_model/,0,"I am working on a disease detection project, wherein  I am supposed to detect injuries in distinct body parts, how do I ensure that my model is learning correctly? I have tried verifying with activation maps but cannot interpret them.  I assume that activation maps should accurately identify the region of infection, is this assumption correct?"
563,Job,5,https://www.reddit.com/r/datascience/comments/16ucjce/job/,5,"So i have been a graduate in data science for 1 year now. I got hired as a data scientist while i was still persuing my degree, however im looking for a change of scenery knowing that most of my work is on the analytics part. 
Pes: i love doing predictive models but its not required here
Is a business analyst a good option? Or should i search for a pure data science position?
Will it effect my career on the longterm or will i b able to go for pure data science position later on?
Any advice is really appreciated"
564,(Advice) Data Science certification,3,https://www.reddit.com/r/datascience/comments/16udl5a/advice_data_science_certification/,7,"Hello everyone!

I just graduated this summer with a degree in electrical and electronics engineering. After my graduation I started working on other skills including project management and data science. I am currently pursuing data science professional certificate by IBM. Although it sounds good, however many reviews by industry specialists I've seen, who have been over this course do say that it's just going to give you the basic skills and the basic understanding. My own plan is to complete this and then get my hands dirty with quality projects. 
Im also in a dilemma as i want to change my field but i feel like im too late because im currently 25 and unemployed.

I need advice on what resources I can use to polish my skills, any other advice would work too considering my degree. Thankyou!"
565,Significance Testing for Market Campaigns/Market Study?,1,https://www.reddit.com/r/datascience/comments/16um2t9/significance_testing_for_market_campaignsmarket/,0," 

Hello,

I'm trying to design a study to assess the effectiveness of a marketing campaign and could use some guidance.

Background: We identified the seasonal patterns for the quantity purchased of a given product for every product, for every customer. We are performing a market study where we identify like-markets (customer A orders some product more on average during the same month customer B orders that same product more on average) and we're going to conduct a marketing campaign where one customer is the control (no campaign) and the other is the experimental (campaign).

For every product, we should have plenty of customers that order that product more in a given month on average to act as our control and experimental group.

My plan to analyze this data post-campaign(s) is to take each product control/experimental group and perform an independent sample t-test assuming unequal variances to check for significance.

The issue is, I'm going to have hundreds of thousands of products (i.e. hundreds of thousands of tests). Obviously, some percentage of the tests will be significant and another percentage of them will not be; but I'm not sure how to interpret the results of the study as a whole given this fact.

I've read into Bonferroni Corrections a bit and that seems like a possible way to go when analyzing the results of all the individual t tests. But I would like to get some advice/feedback from others.

Thanks in advance for the help!"
566,X/Twitter misinformation detection browser plugin,1,https://www.reddit.com/r/datascience/comments/16ukd8b/xtwitter_misinformation_detection_browser_plugin/,1,"It seems that after recent changes made by Elon Musk to X/Twitter (""free speech"" rules plus API limits) there might be market now for an external (web browser side maybe) tool for X/Twitter to detect and highlight troll activity. I've seen there are some papers available on this topic but I haven't found any customer ready to use tool. What do you think? Or maybe you know such a tool? Maybe we can build it here?"
567,LLMs hype has killed data science,851,https://www.reddit.com/r/datascience/comments/16t9p4v/llms_hype_has_killed_data_science/,305,"That's it.

At my work in a huge company almost all traditional data science and ml work including even nlp has been completely eclipsed by management's insane need to have their own shitty, custom chatbot will llms for their one specific use case with 10 SharePoint docs. There are hundreds of teams doing the same thing including ones with no skills. Complete and useless insanity and waste of money due to FOMO.

How is ""AI"" going where you work?"
568,Reinforcement learning in automating game testing 🔥,1,https://www.reddit.com/r/datascience/comments/16ujm1g/reinforcement_learning_in_automating_game_testing/,0,"The role of **Reinforcement learning** in automating **game testing** is becoming increasingly crucial, making it more efficient and effective. Manual testing, while essential, is extremely **time-consuming and subject to human error.** 

Our **opensource** library [SheepRL](https://github.com/Eclectic-Sheep/sheeprl) 🐑 can be used to test whether the game dynamics is well defined: **what if a player can finish the game with just a few moves?** 🎮

This [video](https://x.com/orobix/status/1707403169523773930?s=20) shows that our agent (Kasumi, on the left) is able to win the game in the hardest modality by standing down and throwing kicks. 🥊

This can be helpful for a game developer to:

* understand where and how intervene **to achieve a more playful game**
* **predict and correct bugs early** in the game development process
* enhance the gaming experience and final **product quality**
* reduce time and resources spent on **debugging**.

The game has changed 🔥 and it is up to us to play it with (human + artificial) intelligence!

Thanks to [**u/DIAMBRA\_AIArena**](https://www.reddit.com/user/DIAMBRA_AIArena) for the video!

\---

❌ Are you interested in joining the project community? [Get in touch](https://github.com/Eclectic-Sheep/sheeprl) ❌

[SheepRL](https://github.com/Eclectic-Sheep/sheeprl) 🐑 is open-source, fully written in PyTorch and accelerated with LightningFabric - by Lightning AI

**Feel free to use it for your Artificial Intelligence projects**, and if you want to contribute, we are more than happy to accept your pull requests! ❤️

&#x200B;

https://preview.redd.it/yoy38vghp0rb1.png?width=6668&format=png&auto=webp&s=df5b3a881c81841a4f52617c68c057ffdb1ebeac"
569,What online course/books would you recommend to someone interested in getting into DS?,2,https://www.reddit.com/r/datascience/comments/16udszx/what_online_coursebooks_would_you_recommend_to/,3,"As per title. I've a university degree in Information Systems but have been taking DA/ML mods, have built a couple of models myself for projects/internships which uses decision trees, random forest, logistic regression and so on.

I've basic python programming knowledge along with some OOP knowledge. Self-learned matplotlib/pandas/sklearn myself so I know the basic things but still not very comfortable in using lambda to process functions what not. Also, I'm not very well versed with data algorithms (not sure if it matters :/)

Have never really touched AI stuffs (took a module in uni which utilized tensorflow for image recognition and build a project to detect people with face masks on but that's about it)

Am interested in eventually becoming a data scientist in the future for my career, though I'm currently a data analyst more specialized in visualizing.

Looking for resources, be it on books about ML and what not so I can continue advancing my skills and eventually perhaps get a role as a data scientist. Would say that currently I'm quite rusty with my modelling skills (I still know the basic EDA/preprocessing/one-hot labelling and what not, though I would need to google for example codes and adapt to my problem at hand). Any form of other advices would be welcomed!

Currently on my list:

1. Python Data Science Handbook by Jake VanderPlas
2. “Python Machine Learning” by Sebastian Raschka and Vahid Mirjalili
3. Mastering Machine Learning Algorithms by Giuseppe Bonaccorso
4. 100 Days of Python by Angela Yu on Udemy"
570,An Analysis of DeepMind's 'Language Modeling Is Compression' Paper,2,https://codeconfessions.substack.com/p/language-modeling-is-compression,0,
571,Say I trained an autoencoder. Why is that useful? How can I use it?,5,https://www.reddit.com/r/datascience/comments/16u6e27/say_i_trained_an_autoencoder_why_is_that_useful/,4,"# The setup

I’m learning about autoencoders (for use in recommender systems specifically, if it matters). Whenever you read up on what autoencoder models are, the ELI5 usually goes something like this:

> Autoencoders are models which take some input, encode it into a lower dimensional form, then decode it back to reconstruct an approximation of its original form.

I understand that sentence, but I don’t understand why that is useful.

# My confusion

To me it sounds like an autoencoder is basically just an identity function, plus some error/noise. As if after training my model, I now have a tool which can do what…add distortion to an image? Why did I go to the trouble of training an entire neural network for something so trivial?

Clearly I am missing something fundamental. What are the applications exactly? How is a trained autoencoder useful, particularly for recommender systems?

# A speculative answer to my own question (confirmation/rejection appreciated)

All I can think of is this, and this is just a guess: Perhaps we train autoencoders not because we care about their output layer, but because we want their hidden layer?

On this view, it’s kinda like matrix decomposition. MD starts with some giant matrix of “observed” values, then finds two smaller matrices of “latent” values whose product approximates the original. These latent matrices encode lots of valuable info about the original matrix, but in a dense form that’s more efficient to work with. So after we have those dense matrices, we store them for downstream tasks. So MD is done solely to get our hands on those latent features.

Similarly, for NLP there are simple neural networks whose entire job is to learn static word embeddings. These embeddings can then drive downstream NLP tasks. Once our simple NN has learned them, we store them, after which we basically no longer need/use the NN.

So are autoencoders like this? That is, rather than create a model that we use over and over again because the output is useful, are they just vehicles for learning some latent representation of the input, and after learned, we can just discard the autoencoder model?

I hope this makes sense. Any thoughts appreciated.

**EDIT:** If autoencoders simply achieve functionally the same thing as MD through different means, why might someone choose one over the other? What are the practical considerations?"
572,What kind of algorithm do you use the most as a data science pro ?,141,https://www.reddit.com/r/datascience/comments/16tgojm/what_kind_of_algorithm_do_you_use_the_most_as_a/,115,"As a data science professional, what kind of tool / algorithm do you use the most today and what do you think will be used the most tomorrow ?Mainly concerned about classical ML / DL and other statistical tools to analyze data.

I  would like to work in data science. What I like is working with data,  building models and tweaking them to make the data ""speak"".

I started learning classical ML (with the book *Hands-on Machine Learning*).  But now I wonder what I should focus on: go on with classical ML, learn  DL or something else? What skills would be the more useful for a career  in data science?

I'm sorry if  this has been already asked ... I read the wiki and FAQ, and did some  search but didn't find what I was looking for.

&#x200B;

**EDIT:** thanks to everyone who replied, I was not expecting so many answers!  
I gathered the answers here: [https://www.reddit.com/r/datascience/comments/16xriok/quick\_review\_of\_most\_used\_algorithm\_answers/](https://www.reddit.com/r/datascience/comments/16xriok/quick_review_of_most_used_algorithm_answers/)"
573,Really shitty coding skills,29,https://www.reddit.com/r/datascience/comments/16tsf50/really_shitty_coding_skills/,21,"So I am currently going through university course on data analysis and I have been assigned a labwork. Labwork consists of 5 parts and part one is to do an input data analysis, do some descriptive summary statistics, do some plots, make a few manipulations to the data where needed. So descriptive summary statistics part requires me to do a specific data quality report, more specifically it asks me to provide [count, missing_value_%, mode, mode_freq, mode_%, 2nd_mode, 2nd_mode_freq, 2nd_mode_%] for categorical features. 

So as just a default pd.describe() was not enough for it, i did the whole thing manually using .agg() and combining default aggregation functions with my custom functions. This is where I got stuck.

I spent the whole day trying to write a function that would calculate the modes for me and would work together with other functions inside .agg(). In the end I failed and just decided to do a separate mode dataframe that I later just concatenate to the output of df.agg(). 

How do I actually learn all these technical and trivial stuff? Manipulating dataframes, series, permuting them the way I want (also, the same applies to all other “small stuff” in coding - manipulating strings, lists/dicts, applying functions to dataframes and so on)? Because I feel like actual coding basics in Python is what stops me from doing any actual progress…"
574,Help with data disparity,1,https://www.reddit.com/r/datascience/comments/16uekmp/help_with_data_disparity/,5,"Hi everyone! This is my first post here. Sorry beforehand if my English isn't good, I'm not native. Also sorry if this isn't the appropriate label for the post.

I'm trying to predict financial frauds using xgboost on a big data set (4m rows after some filtering) with an old PC (Ryzen AMD 6300). The proportion is 10k fraud transaction vs 4m non fraud transaction. Is it right (and acceptable for a challenge) to do both taking a smaller sample for training, while also using smote to increase the rate of frauds? The first run of xgboost I was able to make had a very low precision score. I'm open to suggestions as well. Thanks beforehand!"
575,Anyone facing this in your organization?,363,https://i.redd.it/ct3p42qt4qqb1.jpg,36,
576,What all visualization and insights could be part of Twitter Sentiment Analysis?,1,https://www.reddit.com/r/datascience/comments/16ue1kp/what_all_visualization_and_insights_could_be_part/,1,"Other than the usual Word-cloud, what all EDA can I prepare on a tweeter dataset? I need to present some pointers, as on what all could be taken out in the Sentiment Analysis. All ideas are welcome"
577,"Hello guys I have just built a wine quality prediction tool, here is my GitHub profile..",1,https://www.reddit.com/r/datascience/comments/16ud8ql/hello_guys_i_have_just_built_a_wine_quality/,0,"I just switched back into my fields and looking to build next 30 days end to end ml project and one LLm models. In this community we have good programmes who have good experience in this field can you guide me what exactly company demands from data science like what they should know and all..

Please take a look at my GitHub profile and please share your feedback..
Your advices will be very useful for me


GitHub -

https://github.com/codedestructed007/Wine_Quality_prediction


Thanks a lot friends/brothers..👍"
578,What is the your top Open Source LLMs?,0,https://www.reddit.com/r/datascience/comments/16ucj3h/what_is_the_your_top_open_source_llms/,5,"For me it's Llama 2.

Llama 2's training data is vast and varied, making it a significant advancement over its predecessor."
579,Big rec sys interview coming up. What topics to prepare?,2,https://www.reddit.com/r/datascience/comments/16u6ps0/big_rec_sys_interview_coming_up_what_topics_to/,1,Applied for an engineering-heavy role. Got an interview that will focus on recommender systems. Don’t know too much about them TBH. What are the critical topics and competencies that I should be familiar with heading into the interview?
580,Can power spectral density be used to detect autocorrelation and candidates for seasonal values in a time series?,0,https://www.reddit.com/r/datascience/comments/16u9nrv/can_power_spectral_density_be_used_to_detect/,2,"BLUF: I have very little knowledge when it comes to signal processing and analysis, so please don't beat me up too bad if I misunderstood something, even if it's fundamental.

I work a lot with time series data, almost all of it containing seasonal and trend components. Due to that, I've grown familiar with things like P/ACF plots, ADF and KPSS tests, STL and ETS decompositions, AR/MA models, and Ljung-Box (and Box-Pierce) tests. I can identify seasonal values to use for the decompositions by applying domain knowledge and outputs from ACF plots. After decomposing, I usually run the residuals through an ACF plot again to see if there are lingering autocorrelations.

I created a custom function awhile back that takes in a time series (or residuals) and uses Welch's method to estimate the power spectral densities. It's my understanding that the dominant frequencies identified in the plot are the most prevalent (by power) frequencies in the time series and can be used as seasonal parameter arguments passed to the decomposition algorithm (eg, STL, ETS).

I have to adjust the sampling rate parameter in the Welch function since it assumes the sampling is performed X number of times per second. If my time bins are hourly, I change it to 1/3600 so that it gives back appropriate frequencies.

If I understand correctly, dominant frequencies are well above the noise floor but when each dominant frequency is selected and removed from the time series, the next most dominant frequency is closer to that noise floor, bringing it closer to the top. Would I be mistaken if I used this process to test for and indicate that white noise has been achieved (ie, no serial correlations)? I would also combine it with output from an ACF plot and a Ljung-Box test, just to be sure.

Also, will this process capture incomplete, intermediate frequencies? What I mean is, for example, if I have a time series of, say 10,000 observations, which show a consistent frequency all the way across but somewhere in the middle, another different frequency appears alongside that lasts for only 3,000 observations before it disappears, will that transient frequency be detected, even though it isn't present throughout the entire time series? Does that make sense?

I just need a sanity check to make sure I'm not all the way out in left field (or even outside the stadium, in the parking lot). Please let me know if the entire thing is wrong and I'm a moron or, in the case that I've messed up but the premise is valid, let me know where I need to revisit.

Hopefully this makes sense."
581,How to properly sample data size down?,2,https://www.reddit.com/r/datascience/comments/16u45ri/how_to_properly_sample_data_size_down/,3,"I have dataset that is computationally inefficient to run due to size/algorithm. I could choose a different model but this is a speculative project based around the model. The model works great on small to mid-size data <100,000 obs. But the dataset I have is a couple million, which I think would take multiple hours to run. I have been trying to figure out sampling strategies, but haven’t been able to clearly figure out if down-sampling is an okay approach. Any thoughts would be great!"
582,Should I complete certs while looking for a job?,12,https://www.reddit.com/r/datascience/comments/16tpji2/should_i_complete_certs_while_looking_for_a_job/,26,"So, I am one of those individuals who has been very unlucky in the job market since graduating in Sept 2022. I do not come from the most traditional background for data science (MSc in Physics), so, I am asking should I go on Coursera, Udemy, etc... and see if there are any data science/analyst certs I should consider completing to make myself stand out or if I should just keep applying.

I will say, I would prefer completing certs on Coursera as due to my situation I feel confident that I can complete the course during the courses free trial. "
583,Tesla trying to screw desperate people,0,https://www.reddit.com/r/datascience/comments/16ukxy1/tesla_trying_to_screw_desperate_people/,28,"This a direct contract hire job post from Tesla not from third party staffing company. Insane 

https://preview.redd.it/9r5v5z2iy0rb1.png?width=589&format=png&auto=webp&s=2e6bdacd9141bdcfe2fc4a7d5810f6e27f086ef5"
584,I made an chocolate and coffee website focused on data transparency! Check out Choffee (feedback appreciated!),3,https://www.reddit.com/r/datascience/comments/16twe33/i_made_an_chocolate_and_coffee_website_focused_on/,2,"Hey data wranglers!

My friend and I launched a new site focused on data transparent e-commerce — [Choffee](https://shopchoffee.com/)! Please check it out and share your feedback! A core mission of ours is impact transparency -- we aggregate order data and visualize our customers impact on [small business](https://shopchoffee.com/impact-on-small-businesses/) on [farms](https://shopchoffee.com/farming-impact/) through Tableau dashboards. A few things we publish on our site are:

1. Average price per ounce of Coffee/Chocolate by farming country
2. Sales by women owned vs male owned businesses
3. Sales distribution of location of small business

**Why is this important?** Data is one of the most powerful assets we own. Companies collect it all the time and sometimes sell it for billions! Imagine how powerful data would be if we could democratize it. That’s why we built Choffee — to share the data we capture back to our customers so they’re empowered to make data-driven shopping decisions and support businesses that share your values. 

**About us —** I'm an ex-actuarial analyst and a data scientist of 4 years and my friend has been a site engineer for 6 years. We’ve noticed that every company collects data and creates dashboards to track insights internally, however so few companies democratize data back to the consumer. We figured its about that that changes! We currently only sell chocolates & coffee on our business, however we plan to expand to broader product categories as we scale.

If you think this is an interesting idea, please consider buying some bars or coffee!

Shop at [shopchoffee.com](https://shopchoffee.com)"
585,Future trends in Data Science salaries and what to expect in the coming years,0,https://www.reddit.com/r/datascience/comments/16uffmd/future_trends_in_data_science_salaries_and_what/,7,"In the ever-evolving world of data science, staying ahead of the curve is essential not only in terms of skills but also in understanding the future landscape of compensation. As the field continues to expand and mature, the future of data science salaries I believe is a topic of great interest not only for me but for all of you as well. 

This is why I decided to look though future trends in Data Science salaries so you don’t have to.  


**Predicting Trends**

Several factors are poised to influence the trajectory of data science salaries in the coming years. First and foremost, the rapid pace of technological advancements is expected to have a profound impact. The increasing use of artificial intelligence (AI), machine learning (ML), and data analytics tools is likely to drive higher demand for skilled data scientists, resulting in competitive salary offerings.  


**Market Demand**

Market demand plays a pivotal role in shaping salaries. As more industries recognize the value of data-driven decision-making, data scientists are becoming indispensable assets. Financial services, healthcare, and e-commerce are anticipated to be among the sectors offering attractive compensation packages to data professionals.  


**Industry Growth**

The growth of industries such as FinTech, HealthTech, and InsurTech is projected to create specialized roles in data science. These niche positions may command higher salaries due to their specialized knowledge requirements and the potential to deliver significant business value.  


To provide a glimpse of the current landscape, here is a table showcasing different data science job titles and their approximate average salaries:  


&#x200B;

|**Data Science Job Title**|**Average Salary (Annual)**|
|:-|:-|
|Data Analyst|$65,000 - $95,000|
|Machine Learning Engineer|$90,000 - $130,000|
|Data Scientist|$100,000 - $150,000|
|Data Engineer|$95,000 - $140,000|
|Business Intelligence Analyst|$70,000 - $100,000|
|AI Research Scientist|$120,000 - $180,000|
|Data Consultant|$80,000 - $120,000|
|Big Data Architect|$110,000 - $160,000|
|Statistician|$70,000 - $110,000|
|Natural Language Processing (NLP) Engineer|$100,000 - $150,000+|
|Data Science Manager|$120,000 - $180,000+|

&#x200B;

**How to get into Data Science?**

For those looking to enter the field of data science, it's crucial to start with a strong educational foundation. Many aspiring data scientists are now considering intensive data science bootcamps as a more focused and efficient way to gain skills. This [comparison table ](https://docs.google.com/spreadsheets/d/1few9dA8toTIA04MYLmvYDFCQpFbEv32jGLwBWquojDc/edit#gid=0)shows different bootcamp alternatives that could help you find out what they can offer and make the best decision for your needs. Another option is a bachelor's degree in a related field like computer science, mathematics, or statistics. You can find the best universities to finish your bachelor’s degree in DS [here](https://www.topuniversities.com/university-rankings/university-subject-rankings/2023/data-science).  


Moreover, learning relevant tools and languages, gaining practical experience through internships or entry-level positions, specializing in areas like machine learning or data engineering, building a portfolio of personal projects, and networking with professionals in the field are all key steps to successfully embark on a career in data science.

In conclusion, the future of data science salaries promises to be exciting and rewarding. With continued technological advancements, growing market demand, and the diversification of industries seeking data expertise, data scientists can expect a dynamic and prosperous future. Staying informed about these trends will be crucial for those looking to thrive in this data-driven era."
586,Masters in which topic will be helpful for getting data science job.,1,https://www.reddit.com/r/datascience/comments/16u5pk4/masters_in_which_topic_will_be_helpful_for/,4,"I am currently pursuing my BE in computer science and I want to be a data scientist and I think doing a master's will boost my chances in getting a Data science job.

So I want to know doing masters on which topic would be better 
1. Mathematics
2. Statistics
3. Computer science and related."
587,PDF Scraping,2,https://www.reddit.com/r/datascience/comments/16u038j/pdf_scraping/,2,"I apologize if this question has been asked before. I am looking for recommendations on how to extract unstructured data from PDF documents. In my current project, I have used Python libraries such as Pypdfium2, Pdfplumber – py, camelot, and Tabula – py to extract various sections from two different types of PDF reports. However, I now have many different PDF formats that need to be extracted in a structured format. Are there any paid tools that would be more effective than developing a custom solution? 

Has anyone tried using LLM models for PDF extraction?  

Is anyone using Azure AI Document Intelligence in production for such tasks?"
588,Database Management vs Statistical Analysis,2,https://www.reddit.com/r/datascience/comments/16u0109/database_management_vs_statistical_analysis/,1,"Hey, working off a deleted post from yesterday.

My main question is: 

My current entry level job is focused on DBM and a lot of SQL. I am obtaining a MSDS this summer and work heavily with statistical analysis. Is it too much of a reach to think I can find some type of tru analysis entry wise? Or should I stop being a b*tch and work my very low paying DBManagement job until graduation. Are the two forever intertwined? 

Thanks all,

P.S. Please be kind as this is just meant as a discussion for a 24 y/o going through an identity crisis."
589,First job,6,https://www.reddit.com/r/datascience/comments/16trg4f/first_job/,6,"Just got my first offer, still in university currently but offered 84k. Smaller company, where I would be the sole data person, is this crazy? Any red flags to look out for?"
590,Title change question,1,https://www.reddit.com/r/datascience/comments/16u42p0/title_change_question/,1,"Is Changing a job title on a resume ok? 

I worked at a company for a year and a half as a data analyst (I left the job 2 years ago) but my responsibilities were basically a data scientist (data modeling, a lot of bayesian modeling, built out experimentation, even did some applied science work). I did really well there but decided to leave because of title. right after I left they decided to re-level everyone from data analysts to data scientists.

I was talking to a recruiter today and noticed that he wasn’t counting those years of experience. Should I change my resume and LinkedIn to say I was a data scientist instead of a data analyst for that job?"
591,How long does a typical project take you to complete?,2,https://www.reddit.com/r/datascience/comments/16txqky/how_long_does_a_typical_project_take_you_to/,2,"I just started as a data analyst. I have two projects, and I am overwhelmed by the deadlines. I am wondering if the deadlines are normal or if I am a slow worker. How long would these projects take you?

1.  About 3000 observations with 34 variables regarding athletes from around 25 different teams and about 15 categories of financial revenue the athletes made over 2 years. Each athlete may have multiple observations. The data is mostly clean but had to be checked for errors because there were a few incorrect values. 

The goal is to recreate an excel workbook summarizing the revenue by sport, type of revenue, and year. The workbook has a sheet for each year summarizing each type of revenue by each team, a sheet for each team each year summarizing each type of revenue, and a few different various summary pages (such as a summary of athletes with no revenue). Someone made this workbook years ago, and it references another workbook I don’t have access to.

2.  About 500 observations with 25 variables each containing survey responses completed by individuals from different groups of stakeholders. Each responder has only one observation, but most of them are included in multiple stakeholder groups. The data was not clean, and the majority of the responses were long form written answers. The goal is to create a short written report and visualizations summarizing the categories of stakeholders that voted, how category voted, how many submitted inappropriate votes, the most common user-written responses, and the trends in how voters answered questions with fixed responses (weighted based on the categories of stakeholder the voter belongs to).

I hope this is a good enough description of the projects!"
592,What DS experience to seek to set up for contracting later in life?,3,https://www.reddit.com/r/datascience/comments/16tsmmy/what_ds_experience_to_seek_to_set_up_for/,0,"I am UK Data Scientist (31F), looking to switch to part time contracting at around 35 to fit in family. I have 3-4 years ahead of hard work and want to build the right skills while work still is my #1 priority.

**Role:** currently a Staff Data Scientist at London scale up with £120k total comp. I do a lot of mentoring and lead multiple projects accross the business. I think I'd be targetting 50% hours for 50% pay as contractor.

**Experience**: 8y of python, spark, most query languages, NLP, Clustering, Information retrieval. I am better Data Scientist than Engineer, but have done both in the past. Happy to pick up new domain expertise/langauges when needed. 

**Questions:**

What specific DS knowlede suits for contracting type roles? 

What type of roles are in demand?

What to look out for? Does overall plan seem realistic?"
593,Analytics for an Energy company,0,https://www.reddit.com/r/datascience/comments/16tytm8/analytics_for_an_energy_company/,1,"Hi, 

I'm looking for guidance and support in my career as a Data Analyst in the energy sector. I'm currently a ""data analyst"" for roughly two years now. I put data analyst in brackets because I feel like a fraud as I haven't done any hard analysis nor do I feel qualified to be a analyst.

For context, I graduated from a non-Stem background but my degree included statistics. I had no idea what I wanted to do after university but fell into digital marketing. I worked as a digital analyst for 2 years helping clients set up and run their marketing campaigns using a data-driven approach - this is something that fulfilled me. However, I didn't like the marketing side of things and only the data side (running analysis on Excel, visualising the data with BI tools and providing insights). As I pivoted towards the data analysis career path, I joined the public sector for a year to hone my skills but that turned out to be a waste of time as I was just pulling data from their propriety software, running macros and producing PowerPoint slides. I had a lot of spare time during that time and proceeded to learn SQL/Python to up-skill, hoping to use my title to get a better job, which I did. 

Now, I'm in the energy sector, which is where I aspire to grow my career. The work is interesting and the people around me are really smart. I want to add as much value to my team so I've started producing automated dashboards to help visualise the operations/finance side of things. I've asked my manager how I can help her but she doesn't have any clue. She wants me to decide how I approach my job so I've tried leaning on other people asking them what they're working on but none of them applies to my job. 

So my question to you is: people who work in the energy sector, what kind do data analysis do you do? How do you add value to the team and where do you start searching for the datasets to produce analysis?"
594,"Is having a fake Data Scientist title good, bad, or neutral?",173,https://www.reddit.com/r/datascience/comments/16surfy/is_having_a_fake_data_scientist_title_good_bad_or/,102,"My title is Senior Data Scientist, but I think most people here would agree that my actual job is probably like senior data analyst or something. Basically, I build slick dashboards for our client-facing people to find or keep clients. I use Python, Tableau, and SQL frequently, but that's about it.

What I'm wondering though is, if it comes a time when I decide to search for a similar role in a different company, what would this fake title do to my resume?

Would it be a good thing, perhaps because most hiring managers would prefer reading that over reading something like ""Data Analyst"" or whatever?

Or would it be a bad thing, perhaps because similar jobs would treat me as being overqualified and too expensive? And I would end up only being qualified for similar ""fake data scientist"" roles?"
595,Are there any datasets with frontal footage of cars on roads/highways?,1,https://www.reddit.com/r/datascience/comments/16tx5v4/are_there_any_datasets_with_frontal_footage_of/,6,This is for my seatbelt fastness detection project. I can't really find any datasets or just even regular YouTube videos of cars with drivers (even barely) visible
596,Data projects in production,1,https://www.reddit.com/r/datascience/comments/16twyc0/data_projects_in_production/,3,"Disclaimer: I am a software dev.

I have a question about how data projects are build for production use.

I understand why data scientist use Python and Pandas a lot for their exploratory work and research.

But when we are talking about deploying data pipelines or other software which is suppose to run for a few years, these Python libs do not seem to be the right choice, because they do not care about backwards compatibility. Yet in the wild I see a lot of production pipelines which are completely written in pandas. 

Same issue in the team I just joined. Tons of pandas code which we cannot update anymore because even a minor version update could break everything.

Another issue I see is that these pipelines are build without any regard to encapsulation or abstraction. Everything is just glued together directly. But they have the same issue any software system has and why the concept of microservices are a thing in software development for years. Any change is a huge mess because these pipelines are big monoliths.

So I guess my questions are: How do you build your production pipelines? Is it normal to use pandas in those pipelines? Do you have any issues with it? What about microservices?"
597,Kaggle Data Visualization certificate,2,https://www.reddit.com/r/datascience/comments/16tpsvq/kaggle_data_visualization_certificate/,0," How can I add a dataset in Kaggle? I am currently working on the data visualization tutorial and I can not finish the final project because I cannot find the ""add data' button. Is anyone facing the same problem? How to fix it? thank you in advance."
598,Regression vs Classification: 90K Dataset with Only 600 Unique Values - Seeking Insights!,4,https://www.reddit.com/r/datascience/comments/16ti2vx/regression_vs_classification_90k_dataset_with/,16,"I’m working on a specific regression problem. My dataset comprises 90,000 samples, and my target variable ranges from 0 to 100 (real numbers). After examining my target variable, I discovered it has only 600 unique values, which is relatively sparse given my dataset’s substantial size (90,000 rows). 25% of these values appear between 1 to 10 times, and 50% are distributed between 100 to 1,000 occurrences.

I considered transforming it into a classification problem; however, this approach presents its own challenges, such as an extremely imbalanced dataset and the daunting prospect of managing 600 classes. Additionally, converting to classification would mean losing the ordinal property of my target variable.

Is there a middle-ground approach that strikes a balance between regression and classification? Does anyone have innovative strategies or know of any research papers that address such issues?"
599,clients procrastination for BRD approval,1,https://www.reddit.com/r/datascience/comments/16tt7vg/clients_procrastination_for_brd_approval/,0,"I wonder,  how a vendor should deal with clients who procrastinate and destructively criticize any point in the business requirements document. We are beyond the deadline due to they do not help. We have successful stories with many clients. But it is the first time to deal with a client who just want to hinder any progress and who is afrid to have a commitment for giving any approval.
Although they are aware of our success stories and we proposed a proof of concept which is accepted, after preparing the BRD to agree on the points of the project, they just procrastinate.
I want to know from experts if they faced similar situations and how you dealt with it to accelerate the approval steps and move on the next stages."
600,Can someone ELI5 the difference between DS types of work?,13,https://www.reddit.com/r/datascience/comments/16taxs3/can_someone_eli5_the_difference_between_ds_types/,4,"I come in peace, I’m a recruiter for a tech company that is trying to learn about data science! 

I find our hiring managers often want data scientist who has “product analytics” or “product data science” experience. 

I understand this high level; I do know the difference between a DS who works on modeling solely and DS that is working on a product. I get usually people are one or the other 

But for a topic such as Search, i have a really hard time discerning the differences. 

So TLDR - can any one ELI5 the difference within DS subgroups like product data science? 


I’ll probably get downvoted to hell because everyone hates recruiters. But I ask you be gentle because I’m just trying to get better at my job and hopefully be a good experience for any of you who may fall into my interview loops :)"
601,ETL Technology,2,https://www.reddit.com/r/datascience/comments/16tkfe5/etl_technology/,1,I'm trying to migrate old ETL processes developed in SSIS (Integration Services) to Azure but I don't know whether it is better to go for a NoCode/LowCode solution like ADF or code the ETL using PySpark. What is the standard in the industry or the most professional way to do this task?
602,[Meta] Majority of people supports the status quo of the DS subreddit,0,https://www.reddit.com/r/datascience/comments/16tv900/meta_majority_of_people_supports_the_status_quo/,6,"Every couple of months a post comes up that addresses the state of the subreddit, giving valid criticism on a given topic. People in the comments often complain about given topic (I have, too, in the past). 

Now, I wanted to gauge how much of that discontent could actually be translated into change. So, I started a little non-representative experiment - for shits and giggles, I guess.

&nbsp;

*My (non-representative) results:*

People in /r/datascience/ - 1.1m

Average views of a post - ~10k

People interacting with a post complaining about too many career questions - ~120

People commenting - ~40

People bringing forward actually constructive comments relevant to the topic - 3

People responding to a direct question about improving engagement - 0

&nbsp;

*My takeaway:*

a) People support the status quo of the subreddit - either because they do like it that way or through their inactivity. Or maybe they don't mind either way.

b) Comments complaining in these kind of posts mostly seem to have only entertainment value."
603,conformal prediction,1,https://www.reddit.com/r/datascience/comments/16tpils/conformal_prediction/,1,"hi can someone explain intuitively the differences between unconditional coverage and conditional coverage split conformal prediction?

&#x200B;"
604,How to recover from submitting incorrect résumé for job application?,3,https://www.reddit.com/r/datascience/comments/16tii86/how_to_recover_from_submitting_incorrect_résumé/,11,"Hi, I majorly fucked up.

I currently work as a statistician in biotech and am looking to transition to a data science career. I worked a very long day yesterday due to standard end of quarter rush, and so when I got home, I spent all evening completely revamping from top to bottom my LinkedIn and Resume.

The problem is my resume. I found this template online that looked great (https://careercup.com/resume) and began filling it out. The fuck up is on the education section. I had filled out the bullet points saying when I had finished my undergrad and masters as well as the relevant coursework I took, but I submitted this new resume to a job (that looked like something I’d absolutely love and be qualified for) with the education section saying I spent all my time at the University of Pennsylvania (what the template lists as the only school — I didn’t go to this school nor did I do my undergrad and masters at the same school). 

How should I go about fixing this? There is no applicant portal where I can easily upload a new document or fix it. I’m feeling so ashamed of myself that I quite possibly blew it so hard. 

Is there any hope for me? I could use some advice for sure. I noticed the error seconds after I submitted my application and have since corrected it."
605,Complex Dataset approach,1,https://www.reddit.com/r/datascience/comments/16tmqz9/complex_dataset_approach/,2,"Hi everyone. I’ve got a dataset composed of pictures with various categorical and numerical information attached to each picture. I’m trying to cluster these into groups. So far i rolled the picture out to pixel data but if I throw in the other data, it seems to get buried under the number of pixels. 

I’m thinking of weighting the nonpixel higher relative to pixel, but not sure what to do about it (1:1 or…) . 
Any ideas or packages to get in the right direction are appreciated."
606,"A data science position is advertised as an internship and as a working student position, I could apply for both but where do I think my chances are better ? What would you do ?",0,https://www.reddit.com/r/datascience/comments/16tksa5/a_data_science_position_is_advertised_as_an/,0,
607,GitHub - anaconda/state-of-data-science: Data from the state of data science survey released by Anaconda each year.,1,https://github.com/anaconda/state-of-data-science,0,
608,Are you actually making your own NNs in 2023?,18,https://www.reddit.com/r/datascience/comments/16t145z/are_you_actually_making_your_own_nns_in_2023/,10,"I'm finding the task in my role are bifurcating into one of two things.  
1. Simple Statistical/ML Model. Linear Models, maybe SVM or similar. Classification or interpretation of data with 'standard' models.

2. Using an open source / proprietary NN model. OpenAI, huggingface for text generation, image generation, embeddings etc. MAYBE I fine tune something, but probably just use off-the-shelf APIs or models.  


Don't get me wrong, I'm not complaining, I enjoy both these things, and writing your own tensorflow or pytorch model can be a real pain.  


Is there anyone out there who is writing their own custom tensorflow or pytorch models in 2023? If so, what are your use cases? It feels like we're moving towards a world with open-source models that are better than almost anything you could spin up in house for most use cases."
609,You don’t have to be a Data Scientist,494,https://www.reddit.com/r/datascience/comments/16sbhun/you_dont_have_to_be_a_data_scientist/,125,"Just a PSA for anyone here that is starting their career, might feel overwhelmed with applying/interviewing for jobs, or is looking for a career change. 

If you’re interested in a Data career, know that there are many different roles out there other than a “data scientist” role. Here’s only a handful of the common titles I see out there these days:

- Business Analyst
- Data Analyst
- Product Analyst
- <INSERT_WORD> Analyst 
- Analytics Engineer
- Data Engineer
- DataOps Engineer
- ML Engineer
- MLOps Engineer (This is my current role -- Feel free to DM me or read [What is MLOps?](https://www.jacoblyman.com/tech-log/published/what-is-mlops) to learn more)
- Product Manager 
- Management/Leadership roles

Feel free to comment any other Data roles that others might not know about!

Edit: Here is a list of other Data roles that were commented on in the thread as of Sept 27th, 2023.

- Risk Analyst
- Statistical Programmer
- Economist
- Actuary
- AI Engineer
- Manager of Business Intelligence
- Marketing Analytics Manager
- Marketing Analyst
- Marketing Operations Manager
- Revenue Operations Manager
- Bioinformatician
- Cheminformatician
- Institutional Research roles
- Operational Research roles
- Analytics Product Management roles"
610,Is there any chance of getting data analytics job in an industry of your interest?,4,https://www.reddit.com/r/datascience/comments/16t9tc4/is_there_any_chance_of_getting_data_analytics_job/,1,"Currently, I’m a sophomore at an university in Southeast Asia, and I’m planning to move to Australia to study on a transnational program. My intention is also to have a job in Australia. In order to achieve the goal, I’m now self-studying some technical tools about data analytics with an aim of doing a project to fill in the CV, while at the same time improving my soft skills and read more about my desired industry - commercial aviation.

The problem is, I really want to work in that industry. Data analytics jobs are everywhere in every industries such as education, finance, manufacturing,… and I see people applying for HUNDREDS of jobs just to finally to land 1 job. Therefore, how do you think about the chance of getting a job in a specific industry, especially mine since there is not a lot firms/companies? I managed to find some when doing research but what’s the possibility, given you have just a little bit more knowledge in that industry?"
611,"Need guidance for Data Scientist, Product Analytics ( Technical Round 45 minutes SQL + Product Sense ) in 2.5 weeks",1,https://www.reddit.com/r/datascience/comments/16tgwqf/need_guidance_for_data_scientist_product/,0,"Hello Everyone,

I have a technical round in 2.5 weeks for the Data Scientist, Product Analytics role at Meta and Recruiter told me it's going to be an SQL + Product case round. I am average at SQL but have some experience with working on product scenario-based real-world problems. How can I prepare myself in a short span of time to clear this round? Do they repeat questions or what will be the best source for study material? Is there someone who is willing to prepare me without asking for heavy fees which they ask on different platforms?"
612,"What software can handle large data, SAS or R?",15,https://www.reddit.com/r/datascience/comments/16sxpls/what_software_can_handle_large_data_sas_or_r/,60,These are the only 2 software used where I work. I'm proficient in R than SAS but if it will be useful I will try to brush it up. Please suggest if there are any other solutions to make R work faster. Spark is something I'm considering too
613,Is there any GPT like tool to analyse and compare PDF contents,1,https://www.reddit.com/r/datascience/comments/16tfk8f/is_there_any_gpt_like_tool_to_analyse_and_compare/,2,"I am not sure if this is the best place to ask, but here goes.

I was trying to compare two different insurances from different companies (C1 and C2)  by reading their product disclosure statements. These are like 50-100 page PDFs and very hard to read, understand and compare. E.g. C1 may define income different to C2. C1 may cover illnesses different to C2. 

Is there any GPT like tool where I can upload the two PDFs and ask it questions like I would ask a insurance advisor. If it is not there is it feasible to be built.

* What the are the key differences between C1 and C2?
*  Is diabetes definition same in C1 and C2, if not what is the difference?
* C1 pays 75% income up to age 65 and 70% up to age 70. How does this compare with C2?

e.g. Document [https://www.tal.com.au/-/media/tal/files/pds/accelerated-protection-combined-pds.pdf](https://www.tal.com.au/-/media/tal/files/pds/accelerated-protection-combined-pds.pdf)"
614,Take my survey!,0,https://www.reddit.com/r/datascience/comments/16tf9hz/take_my_survey/,0," I have made a pretty fun survey for a uni assignment - would really appreciate any respondents. More than happy to respond to other surveys in return!

Takes less than 5 minutes.

https://v4-4-5.saas-us1.surveyengine.com/eu34blcvoikl8j4g9c0b2jk9sf35rns81vt2pl7kr14amejjthq6qdhqou4h6323ia50"
615,A Data Scientist with an idea itching to become the startup Vagabond,0,https://www.reddit.com/r/datascience/comments/16terry/a_data_scientist_with_an_idea_itching_to_become/,15,"Greetings fellow Data Scientists and Dreamers,

I've  finally begun my path towards starting up. I aim to provide the gaming community with alternative methods to obtaining game-playable assets and loot. I'm doing this while reading *Lean Startup* and currently I'm trying to validate some assumptions I've written down on the project's Lean Canvas.  
Yesterday, I deployed a questionnaire at various gaming communities on Reddit and had a slew of different interactions, they ranged from  people calling it a crypto scam (there's no crypto involved in the project at all) while others obliged and took the questionnaire, to others inquiring more about it and engaging me in earnest. From the likely 7K+ persons who saw the post (according the post metrics provided by Reddit) I only got 25 people to actually fill in the questionnaire, however. 

If there are any founders or dreamers among you I'm hoping to learn what approaches some one you have taken to try and validate assumptions in the pre-prototype phase, i.e. the phase where you're trying to gauge if the 'gaps' you think you've found indeed do exist.

For Data Scientists who go out there and gather data what techniques did you folks use to engage your target groups. Have you done campaigns on Reddit, what worked, what didn't work? Thanks a milllion.

Lastly, if you're a gamer, hardcore or casual, would you mind taking the questionnaire, its on a google form: [https://docs.google.com/forms/d/e/1FAIpQLSc6MApt\_ji7rsBgYHnzB3pP901X9VETvO-8ICvGrKAl2SD7nA/viewform](https://docs.google.com/forms/d/e/1FAIpQLSc6MApt_ji7rsBgYHnzB3pP901X9VETvO-8ICvGrKAl2SD7nA/viewform) and if you're not a gamer, would you mind taking a look at it and recommend some feedback so that I may improve upon it?  


Warm regards, 

Rick   


p.s. you can find me on [www.linkedin.com/in/rdmtinez](https://www.linkedin.com/in/rdmtinez) if you wish to connect "
616,Data science for an Investment Professional.,3,https://www.reddit.com/r/datascience/comments/16t7d17/data_science_for_an_investment_professional/,1,"Hello everyone, 
I have a degree in finance (also I'm a CFA charterholder and CAIA candidate)  and 7 years of experience in Fixed Income trading and Risk Management.
I would like to expand my circle of competence through coding/ data science. I was doing reseaech to create a self-paced road map to learn data science for investment professionals, however I don't found a proper road map to start this journey.

I would like to know your thoughts regarding how to learn valuable data science skills to upgrade my professional profile. (I'm excel proficient, but zero programming knowledge)

Which should be the key topics to learn, the first steps and the most valuable sources you will consider for a financial professional in order to gain deep knowledge in data science?

In advance, thank you for you comments."
617,What problems could I try to solve?,1,https://www.reddit.com/r/datascience/comments/16td7vt/what_problems_could_i_try_to_solve/,1,"I work as a BI architect for a retailer. I’ve built out our data warehouse which is feeding a set of powerBI dashboards and cubes for the business. I’ve got access to all of our data - stock, sales, purchasing, web traffic (ga) etc. I do have access to CRM data but my understanding of customer is poor - this is handled by someone else.

So far I’ve done a bit of basket analysis in Python which I’m surfacing in a dashboard for the users which has gone down well. I really enjoyed doing it.

But what else could I look at? I’m sure there are some standard pieces of analysis that retailers would normally do. But we are pretty immature when it comes to moving beyond ‘this is what we sold last week’."
618,Anyone here work as a Data Scientist focused on user growth?,2,https://www.reddit.com/r/datascience/comments/16t83yn/anyone_here_work_as_a_data_scientist_focused_on/,3,"I’m about to start a new job and the objective will be user growth. Focused on personalization (ads targeting), segmentation and measurement of AB Test results.

Company goal is to increase retention and also acquire new users.

Can anyone working in a similar space share their experience?"
619,Interact with an OWL-ViT Object Detection Model,3,https://www.reddit.com/r/datascience/comments/16t4um7/interact_with_an_owlvit_object_detection_model/,1,"There has been a lot of interest in the new computer vision ML models coming out of Meta Research and Google, so we built an interactive demo of what it's like to interact with an OWL-ViT model as an end user in a product.

[**Here is a link to the interactive demo**](https://www.modelbit.com/owl-vit-demo)**.**

[OWL-ViT](https://arxiv.org/abs/2205.06230) is a new object detection model from the team at Google Research. It allows you to identify an object in one image (the “query image”) and then find that same object in any number of target images.

&#x200B;"
620,What would you get your company to pay for as a beginner,1,https://www.reddit.com/r/datascience/comments/16tchf8/what_would_you_get_your_company_to_pay_for_as_a/,3,"As the title says, I'm a beginner in the field and I can probably get my company to pay for a course or a cert or something like that

What would get your company to pay for if you could? Around 1000-1500€"
621,Training regression model using 50 Gb,0,https://www.reddit.com/r/datascience/comments/16tkgyu/training_regression_model_using_50_gb/,16,"Hello guys, I have a question for interview assessment:

We have 50Gb of data, on which we want to run a linear regression, but we have only 8Gb of RAM on our machine. Name several possible regression strategies"
622,How to fill non-obvious gaps in my DS knowledge? Any study lists?,7,https://www.reddit.com/r/datascience/comments/16sxkh1/how_to_fill_nonobvious_gaps_in_my_ds_knowledge/,6,"I got a BS degree on a data science related field but I still find some gaps in my knowledge, that frankly seem embarrasing. For instance, I can use libraries with ease, but might have difficulties calculating some probability function or using the shell. I also didn’t have the chance to use remote servers in the past, and I am not sure I would do well in any company that has lots of data (i.e. I have gaps in memory usage, etc.).

I made a study list based on my gaps in knowledge, but sometimes it’s hard to see things I don’t know (because I don’t know them). I would like to see your study guides / plans, for either interview prep or just learning DS/DE. That may give some ideas on what I am missing.

Alternatively, can someone just list out a few things that you do at your DS job that are non-obvious (i.e. i know most of you do modeling, but what steps before/after modeling people with less experience tend to miss)?

I know that it’s probably best to explore my gaps through actually working, but my current role is program management and I have little to nothing to do in my daily responsibilities with DS. Just trying to learn on my own. 

Thanks!"
623,How important is statelessness on reducers in MapReduce process with parallel processing?,1,https://www.reddit.com/r/datascience/comments/16ta05a/how_important_is_statelessness_on_reducers_in/,0,
624,What is my job title?,2,https://www.reddit.com/r/datascience/comments/16t0xc9/what_is_my_job_title/,1,"I work in the semi-conductor industry and last year I switched from my FSE Technical Supervisor role, to a Data Analyst/ Diagnostics Analyst role where we remotely troubleshoot our etch equipment based on the logs and data sent from the customer. 

Everyone hired on this team has 20+ years of technical support/ FSE experience except me. The reason I was hired is because I have 8 years experience as an FSE, but I am a Computer Science student with programming experience. My bosses goal was for me to create data products that our analysts can use. 

This is so awesome because I essentially get to build a fantastic resume while finishing school for future computer science related jobs, without having to go work an entry level job elsewhere and take a paycut after school.

I started this role October 1st, 2022, and my goal is to finish my degree by October 1st, 2024 and find another job based off of 2 years experience with my current 'X' role (Don't know what to label it as). 

My daily tasks are normal diagnostics stuff, but in the meantime/ extra time I create data products. One product was a workflow/ script that ingests tabular files with all of the down equipment in our customers facility and compares it to our CRM database to see what cases we need to open and provide insight on and which we need to close. Before this, the guys were literally manually comparing each line of reportred down equipment (hundreds of lines) to each case in our database (thousands) and seeing what does and does not exist and acting accordingly. This program I created saves an estimated 500+ work hours per year. 

I've also created standardized forms where our guys enter in applicable data about equipment errors, and it outputs a standardized entry for our cases on CRM so the info can be easily parsed and used for PBI dashboards that we present to the customer. 

I've now gotten the ok from my boss to basically completely stop with diagnostics work and only do data product engineering. My next projects are:

1. Setting up pipelines to ingest csv data from our customer and automatically create cases in CRM for three different types of data we get (work content reduction, normal equipment cases, and niche equipment cases).

2. Work with our companies actual data engineering team to create a pattern matching/ ML application that will ingest the down equipment I mentioned earlier and automate the game plan based off our historical cases. Then, set up pipelines that feed the tabular file containing down equipment mentioned earlier into the ML application so it's automated from start to finish. 

I'm super excited about getting to work on all of this and learn about all the different skills and approaches, but I have no idea what my job title should be on my future resume, if what I'm doing is valuable for finding another job in 2024, and what jobs would offer the highest salary based on this experience. I'm assuming data engineer, but I have no idea.

Can anyone offer some insight please? 

My long term goal is machine learning for a career. I plan to get an MS in Data Science/ Analysis since an MS in Machine Learning doesn't really exist yet."
625,Does it make sense to use sequential feature selection if the model uses a boosting algorithm?,3,https://www.reddit.com/r/datascience/comments/16suvck/does_it_make_sense_to_use_sequential_feature/,2,"So I started a new role recently where the forecasting pipeline runs SFS to create multiple datasets which are then fed to Xgboost models. This pipeline is run weekly, where the data is processed and then new models are trained. This seems odd to me bc Xgboost already does feature selection in a way. I would expect SFS to perhaps be used when beginning a project to help understand the data, but once that understanding is complete and the features are selected, when the pipeline is run, only create those features and update the model as needed.

I haven't found anything online where people use both of these methods. From what I've seen, people will use SFS for linear models. Lots of tutorials of people using boosting models as a method of feature selection by using feature importances, but I've yet to find anything like what I'm seeing in this project.

So, am I missing something to understand the value that SFS can bring when combined with a boosting algorithm? Or is my intuition correct that there is some redundancy in this pipeline and it can be simplified?"
626,Applying to same company after getting not incline,3,https://www.reddit.com/r/datascience/comments/16sqvmg/applying_to_same_company_after_getting_not_incline/,5,"I got a not inclined decision from a FAANG internship this summer. I will graduate this December and am looking for jobs, have already applied to over 200 companies in over 500 positions. Have optimized my resume, use referrals to apply and tailor my profile to the role. 
My question: can I still apply to full time positions at the same company that gave me a not incline? I interned as an L4 DS intern and will now apply for L4 DS position in the other departments. Will this work or would I not be considered since I recently got a not incline? 

Thanks for your help!"
627,is ML code really 5% of ML system?,189,https://www.reddit.com/r/datascience/comments/16ru5ur/is_ml_code_really_5_of_ml_system/,73," 

Google says ML code is less than 5% of the code of ML system? Here is the quote: 'the real challenge isn't building an ML model, the challenge is building an integrated ML system and to continuously operate it in production.' How has this perspective aligned with your experience?

 

https://preview.redd.it/ptgi4hzazeqb1.png?width=1318&format=png&auto=webp&s=a818974f889b6bc648a73a1e23e0c139a0710dfa"
628,Image Segmentation IoU calculation,1,https://www.reddit.com/r/datascience/comments/16sw0w3/image_segmentation_iou_calculation/,0,"In image segmentation, while calculating IoU do the background pixels count? or do we just consider the foreground part of the ground truth?

What is the best approach?"
629,Is a Data Science degree worth it in 2023?,0,https://www.reddit.com/r/datascience/comments/16taani/is_a_data_science_degree_worth_it_in_2023/,22,"I’m currently a senior in high school. I’ve taken 2 classes on Data Science and enjoy it. I’m a big math and business guy and I believe that this field can combine the two.

 However is the degree worth it? I see a lot of info out there saying Data Science isn’t a sustainable field. I want to convince myself that this is misinformation but am unsure.

Secondly for me is the lifestyle/salary part. I’ve seen a lot of job opportunities for DS that work remotely. Im a big skier and see this as an opportunity to live closer to the mountains. But with that is their chances for high salaries with that? This might seem like a dumb question but looking ahead, I have expensive hobbies. I want to make sure there is a good ladder for me to climb to be eventually making great money to set myself + future family up no matter what."
630,"What are some lesser known, but very useful data science tools in python?",4,https://www.reddit.com/r/datascience/comments/16shvtc/what_are_some_lesser_known_but_very_useful_data/,1,
631,Is Grad School Worth It?,24,https://www.reddit.com/r/datascience/comments/16s2ex1/is_grad_school_worth_it/,47,"I’m in my final year of undergrad, getting my degree in political science with a minor in data analytics. I am planning on at least applying to the Data Science M.S. program my school has, but is it a good idea for me to go?

Some factors:

1. It’s a year long program and I’m graduating w my bachelors in 3 years, so i would get to keep my on campus jobs (including being an RA, so free room+board) plus I would still be graduating at 22 (with all my friends, even if it’s a different ceremony)
2. It would cost about \~18k for tuition and fees with the guaranteed aid i would get. This is my biggest hesitation-  I could probably get some job, even though it wouldn't be in DS and make some money instead of taking out more student loans.
3. I believe I am pretty likely to get into the program- i met with an admissions counselor for the fast-track program they offer and he said my profile looked good (my GPA has gone up since this meeting) and they were generally pretty accepting of undergrads from my school.
   1. I decided against the fast track program because i did not feel i had enough time in my schedule to add on 6 grad credits this year.
4. I really want to get into DS, and that feels pretty impossible with my current degree track.
5. For my DA minor, i have taken some DS classes and I have done well and really enjoyed them.
6. The only data-realted semi-professional experience I have is working as a reserach assistant and cleaning and doing a bit of analysis on old political datasets.

Thoughts? Would appreciate any feedback!

edit: the school im at is Syracuse"
632,Anyone else here bogged down with adhoc SQL requests at work?,51,https://www.reddit.com/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/,43,"Co-founder and I are working on something that solves this problem (AI data analyst), curious if anyone else here facing the same issue? Our business users aren't SQL savvy, we deploy self service tools but seems learning curve there are too steep still. The adhoc SQL requests never end!

 Would love to connect and learn more!"
633,How do you handle big data in Jupyter notebook?,93,https://www.reddit.com/r/datascience/comments/16rqnla/how_do_you_handle_big_data_in_jupyter_notebook/,75,"I’m wondering how everyone handles big data. I have 12 csvs each 90 mbs each. I’ve done some analysis imported a couple individually but of course the combine csv script I use to union them on is pretty slow. 

Directly importing from sql is doable but slow as well. I’m relatively new at work but just wondering what everyone else does whether they just look at smaller subsets of their data at a time or they use dask instead of pandas"
634,How do you avoid/deal with the discussion of causality when the project goal was predictive performance to start with?,26,https://www.reddit.com/r/datascience/comments/16s0csk/how_do_you_avoiddeal_with_the_discussion_of/,36,"Have had quite a few experiences when a project starts with the goal of predictive performance but at the end causal questions were thrown at to answer based on the model. 

""When users are looking for casual relation, use Linear models e.g. MLR/Logit"" seems like a commonly given advice for such cases. But, throwing linear models without a proper experimental design, which is often out of scope, doesn't really give any realistic causal effect - think of Simpsons paradox. 

So, am I missing somethig here? What's your go to approach in such cases?"
635,What type of project excites you?,2,https://www.reddit.com/r/datascience/comments/16sdcnt/what_type_of_project_excites_you/,2,"Over the last couple of months I've had a few motivational rollercoasters. One week I'm heads down and flying through my work, I absolutely love it. Other weeks it can't go by any slower and my motivation is super low. 

I started to realize that my shifts in motivation were project driven. When I genuinely like a project work is fun for me. When I hate the project it is the last thing I want to do. 

For me, my favorite projects are building web scrapers, preprocessing super messy data, and building visualization dashboards. At the moment I'm a Business Intelligence Manager, I'm considering shifting over to Data Engineering because that type of work just seems so much more fun to me. "
636,Data Registry suggestions for ML projects,2,https://www.reddit.com/r/datascience/comments/16sdaje/data_registry_suggestions_for_ml_projects/,4,"Looking for suggestions for data registry, with following requirements -

- Programmatic access for both read and write data back (DVC only provides reading data from repo)

- Versioning of all kinds of data (csv, text, images). MLflow provides a workaround to store data as artifacts - Is that good enough ?

- Data access control (user level access, both internal and external to projects) where clients can upload the data directly and DS teams can use it for experiments. 

- On premise solution with container support is preference. 

As of now, I have evaluated DVC, modelstore and mlflow. Please provide inputs"
637,How did you succeed in a new role? What lessons did you take from your previous role?,2,https://www.reddit.com/r/datascience/comments/16sd43a/how_did_you_succeed_in_a_new_role_what_lessons/,2,"When switching to a new role what did you do to ensure that you succeed? What lessons did you learn from your previous job that you took into your new job? 

For example Im in the process of switching jobs and one of the things I’ve learnt is that when delivering results (during fire drills) the way I write my code is focused on simply getting the results out vs being organized, efficient and scalable. While I get from point A to point B the way I get from point A to point B is not the most efficient. I think something I can do is take a step back and take a top down approach to problem solving when I enter my new role."
638,Power BI vs Tableau,2,https://www.reddit.com/r/datascience/comments/16sfxuq/power_bi_vs_tableau/,22,"Hey everyone, so I have the opportunity to work more on data within my current job. I would be the only one in that type of field and would love to gain as much knowledge as I can to maybe later transition fully into a career in data. Should I choose to become an “expert” in Power BI or Tableau and why?

Thank you for your advice"
639,Advice on Comparing Time Series Datasets,3,https://www.reddit.com/r/datascience/comments/16s8ndq/advice_on_comparing_time_series_datasets/,4,"I am working on my master's degree and I have some data that I have no clue how to handle. Any advice would be appreciated.

I have triaxial accelerometer data(50 hz) for some quadruped animal along with internal body temperature (every 5 minutes). I have multiple days worth of this data, and am trying to look at the affect of activity on body temperature. Ideally, we should see activity rise, followed by temperature, and both will fall together as well.

I have already calculated energy: sqrt(x^2 + y^2 + x^2) and averaged that for every 5 minutes, so the activity and temp intervals match. Is this a good approach?

Also, how do I compare these datasets while accounting for the ""lag"" or affect of previous activity on current temperature? I'm not having any luck searching for methods to analyze this data.

Any help or suggestions are appreciated!"
640,NLP Data Cleaning,3,https://www.reddit.com/r/datascience/comments/16s7bx8/nlp_data_cleaning/,3,"I am currently using BERT model and wanted to do some data cleaning. I've tried stuff like removing punctuations and vocabulary / spell checking (e.g. pyspellchecker). However, I noticed that the 'autocorrect' function is inaccurate given also that the texts we handle are more on technical/financial terms.

Does anyone have a suggestion on how to further process the texts? There are also some texts there that are actual sql / python codes so I'm not sure how to eliminate those.

I am somehow contemplating to not do further text cleaning and just deal more on tweaking the hyperparameters instead."
641,Cross Encoders for Long documents and pragagraphs,1,https://www.reddit.com/r/datascience/comments/16sdupt/cross_encoders_for_long_documents_and_pragagraphs/,0,"Hi guys good evening, hope all is well! 

I need some opinions on using cross encoders for long text documents. I have a case where I have list of documents called documents A, and another list of documents called documents B. Based on semantic similarity I am developing a model that matches documents from list A to list B. Here is my current approach

&#x200B;

First I use a Bi-Encoder to encode both lists of documents (using the sentence-transformers/gtr-t5-xl)

Then I use FAISS to get top 100 results from the Bi-Encoder

Finally use a Cross-Encoder to re-Rank the documents returned 

Now my question is Cross-Encoders are usually good for a token limit of 1024 or less, but I am wondering is there a better way to compare longer documents? lets say if I was comparing math books for grade 10 in list A, and math books for grade 11 in list B, so see if there are any books that are similar in semantic context in list A, and B to see which books are like each other what approach should I take? 

Would moving to a vector database be the next best thing as I can keep adding to the database index as new documents are added? 

&#x200B;

Thanks, and would to hear your opinion"
642,Stuck in an internship with no data science work,13,https://www.reddit.com/r/datascience/comments/16rt739/stuck_in_an_internship_with_no_data_science_work/,6,"

I'm doing an internship at this company which pays me an ok amount. Its a 3 month internship and the period is about to be over. Issue is that they give me 0 work. Also due to certain reasons they put me in an unrelated to my work department, so it's not like the work I would have done there would have mattered that much. 

I couldn't get any other internship as this was the best brand name and stipend I could get and the  placement  season is also over so I continued here considering the alternative is me sitting at home for 3 months. 

So my routine has been, come to office, learn my own skills, go home, I don't even see my manager anymore and he doesn't even care because they don't even require me. I have learnt a shit ton during this period and built a portfolio,  i spent all this office time to skill up and made myself competitive in the job market.

Problem is I have only 2 lousy project which I was asked to do to show as my internship expirience. Need your perspective, did I make a huge mistake in doing this and should have asked for more work from office even if it was in unrelated field and meangless?? 

I'm worried about what to say and show in my internship experience, when I talk to recruiters, is it possible to just lie and make up things you din in internship?? I'm planning on just making up fake lists of relevant tasks on my internship expirience section. 

Am i fucked or what? Idk. Sometimes i think im being smart, sometimes I'm think I'm a dumbfuck who focused on self learning instead of corporate projects. Helpp."
643,Are career fairs worth it?,43,https://www.reddit.com/r/datascience/comments/16rjh59/are_career_fairs_worth_it/,29,"Graduate in December with MS and have a career fair opportunity this week. As I attend remotely, campus is 4 hours away. I'd have to do the drive there and back in the same day, so I want to know if there's potential for me to actually get value, or if I'll likely be wasting my time. I understand I'll have to make the best of it, and I'm confident I will, but I really just want to know if success stories in this field happen from networking at career fairs.

I don't have any leads yet, just been blindly applying online. A couple of rejections, but haven't heard back from a majority of applications which are probably ghost. Not much relevant experience in the field, trying to start out as a DA. Thoughts?"
644,"Sanity Test, DummyClassifier",1,https://www.reddit.com/r/datascience/comments/16s724v/sanity_test_dummyclassifier/,0," I  was advised to use DummyClassifier for a sanity test on the best model;  however I'm having a hard time finding instructions as of how to use it  and how to evaluate the results of said test.

Help.

Thanks!"
645,Modern Time Series Forecasting With Python (Book Review),2,https://www.reddit.com/r/datascience/comments/16rzglu/modern_time_series_forecasting_with_python_book/,3,"TLDR for those who don't want to read the whole thing: This is a nicely written book that exposes you to a lot of concepts but fails to teach them to you while providing abstract code that can only be understood after reading through all the custom functions and classes that the author uses.

&#x200B;

I will start by giving you some context:

I switched from economics to statistics this year while only having seen econometrics 1 meaning I had no prior theoretical knowledge of time series analysis but was interested on the field nonetheless. Since I was planning to learn how to code this summer, I bought this book to use it when I had the basics under control.

By the time late july had set I knew the basics of python and the book didi not ask more than that, ""*Since the book explains most concepts from the ground up, basic proficiency in Python is all you need. ""* on the author's own words. I started reading the book around that time and to be completely honest; my opinion from it was at the highest before reading and it only went downwards the more I advanced with it.

The first chapters consist of the basics of time series data (Barely any depth) followed by some preprocessing steps in which the author tries to teach the basics of missing value handling and visualization of the components of the data, ending the first section by exposing some of the classical models. All of this was done in 105 pages! 

The next section of this book exposes machine learning concepts for time series; this is where the two main problems I have with this book start to become apparent:

1- The explanations are very concise; which for complex subjects such as the ones the book covers it really becomes a problem.

2- The book uses an excessive amount of custom functions and classes by the author.

&#x200B;

**1.1 The book is way too short for the amount of content it pretends to teach.**

First things first; *how long* is the book? 

While in Packt's website and Amazon the book is said to be 552 pages long, the actual content of the printed copy I have is 505 pages; for 40€/$ this seems like a pretty nice deal; the problem is that if you look at the sheer amount of stuff this contains; it looks too good to be true; it is. The way so much content is compressed into the book is by cutting off a lot of the meat of what it is trying to teach; this is why I say that the book exposes you to a lot of concepts but fails to teach them to you; 500 pages is not enough for a book that teaches you basic analysis, ML and DL from the ground up, But how egregious can this be? There is only a single 28 pages long chapter for classical statistical models; the explanation for ARIMA is two pages long; this is how bad it gets. You could say that this book is specialized in ML and DL and you would be correct in that statement but the ML part is 154 pages long and the DL one is 194; it's simply too short with its explanations and it makes the book outright frustrating to follow once you reach the Deep Learning section. 

&#x200B;

**1.2 The book has an identity crisis regarding the group it's marketed towards.**

In the amazon page, it says that the book is directed towards Data Scientists but that everything is explained from the ground up so only the basics of Python Programming are strictly needed even though knowledge of ML would help.

Ok, so what is it? I can tell you that the book is overwhelming for beginners; not because the models are explained at their full complexity but because it is done way too fast. Is it for experienced data workers who want to learn time series? Well, you've got some pages dedicated to basic pandas commandas and ML and DL are ""taught"" from the ground up while almost totally neglecting the classical models and any kind of inference so not really. The amazon page says ML knowledge is is recommended and I'd say that maybe if you've reached that point then you may understand the book but for beginners it's simply inaccesible.

It's not just ML though; the book uses Plotly for visualizations; If you know basic python you will most likely go the matplotlib route and showing plotly code without explaining it is a decision that shows even more how this book simply is not for beginners.

The book just explains badly; I am taking the edX MIT Machine Learning Course and while it is more complex; it is perfectly understandable; this book just half-explains stuff and while people who know what they are doing may be able to cope with it, I get the feeling that if you understand the concepts the book is teaching then it may be because you have already moved past them.

&#x200B;

**2. The unbearable custom code**

Up to here I could maybe understand that the explanations simply weren't from me and the book may be better under other people's eyes but it is not the explanations that I find severely short and lacking the largest problem I have with this book; it is the code it uses.

Right from the first  coding chapter the author uses custom functions and classes and it is extremely frustrating. To deal with time series in ML the author uses his own code and while it may be more comfortable, you have to know how to use it and there lies a huge problem; the functions and classes DO NOT have docstrings and because the author does not explain them properly in the book, you have to go to the function definitions to get a sense of what each component is doing. This is simply unbearable and if you do not already know ML and DL, this just adds another layer of abstraction which will make a complex part even more difficult to understand.

It is not only that they are not properly documented but they are not implemented onto a package; it despite all you still try to persevere and make real world usage of this book you will have to copy the full src folder in each folder you are going to make use of the material. The author claims that after finishing the book you are going tobe able to *""build world-class time series forecasting systems"",* But how though? Is the author really saying that you are going to need to make a package out of HIS code to make it usable? This is for me the ultimate dealbreaker.

&#x200B;

**Final comments**

&#x200B;

This was my first contact with Machine Learning and I can tell you that It's hard to think there could be a worse introduction than this. There is a point about halfway through the book in which I stopped working with the code and just decided to finish it to warn others that it simply isn't a good product. The author clearly knows what he's talking about but he but off more than what he could chew and when the best thing about the book are the references and further reading materials that the author recommends, you can see that this book simply is not good.

3.5/10, It just isn't good.

&#x200B;

&#x200B;

&#x200B;

&#x200B;

&#x200B;

&#x200B;

&#x200B;"
646,What do data scientists do anyway?,139,https://www.reddit.com/r/datascience/comments/16r5v0j/what_do_data_scientists_do_anyway/,93,I have been working in a data science Consulting startup as a data scientist. All I've done is write sql tables. I've started job hunting. I want to build AI products. What job description would that be? I know this sounds stupid but I don't want to be an analyst anymore
647,"Creating insights from Battery monitoring parameters (State-of-charge, battery cell voltages, temperature, etc.) to use with AI or model based.",7,https://www.reddit.com/r/datascience/comments/16rp7wj/creating_insights_from_battery_monitoring/,8,"So, in a new role currently and I decided to pursue the health monitoring and impending failures of batteries (Lithium Iron Phosphate, Lithium Ion and a few lead-acid as well) but having never done it before I am not so confident on my approach.

Currently what I have in mind is using the past battery data for a specific site, I would find out the variation in SOC during charging and discharging state and compare it with current day rates while alerting for large changes.

Also, if multiple batteries are connected and while discharging/ charging their SOC deviate too far from each other (standard deviation or difference in min max) I would alert that something is not right.

A bit primitive approaches but wanted something to get going.

Would love to hear from you guys' different approaches that could be used, or you guys have used in the industry.

Thanks!  


PS. Let me know if you need more information."
648,Salary negotiations,1,https://www.reddit.com/r/datascience/comments/16s3hhh/salary_negotiations/,10,"I am a Data Scientist.

How much money should I request during the personal visit to the company?

My potential employer (in Germany) is going to make me an official offer (they invited me and congratulated on a successful application), but if they ask about my salary expectations first, what if I state a figure that is too high? I don't know whether they pay according to the job market or not.

How much less %% than the market median should I position myself, considering that:

* I have less than a year of experience.
* I have a Bachelor's in Computer Engineering, but it's not from a university in Germany.
* I have a B2 level in German and a C1 level in English.

I just don't want to propose a figure that is 20% higher than what they might offer me, as it could potentially hinder or even destroy our negotiations.

[View Poll](https://www.reddit.com/poll/16s3hhh)"
649,How do I assess the viability of a data science masters? What's the core of a data science curriculum?,2,https://www.reddit.com/r/datascience/comments/16rxjwm/how_do_i_assess_the_viability_of_a_data_science/,1,"Hi. I am in a bit of a rut and trying to gain marketable skills that will get me a decent-paying job to tide me over. 

I heard data science can be fun because you try to understand trends and then explain them. I know I'm a good writer and I love understanding *why* things are the way they are.

I was looking at this MS in [Data Science at SUNY Albany](https://www.albany.edu/math/programs/ms-data-science?gclid=Cj0KCQjwvL-oBhCxARIsAHkOiu0n3ZX6KSqnf3MpcrAczfHf2hQY-iX1WDcc9MKE8Xw98fJ9Qr7GWrwaAkUQEALw_wcB). It's open-enrollment and has no prerequisites, and the tuition isn't too bad, so I was wondering if it would make sense as a way to get myself back into the workforce and gaining skills that could be useful.

How would I know whether an MS program is useful for upskilling/entering the workforce? How do I assess the curriculum of a program to see whether it actually preps someone for a data science job? Thank you."
650,Cybersecurity Breach Data Set,1,https://www.reddit.com/r/datascience/comments/16s39a0/cybersecurity_breach_data_set/,0,"Hi everyone,

I'm hoping someone can point me in the right direction. I'm trying to find a cybersecurity breach data set with 10k or more records. I've found several incomplete data sets regarding breaches, but nothing that exceeds 10k records. 

Here's a good example of what I'm looking for: [https://docs.google.com/spreadsheets/d/1i0oIJJMRG-7t1GT-mr4smaTTU7988yXVz8nPlwaJ8Xk/edit#gid=2](https://docs.google.com/spreadsheets/d/1i0oIJJMRG-7t1GT-mr4smaTTU7988yXVz8nPlwaJ8Xk/edit#gid=2)

Does anyone know of a similar data set with 10k records?

Thanks in advance!!

&#x200B;

&#x200B;

&#x200B;"
651,"How do you deal with business data where profit, margins, sales etc. do not jive?",3,https://www.reddit.com/r/datascience/comments/16rt4o4/how_do_you_deal_with_business_data_where_profit/,5,"I am working on a dataset with profit, margins, sales, and total expenses. There are some missing values for the margin and I am trying to fill them up using profit + total expenses, which is also the given definition for margin in the dataset notes. To make sure I can use this definition to fill up the missing entries for margin, I looked at the rows with no missing values and checked whether margins = profit + total expenses is true for all rows. However, half of the data does not satisfy this. How should I go about filling up this data? Thank you very much in advance."
652,What do you do when data quality is bad?,58,https://www.reddit.com/r/datascience/comments/16ra88t/what_do_you_do_when_data_quality_is_bad/,40," I've been assigned an AI/ML project, and I've identified that the data quality is not good. It's within a large organization, which makes it challenging to find a straightforward solution to the data quality problem. Personally, I'm feeling uncomfortable about proceeding further. Interestingly, my manager and other colleagues don't seem to share the same level of concern as I do. They are more inclined to continue the project and generate ""output"". Their primary worried about what to delivery to CIO. Given this situation, what would I do in my place?"
653,"Standard books for Data Science, ML and AI, any suggestions?[D]",1,https://www.reddit.com/r/datascience/comments/16s1tax/standard_books_for_data_science_ml_and_ai_any/,0,"Hi redditors, I'm trying to switch to above said domain and have taken course too but had to revise topics for interview preparations, can't watch classes all the time, so can anybody suggests any standard books one must have which covers above topics.

I have searched in Amazon and Flip kart for those books but they are around 2-3 k(recommended in geekforgeeks) and don't suggest Kindle or any other pdf versions, can't stare screen all the time.

Thanks."
654,Old Republic Actuarial Analyst Salary?,0,https://www.reddit.com/r/datascience/comments/16s6nr7/old_republic_actuarial_analyst_salary/,2,What is the salary for a first year full time Actuarial Analyst at Old Republic International?
655,Does the datacamp ds certificate have a lot of value when applying?,2,https://www.reddit.com/r/datascience/comments/16rucep/does_the_datacamp_ds_certificate_have_a_lot_of/,8,
656,DSA for Data Scientists?,1,https://www.reddit.com/r/datascience/comments/16s04rm/dsa_for_data_scientists/,0,Why do recruiters have to have a DSA screening round for Data Scientists. As if there are not enough tools for a DS to learn. What are your thoughts?
657,ISC-Funded Projects: A Look Back,1,https://www.reddit.com/r/datascience/comments/16rywsh/iscfunded_projects_a_look_back/,0,"We’ve funded various Technical and Social Infrastructure projects. Some highlights include:

🛠️ Technical Projects

R-hub: A centralized tool for checking R packages

Improvements in packages like mapview and sf

👥 Social Projects

SatuRDays: Bootstrapping a system for local R conferences

Data-Driven Discovery and Tracking of R Consortium Activities

Share your thoughts on how these projects have influenced the R community!

Submit your application here: [https://www.r-consortium.org/all-projects/call-for-proposals](https://www.r-consortium.org/all-projects/call-for-proposals) 

\#SatuRDays #RProgramming #Rstats #OpenSource #DataScience"
658,Do you version control your models?,2,https://www.reddit.com/r/datascience/comments/16rsrbj/do_you_version_control_your_models/,2,"Thinking about adopting an open source tool/platform to start versioning our models. So, wanted to see how common it is and which would be recommend tool/platform. 

Here's an [article](https://neptune.ai/blog/top-model-versioning-tools) discussing about alternative options available for model versioning."
659,Poor statistical/Linear Algebra foundation,88,https://www.reddit.com/r/datascience/comments/16r1881/poor_statisticallinear_algebra_foundation/,33,"Often you hear people saying that understanding the inner workings of models and algorithms is irrelevant and a waste of time. I am currently a MS student and struggle to understand some of the inner workings of things such as M-estimation for robust regression and I believe it’s due to my poor statical background (CS undergrad). 

Should I put the time into going back and getting proper statistical credentials (I want to frankly) or is it a nice to have that isnt worth the time and money?"
660,Scrapping Open Street Maps,3,https://www.reddit.com/r/datascience/comments/16rmvvk/scrapping_open_street_maps/,10,"Good morning everyone, let me put you in context. I have a series of home addresses that I need to convert to geographic coordinates. I was thinking of building a small bot with selenium to perform the searches in Open Street Maps and extract the coordinates directly.

My question is if this would be legal or if I should have some consideration when doing it (put some timer between searches to not collapse the web for example).

Thank you very much in advance!

EDIT:

Thanks for your comments. Nominatim is the right tool, it is possible to use the public API for small tasks or host it yourself for more intensive use.

&#x200B;"
661,Open source Data Science projects.,6,https://www.reddit.com/r/datascience/comments/16rk1lw/open_source_data_science_projects/,14,"Hi, I am a **Data Scientist**, I am looking for **open source collaborative projects (not computer vision)** in this domain. I got free time on my had, I just want to be a bit more productive with my free time.

Cheers !!"
662,Question,0,https://www.reddit.com/r/datascience/comments/16s4dmz/question/,6,"Hello, I was wondering if it is actually possible to get a job in data science from a non-uni background, my studies are from a Professional Chef, but since 2020 life has shown me the data world and since I have been studying a lot to get to be a Data Scientist, I have been working in Data analysis for the past almost 3 years now, but want to get in deeper, I'm currently taking the IBM professional Data Science Certificate and I am prepping my portfolio to show what I know and skills I have. I have taken the maths needed, statistics, etc. I even have a Power BI diploma and use it every day at work. What else can you guys recommend me?"
663,"Weekly Entering & Transitioning - Thread 25 Sep, 2023 - 02 Oct, 2023",5,https://www.reddit.com/r/datascience/comments/16rhw3q/weekly_entering_transitioning_thread_25_sep_2023/,87," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new)."
664,How has work changed for you given the shift from growth to profitability?,4,https://www.reddit.com/r/datascience/comments/16rihec/how_has_work_changed_for_you_given_the_shift_from/,3,"For the data scientists/applied scientists/research scientists - What kind of projects are you working on now that the economy has shifted and companies are focusing more on profitability than on growth? 

What techniques have worked for you and what are you looking into as potential solutions?

An example would be - optimizing your marketing campaign spend in channels that give you the most bang for your buck vs just spending arbitrarily to acquire new users."
665,Data Science Training,0,https://www.reddit.com/r/datascience/comments/16rrpj9/data_science_training/,0,"[**Data science**](https://checkmateittech.com/data-scientist-training/) is the process of getting knowledge and insights from large, complex datasets by using methods from different fields, such as statistics, machine learning, and subject expertise. Data scientists collect, clean, analyze, and make sense of data to answer specific business or study questions. During this process, data analysis, feature engineering, model building, and model validation are often done. Organizations can use data science to make smart choices, find patterns, and predict future trends. It can be used in many areas, such as health care, economics, marketing, and the social sciences. For Data Science projects to be successful, the people working on them must know how to use computer languages like Python or R, as well as data manipulation and visualization tools. This lets them make discoveries that are useful and gain insights that can be put to use."
666,"given historical trade data (in forex or crypto), and you know the trade used trailing stops, can you use data science to know how it trailed?",0,https://www.reddit.com/r/datascience/comments/16rxbch/given_historical_trade_data_in_forex_or_crypto/,0,"Imagine you have a time series and every second you are always in a trade. You can trade and say price will go up or price will go down.


Your time series looks like:

 <current seconds in time series, trading direction is UP, percent change in price from trade entry>



you also know the trades used trailing stops (let me know if you dont know what they are). but you do not know how it was trailed.


can data science be used to reverse engineer how to trail the trades to make the exact trades historically?"
667,Z score of weighted percentage,1,https://www.reddit.com/r/datascience/comments/16rqsvw/z_score_of_weighted_percentage/,0,"In my dataset, I have number of makes and numbers of attempts and I want to rank the shooters. 

How can I use z score in a way that takes into account both accuracy and volume?"
668,Is Alteryx a practical skill to learn?,15,https://www.reddit.com/r/datascience/comments/16r9lfj/is_alteryx_a_practical_skill_to_learn/,18,"I find it to be a very useful tool.  However, only my current employer is using it.  If I change jobs, I won't have access to Alteryx anymore and my skill with deteriorate with non-use.     
It is unlike Excel where I'm sharpening my skills with it every place I work.  Any software is worth learning for your career, but we humans tend to forget knowledge what don't use.  Or I do at least, maybe it is just me.  Your thoughts?  
"
669,How to use ML/DL with data analysis?,0,https://www.reddit.com/r/datascience/comments/16rq89p/how_to_use_mldl_with_data_analysis/,0,"Hi everyone, I am kinda of lost on this matter.

I used to work with tensorflow in the past to build models for image recognition and classification.

But I don't really know what to learn in ML/DL so I can implement it with data analysis.

If anyone has any tips, please do tell.

Much appreciated.👍"
670,Good data analysis projects for portfolio?,1,https://www.reddit.com/r/datascience/comments/16rq5ll/good_data_analysis_projects_for_portfolio/,1,"Hey everyone, does anyone know any good projects to add to my portfolio as a junior data analyst ?

I currently work with postgresql, python and powerbi."
671,What is the best way to predict missing data?,2,https://www.reddit.com/r/datascience/comments/16rlfwd/what_is_the_best_way_to_predict_missing_data/,10,"Hey guys, I'm a business major that is recently learning data analytics. I'm currently using pandas library.

I have **the trading** **volume data for 2 stocks, earnings dates, closing price data**. However for stock b December's volume data is not available. Can anyone indicate to me how I should predict the volume data for every day of December? I know I have to train some sort of model, but I have no experience doing that, how should I approach this? What sources should I use to learn? thanks guys"
672,AI Career,1,https://www.reddit.com/r/datascience/comments/16rp02v/ai_career/,2,"I'm currently in my first year at the University of Amsterdam, diving into Econometrics and Data Science. In my third year I will specialize in data science with courses like ""Time Series Analysis,"" ""Text Retrieval and Mining,"" and ""Reinforcement Learning.""

I'm super passionate about AI and I'm aiming to join the industry after graduation. I'd really appreciate some pointers:

* **Career Path:** What steps should I be taking now to set myself up for success in AI? Are there specific skills or areas I should focus on?
* **Job Search:** Any advice on finding a solid AI job post-graduation? Any companies or sectors you'd recommend for someone just starting out?
* **Study Tips:** University life is a whirlwind. Do you have any study strategies or resources that helped you out?
* **Networking:** How can I start connecting with the AI community? Are there events or online groups that you found valuable?

Thanks in advance for any insights or tips you can share."
673,"For people in the industry, how do you explain the poor interpretability of some ML techniques to bosses who are not data scientists?",91,https://www.reddit.com/r/datascience/comments/16qtywk/for_people_in_the_industry_how_do_you_explain_the/,56,"I'll be having a job interview in a few days and I think this question might come up and I personally don't know how to explain it to a layperson. Black box methods may come in handy one day, but I realized just now that I can't briefly explain how it works without making it sound like magic. What's your workaround for this? Have you been in a situation where you presented your results and you had to explain how neural networks operate in detail? Any similar experiences?"
674,How do you send data in batches to an open source LLM to be processed on GPU,0,https://www.reddit.com/r/datascience/comments/16rkq3f/how_do_you_send_data_in_batches_to_an_open_source/,2,"Say for eg. I am doing sentiment analysis using Llama 2. I have daily news articles which I wish to get daily sentiment ratings.

Rather than looping daily in my Python script or prompt template, how do I send say 30 days of daily news in a batch to Llama 2 to get back 30 daily sentiment ratings in one go so that I am fully utilizing my GPU resources?"
675,"Did academics prepare you for your role, or for the DS/ML/AI field?",19,https://www.reddit.com/r/datascience/comments/16qxfo0/did_academics_prepare_you_for_your_role_or_for/,19,"I browse through post often and general have limited understanding of what is being discussed. I can understand the very basics but the more indepth the convo goes the less I'm able to follow.

I currently work as a BI developer, use SQL quite a bit and PowerBI, power automate.

My goal is to eventually dive into Data Science. At this time I would say I am no where close to being ready. I am enrolled amd planning to start Georgia Tech OMSA this upcoming spring. My question is.. did academics prepare you adequately to where you're able converse and function well as a DS?

TIA!"
676,"is there a way to calculate jitter or smoothness in motion capture movement, that result in numbers/values? if so, is there any standard to it?",1,/r/computervision/comments/16rgcfh/is_there_a_way_to_calculate_jitter_or_smoothness/,2,
677,"Hyperparameter Tuning for SVM, stuck!",1,https://www.reddit.com/r/datascience/comments/16rfar3/hyperparameter_tuning_for_svm_stuck/,0,"Can someone guide as to how I derive the optimal cost and gamma values in R.

Do you use tune.svm() ?"
678,Seeking Feedback to Improve my Data Scientist CV,0,https://www.reddit.com/r/datascience/comments/16re6pa/seeking_feedback_to_improve_my_data_scientist_cv/,6,"Hello everyone!

I hope you're all doing well. I'm currently working on fine-tuning my CV for a data scientist/ML Engineer or MLOps (need to acquire more skills in here) position, and I would greatly appreciate your feedback and insights.

I've included all the essential details, but I want to make sure it truly reflects my skills and experience in the best possible way. If you have any tips, suggestions, or even specific areas you think I should focus on, please feel free to share them in the comments below.

Here's the link to my CV: [https://ibb.co/9wL6H4N](https://ibb.co/9wL6H4N) or [https://postimg.cc/LJR3qQ2N](https://postimg.cc/LJR3qQ2N)

Thanks a million in advance for your help! Your expertise means a lot to me, and I'm excited to hear your thoughts. 😊"
679,Data-cleaning tool,0,https://www.reddit.com/r/datascience/comments/16rhd3n/datacleaning_tool/,1,"Hello, im new here. Need some github repositories to run some data-quality and data -cleaning tests, please!"
680,"Time series forcasting, when to split the target?",0,https://www.reddit.com/r/datascience/comments/16ra2yz/time_series_forcasting_when_to_split_the_target/,3,"Hi all, I'm using AWS forcasting to forcast demand over different departments (fashion, home, elec, etc). Would it be suitable to do different forecasts for different departs that's have different related time series?
Some related time series that I have tried reduce the WAPE on some departments but increase it on others"
681,Should I accept this data science job (i.e. how bad is the job market?),151,https://www.reddit.com/r/datascience/comments/16qaxeq/should_i_accept_this_data_science_job_ie_how_bad/,126,"I'm a master's student rn, graduating next year and just got a return offer from the internship I did this summer. It was a cool place and I liked the people, but their salary offer isn't great - $68,000 in a high CoL city (Washington DC area). It does come with good benefits which is nice, and I've been told it's very likely my pay would go up to at least $90,000 after two years, with potential for higher. 

Should I accept given the current state of the job market? Or should I decline and search for a higher-paying opportunity later? Financially, I believe I could make $68,000 work, but it would be tough with student loan debt and DC rent. DC is also a considerable distance from my family and not ideally where I'd want to settle, although I generally like the area. The position does not allow WFH either which is a downside."
682,Are there too many posts focused on career discussions?,124,https://www.reddit.com/r/datascience/comments/16qc882/are_there_too_many_posts_focused_on_career/,45,"I've noticed a trend over the past few months on this subreddit, and it's something I'd like to address in a constructive manner. It seems that a significant portion of the posts here revolves around career-related queries, job offers, and CV reviews. While I understand the value of such discussions, when they dominate 99% of the content, it can diminish the enthusiasm for the subreddit.

IMHO, I believe this sub could benefit from a more diverse range of posts. I'd love to see more members sharing their projects, posting blog articles about new techniques, and discussing about technical topics. I believe we can all learn a lot from  these kind of conversations.

Also, notice that many of the common career questions have already been comprehensively addressed in previous discussions. Instead of repeating the same topics, we can work together to create a space where we can learn about new topics.

What do you thing? Do you think the same or am I simply becoming old and grumpy?

PS. Maybe we could download data from the posts on this sub and test my hypothesis, ie: test that the frequency of posts with the Flair ""Career"" are more abundant that the others ;)"
683,What tools do you use on your data science projects from proof of concept to production?,1,https://www.reddit.com/r/datascience/comments/16r7elg/what_tools_do_you_use_on_your_data_science/,3,"I see a large amount of relevant open source tools and libraries to assist in peripheral (not the actual data processing or modeling) areas of data science. I mean tools that make certain important tasks easier. For instance: kedro, hydra-conf, nannyml, streamlit, docker, devpod, black, ruff, pandera, mage, fugue, datapane, adn probably a lot more.

What do you guys use for your data science project?"
684,Exploring Numexpr: A Powerful Engine Behind Pandas,9,https://www.reddit.com/r/datascience/comments/16qrxs4/exploring_numexpr_a_powerful_engine_behind_pandas/,7," Enhancing your data analysis performance with Python's Numexpr and Pandas' eval/query functions 

 This article was originally published on my personal blog [Data Leads Future.](https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/) 

&#x200B;

[ Use Numexpr to help me find the most livable city. Photo Credit: Created by Author, Canva ](https://preview.redd.it/29ec8ukgr5qb1.png?width=1200&format=png&auto=webp&s=238da4465da17bd301b49112d574444b16d4113c)

 This article will introduce you to the Python library [Numexpr](https://numexpr.readthedocs.io/en/latest/intro.html?ref=dataleadsfuture.com#), a tool that boosts the computational performance of Numpy Arrays. The eval and query methods of Pandas are also based on this library.

 This article also includes a hands-on weather data analysis project. 

 By reading this article, you will understand the principles of Numexpr and how to use this powerful tool to speed up your calculations in reality. 

# Introduction 

# Recalling Numpy Arrays

 In a previous article discussing Numpy Arrays, I used a library example to explain why Numpy's Cache Locality is so efficient: 

[https://www.dataleadsfuture.com/python-lists-vs-numpy-arrays-a-deep-dive-into-memory-layout-and-performance-benefits/](https://www.dataleadsfuture.com/python-lists-vs-numpy-arrays-a-deep-dive-into-memory-layout-and-performance-benefits/)

 Each time you go to the library to search for materials, you take out a few books related to the content and place them next to your desk. 

 This way, you can quickly check related materials without having to run to the shelf each time you need to read a book. 

 This method saves a lot of time, especially when you need to consult many related books. 

 In this scenario, the shelf is like your memory, the desk is equivalent to the CPU's L1 cache, and you, the reader, are the CPU's core. 

&#x200B;

[ When the CPU accesses RAM, the cache loads the entire cache line into the high-speed cache. Image by Author ](https://preview.redd.it/3k7gdxywr5qb1.png?width=625&format=png&auto=webp&s=5e6a2ed6620cf23638d9c3f20e5f6f46a54e0049)

### The limitations of Numpy

 Suppose you are unfortunate enough to encounter a demanding professor who wants you to take out Shakespeare and Tolstoy's works for a cross-comparison. 

 At this point, taking out related books in advance will not work well. 

 First, your desk space is limited and cannot hold all the books of these two masters at the same time, not to mention the reading notes that will be generated during the comparison process. 

 Second, you're just one person, and comparing so many works would take too long. It would be nice if you could find a few more people to help. 

 This is the current situation when we use Numpy to deal with large amounts of data: 

* The number of elements in the Array is too large to fit into the CPU's L1 cache.
* Numpy's element-level operations are single-threaded and cannot utilize the computing power of multi-core CPUs.

 What should we do? 

 Don't worry. When you really encounter a problem with too much data, you can call on our protagonist today, Numexpr, to help. 

## Understanding Numexpr: What and Why

### How it works

 When Numpy encounters large arrays, element-wise calculations will experience two extremes. 

 Let me give you an example to illustrate. Suppose there are two large Numpy ndarrays: 

    import numpy as np 
    import numexpr as ne  
    
    a = np.random.rand(100_000_000) 
    b = np.random.rand(100_000_000)

 When calculating the result of the expression a\*\*5 + 2 \* b, there are generally two methods:

 One way is Numpy's vectorized calculation method, which uses two temporary arrays to store the results of a\*\*5 and 2\*b separately.  

    In: %timeit a**5 + 2 * b
    
    Out:2.11 s ± 31.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)

 At this time, you have four arrays in your memory: a, b, a\*\*5, and 2 \* b. This method will cause a lot of memory waste. 

 Moreover, since each Array's size exceeds the CPU cache's capacity, it cannot use it well. 

 Another way is to traverse each element in two arrays and calculate them separately. 

    c = np.empty(100_000_000, dtype=np.uint32)
    
    def calcu_elements(a, b, c):
        for i in range(0, len(a), 1):
            c[i] = a[i] ** 5 + 2 * b[i]
            
    %timeit calcu_elements(a, b, c)
    
    
    Out: 24.6 s ± 48.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)

 This method performs even worse. The calculation will be very slow because it cannot use vectorized calculations and only partially utilize the CPU cache. 

### Numexpr's calculation

 Numexpr commonly uses only one evaluate method. This method will receive an expression string each time and then compile it into bytecode using Python's compile method. 

 Numexpr also has a virtual machine program. The virtual machine contains multiple vector registers, each using a chunk size of 4096. 

 When Numexpr starts to calculate, it sends the data in one or more registers to the CPU's L1 cache each time. This way, there won't be a situation where the memory is too slow, and the CPU waits for data. 

 At the same time, Numexpr's virtual machine is written in C, removing Python's GIL. It can utilize the computing power of multi-core CPUs. 

 So, Numexpr is faster when calculating large arrays than using Numpy alone. We can make a comparison: 

    In:  %timeit ne.evaluate('a**5 + 2 * b')
    Out: 258 ms ± 14.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)

### Summary of Numexpr's working principle

 Let's summarize the working principle of Numexpr and see why Numexpr is so fast: 

 **Executing bytecode through a virtual machine.** Numexpr uses bytecode to execute expressions, which can fully utilize the [branch prediction](https://en.wikipedia.org/wiki/Branch_predictor?ref=dataleadsfuture.com) ability of the CPU, which is faster than using Python expressions. 

 **Vectorized calculation.** Numexpr will use [SIMD (Single Instruction, Multiple Data)](https://en.wikipedia.org/wiki/Single_instruction,_multiple_data?ref=dataleadsfuture.com) technology to improve computing efficiency significantly for the same operation on the data in each register. 

 **Multi-core parallel computing.** Numexpr's virtual machine can decompose each task into multiple subtasks. They are executed in parallel on multiple CPU cores. 

 **Less memory usage.** Unlike Numpy, which needs to generate intermediate arrays, Numexpr only loads a small amount of data when necessary, significantly reducing memory usage. 

&#x200B;

[ Workflow diagram of Numexpr. Image by Author ](https://preview.redd.it/46plaxk6t5qb1.png?width=863&format=png&auto=webp&s=8c0bb7311c4fc743d720c2e0cec3c28c1ff98ed3)

## Numexpr and Pandas: A Powerful Combination

 You might be wondering: We usually do data analysis with pandas. I understand the performance improvements Numexpr offers for Numpy, but does it have the same improvement for Pandas? 

 The answer is Yes. 

 The eval and query methods in pandas are implemented based on Numexpr. Let's look at some examples: 

### Pandas.eval for Cross-DataFrame operations

 When you have multiple pandas DataFrames, you can use pandas.eval to perform operations between DataFrame objects, for example: 

    import pandas as pd
    
    nrows, ncols = 1_000_000, 100
    df1, df2, df3, df4 = (pd.DataFrame(rng.random((nrows, ncols))) for i in range(4))

 If you calculate the sum of these DataFrames using the traditional pandas method, the time consumed is: 

    In:  %timeit df1+df2+df3+df4
    Out: 1.18 s ± 65.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)

 You can also use pandas.eval for calculation. The time consumed is: 

 The calculation of the eval version can improve performance by 50%, and the results are precisely the same: 

    In:  np.allclose(df1+df2+df3+df4, pd.eval('df1+df2+df3+df4'))
    Out: True

### DataFrame.eval for column-level operations

 Just like pandas.eval, DataFrame also has its own eval method. We can use this method for column-level operations within DataFrame, for example: 

    df = pd.DataFrame(rng.random((1000, 3)), columns=['A', 'B', 'C'])
    
    result1 = (df['A'] + df['B']) / (df['C'] - 1)
    result2 = df.eval('(A + B) / (C - 1)')

 The results of using the traditional pandas method and the eval method are precisely the same: 

    In:  np.allclose(result1, result2)
    Out: True

 Of course, you can also directly use the eval expression to add new columns to the DataFrame, which is very convenient: 

    df.eval('D = (A + B) / C', inplace=True)
    df.head()

[ Directly use the eval expression to add new columns. Image by Author ](https://preview.redd.it/ykotgj0ut5qb1.png?width=495&format=png&auto=webp&s=f005b5782e751f2f5ea90fcddd8169cfcc2c5751)

### Using DataFrame.query to quickly find data

 If the eval method of DataFrame executes comparison expressions, the returned result is a boolean result that meets the conditions. You need to use Mask Indexing to get the desired data: 

    mask = df.eval('(A < 0.5) & (B < 0.5)')
    result1 = df[mask]
    result

[ When filtering data only with DataFrame.query, it is necessary to use a boolean mask. Image by Author ](https://preview.redd.it/izwngwizt5qb1.png?width=469&format=png&auto=webp&s=c7f0e4806977ccdcf3c588a67a6c913255f47091)

 The DataFrame.query method encapsulates this process, and you can directly obtain the desired data with the query method: 

    In:   result2 = df.query('A < 0.5 and B < 0.5')
          np.allclose(result1, result2)
    Out:  True

 When you need to use scalars in expressions, you can use the @  to indicate: 

    In:  Cmean = df['C'].mean()
         result1 = df[(df.A < Cmean) & (df.B < Cmean)]
         result2 = df.query('A < @Cmean and B < @Cmean')
         np.allclose(result1, result2)
    Out: True

 This article was originally published on my personal blog [Data Leads Future.](https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/) "
685,"Idea for a Tool - ""Define your data science project""",0,https://www.reddit.com/r/datascience/comments/16r6quo/idea_for_a_tool_define_your_data_science_project/,0,"Hey guys, I've worked with a lot of clients that have poorly scoped AI/data science projects, and I thought of a business idea that might be really helpful. Would love your feedback

* Most data science consultants have scoping questionnaires that they use for the project discovery process. But the idea is for this questionnaire to exist on its own
* Basically, if clients might have a data science project, they would go to a website and complete a survey to better scope their idea. The survey will have mandatory fields - e.g. what kind of data do I have, what kind of data do I want, what kind of budget i have, etc.
* This will allow clients to bring have a much better scoped project, BEFORE they even talk to any data science consultants. Much better engagement experience from the start for everyone
* Target User: Small businesses that have data science needs but do not have in-house data scientists (will need an external data science consultant to come in and help them) 
* Revenue: Perhaps through commission from leads generated by data science consultants? Haven't really thought through this part, although I would hesitate to charge the client side at all"
686,"Looking for graduate admissions data, DoED",1,https://www.reddit.com/r/datascience/comments/16r1z2f/looking_for_graduate_admissions_data_doed/,0,"I've found the troves of data from the department of education on undergraduate admissions. School acceptance rates, ACT / SATs, etc. 

Is there any such data for graduate schools or programs? For example, GRE / GMAT data, or simply acceptance rates. Any help would be greatly appreciated!"
687,Quantum physics + Data Science,0,https://www.revealedge.com/quantum-physics-and-data-science-exploring-the-limitless-possibilities-of-a-dynamic-duo/,0,Data science + Quantum physics = 21st century....
688,Limitations of Excel for academic analysis,0,https://www.reddit.com/r/datascience/comments/16r3rb7/limitations_of_excel_for_academic_analysis/,14,"When doing stock market analysis with 100 years of price data, I found that I was able to do everything I wanted in Excel. Do we only need to use R, Python, SAS etc. When analysing more than circa 1 million rows of data? Assuming that I am not doing any automation or integration, only academic analysis."
689,Can someone please suggest me on how to autofit model in GARCH?,0,https://i.redd.it/4b0ig2c3i7qb1.jpg,0,
690,About Junior Data Scientist Interview,22,https://www.reddit.com/r/datascience/comments/16qd0ij/about_junior_data_scientist_interview/,16,"Hello everyone, I have called an interview for 2 days and there will be 3 person participated in interview : Talent acquisition specialist,  Data Scientist, Director. What kind of questions should I expect  from them. I need some help because I am fresh graduate and I haven't experienced it before. thanks in advance. Here is job description and requirements:

**Skills Required:**

* Bachelor’s Degree in Computer Science, IT, or similar field; a Master’s is a plus
* Minimum 1 year experience as a data engineer/scientist or in a similar role
* Technical expertise with data models, data mining, and segmentation techniques.
* Ability to compose pipelines for data science models.
* Knowledge of Machine Learning techniques, including decision tree learning, clustering, artificial neural networks, etc., and their pros and cons
* Data Wrangling – proficiency in handling imperfections in data.
* Programming Skills – good knowledge of statistical programming languages like R, Python, and hands on experience database query languages like SQL.
* Statistics – Good applied statistical skills, including knowledge of statistical tests, distributions, regression, maximum likelihood estimators, etc.
* Basic Math Skills (Linear Algebra) - understanding the fundamentals of Linear Algebra.
* Knowledge with Timeseries data analysis and modelling.
* Knowledge with regular expressions.
* Knowledge with Data Visualization Tools like Power BI, Spotfire, Tableau, matplotlib, etc.
* Great numerical and analytical skills
* Excellent Communication Skills –efficiently communicating with both a technical and non-technical audience."
691,Writing a CRM : how to extract valued data to customers,1,https://www.reddit.com/r/datascience/comments/16qvvl0/writing_a_crm_how_to_extract_valued_data_to/,4,"Hi
I've wrote a CRM for shipyards, and other professionals that do boat maintenance.

Each customer of this software will enter data about work orders, products costs and labour...
Those data will be tied to boat makes, end customers and so on ...

I'd like to be able to provide some useful data to the shipyards from this data. I'm pretty new to data analysis and don't know of there are tools that can help me to do so ?
I.e. I can imagine when creating a new work order for some task (let's say an engine periodical maintenance), I could provide historical data about how much time it does take for this kind of task... or even when a special engine is concerned, this one is specifically harder to work with, so the  planned hour count should be higher and so on...

Is there models that could be trained against the customer data to provide those features?

Sorry if it's in the wrong place or If my question seems dumb !

Thanks"
692,Time Series Forecasting using RNN,4,https://www.reddit.com/r/datascience/comments/16qnryv/time_series_forecasting_using_rnn/,5,"Hello guys, I needed some assistance with Forecasting a Time Series dataset using Neural Nets.

For context, the data has an annual seasonality with daily records of upto 5 years. Previously, I had used Statistical Methods like TBATS and DHR along with GARCH to transform and forecast.

Now, I have been attempting to do the same using RNNs. I started off with GRU and LSTM with a few Hyperparameter Optimization Algorithms for the optimum depth, lookback window etc. only to end up with an eggregious yield of approx 10 MAPE.

Thus, I'd appreciate your input as to what can I improve be it an industry practise, some other insightful articles on the same or even alternative ML approaches!

Thanks in advance :)"
693,Just published my second blog on medium about feature scaling in machine learning please have a look,0,https://medium.com/@harshsmj1504/understanding-feature-scaling-in-machine-learning-techniques-implementation-and-advantages-fd9065a349aa,0,
694,How can I further improve the accuracy of my CNN based on transfer-learning?,6,https://www.reddit.com/r/datascience/comments/16qj0w2/how_can_i_further_improve_the_accuracy_of_my_cnn/,14,"I employ existing widely used CNNs (e.g., `Xception`, `DenseNet169`, `InceptionV3`) via transfer-learning using Keras for a classification task of `10` classes. I've employed almost every available model but still experiencing overfitting as you can see via the attached accuracy-epoch graph, which was obtained during training. I re-calculate the weights of the layers that come with the existing models (*a.k.a.* base models). I've employed KerasTuner to optimize the hyperparameters such as the activation function, optimization algorithm, and learning rate. As a result of this task, `Adam` and `ReLU` were set as the optimization algorithm and activation function, respectively. To prevent overfitting, following the base model, I've added a `Dense` with `1,024` units and a `Dropout` layer with a dropout rate of `0.6` (kept that high to prevent overfitting) just before the final `Dense` layer with `softmax` activation function, which is solely responsible for the classification. I do use a 4-fold CV and the test set/train set ratio is `.3`. The total number of samples is `1,000` and each sample has a shape of `224x224x3`.

Here are the scores that I've obtained on the test set:

Acc: `72.5%`

F1-Score: `72.287%`

Precision: `73.734%`

Recall: `72.5%`

Any recommendations to improve the test accuracy of the model are greatly appreciated. Please feel free to ask for any further information, which I might missed to note.

Many thanks in advance for your time.

*p.s. This task is a part of my own research project; not seeking help for homework or an exam.*

[Accuracy-Epoch graph](https://preview.redd.it/ehqqfp1gc3qb1.png?width=750&format=png&auto=webp&s=635ff0368530a400c271912e370aa7751b28c6de)"
695,Never understood this.,406,https://www.reddit.com/gallery/16prrz3,84,
696,Are these DS Virtual Internships good to get started?,1,https://www.reddit.com/r/datascience/comments/16qt2n3/are_these_ds_virtual_internships_good_to_get/,2,"I am an aspiring data scientist currently pursuing a BCs in CS (2nd year). Lately, I've been actively searching for remote data science internships to gain practical experience and make my resume strong. I've come across several online virtual internship programs that are open to anyone. I am wondering if these opportunities are worth the time and if it's appropriate to include them in my work experience. Here are a few examples of such programs:

1. [iNeuron](https://internship.ineuron.ai/)
2. [OpenWeaver](https://community.openweaver.com/t/virtual-internship-in-data-science-apply-now/114521)
3. [The Spark Foundation](https://internship.thesparksfoundation.info/)
4. [Let's Grown More](https://letsgrowmore.in/vip/)"
697,Data Science certification.,0,https://www.reddit.com/r/datascience/comments/16qslw1/data_science_certification/,45,Hi guys are there any good certifications for data science that companies actually take seriously?
698,guidance,0,https://www.reddit.com/r/datascience/comments/16qsj8s/guidance/,0,"hello everyone I am a sophomore data science student I want to learn data science online for some reason I cant rely on my uni so I am watching lectures on pandas numpy and other stuff but I am confused about practice like how do I practice to get the grasp on the skills and I want to learn statistics too so should I cover whole statistics or are there some specific topics needed for data science 

thanks in advance"
699,"Seeking Career Guidance: From Heavy Industry to Fintech, with a Physics Twist",1,https://www.reddit.com/r/datascience/comments/16qsg1r/seeking_career_guidance_from_heavy_industry_to/,2,"Hey everyone,

Navigating some unexpected twists in my data science journey and could really benefit from the collective wisdom of this community.

For about 2.5 years, I delved deep into predictive modeling within the heavy industry sector, leveraging my physics degree for a robust quantitative approach. Things took an unforeseen turn when my company closed its data science department. Though it was a jolt, I was offered a lifeline in the form of an analyst role within the fintech BaaS segment of our company. Here, I've been testing mobile apps, setting up APIs for clients, and gaining a different perspective.

Yet, as intriguing as fintech is, I've felt a drift from the heart of data science that once ignited my passion, and it's been a hurdle trying to relocate to a role that resonates more with my prior expertise.

I'm at a juncture and could use some insights on these potential pathways:

1. **Dive Deeper into Fintech**: Given my recent experiences, should I immerse myself further in fintech? I'm contemplating gaining a richer understanding of finance and then scouting for a data science role within this arena.
2. **Physics and Data Science Fusion**: My love for physics remains undiminished. Could a focus on intertwining data science with physics be a promising avenue? Has anyone ventured this path and can share their experience?
3. **Returning to Familiar Grounds or Exploring Fresh Horizons**: Is it more pragmatic to gravitate back to industries with which I'm acquainted or explore entirely new terrains where my data science prowess might be a good fit?

Your experiences, advice, and reflections would be a beacon for me during this transitional phase.

Heartfelt thanks for reading and offering your perspective!"
700,Data science course in dehradun- brillica services,0,https://www.reddit.com/r/datascience/comments/16qr55x/data_science_course_in_dehradun_brillica_services/,0," 

Embark on a transformative journey into the world of data science with Brillica Services' comprehensive Data Science Course in Dehradun. Our program is meticulously designed to equip you with the skills and knowledge required to thrive in the dynamic field of data science. Whether you're a beginner or an experienced professional seeking to upskill, this data science course in dehradun will empower you to harness the power of data for insights and innovation.

Whether you aspire to become a data scientist, data analyst, or simply want to harness data-driven insights for your current role, Brillica Services' Data Science Course in Dehradun is your gateway to a promising future in the field of data science. Join us today and unlock a world of opportunities in data-driven innovation."
701,"Comparing ""claimed"" results vs ""reproduced"" results.",1,https://www.reddit.com/r/datascience/comments/16qpup6/comparing_claimed_results_vs_reproduced_results/,4,"I am working on reproducing results claimed by an author in a research paper. 

I have followed the same process and have a model training and running.

So the MAE they claim is 5. And I am able to reproduce 23. 

I am a bit new to this, so when talking about reproducing results; how different can they be to say ""reproduce successful""?"
702,Software engineering or data engineeing,3,https://www.reddit.com/r/datascience/comments/16qptlb/software_engineering_or_data_engineeing/,2,"I am studying data science and from media and asking people who are already working in the field strated to be concerned about finding a DS job after graduation.
So I am picking a plan B besides my DS BSc but still want to work in DS in the long term so what would you recommend me 
Software Engineering or Data engineeing
I know some people would say data analyst but I just don't know anything about the jobs and from reading job discribtions I feel like using excel and dashboards is a waste for all the Math and programming and ML I have been studying in the last 3 years"
703,I am transitioning from another engineering field to data science. How hard is it to get into the field with only certificates?,0,https://www.reddit.com/r/datascience/comments/16qvpli/i_am_transitioning_from_another_engineering_field/,4,"I am a geotechnical engineer with 4 years of experience. 6 months ago, I started my transitioning process into data science. So far I have taken some online classes which have awarded me with certificates and I've been working on some projects to build my portfolio.

I have not really started looking into DE career opportunities yet. I want to know how valuable are those online certificates if I want a serious career."
704,Struggling with SQL Queries - Need Advice,0,https://www.reddit.com/r/datascience/comments/16qplm4/struggling_with_sql_queries_need_advice/,15,"Hello everyone,

I’ve been trying to improve my SQL skills, specifically in writing queries involving joins and subqueries. I’ve gone through several SQL tutorials on YouTube and while I feel like I understand the concepts being taught, I struggle when it comes to applying them in practice.

When given a problem, I find it difficult to write the corresponding SQL queries. This has led me to question whether I’ve truly grasped the theoretical and practical aspects of SQL.

Has anyone else experienced this? How did you overcome it? Any advice or resources that could help me bridge this gap between understanding and application would be greatly appreciated.

Thank you!"
705,Packaged food related ingredients and its proportions in a dataset,1,https://www.reddit.com/r/datascience/comments/16qo5es/packaged_food_related_ingredients_and_its/,0," 

Hi All,

Is there a way to collect real time data regarding Packaged food and its ingredients. I'm currently focussing on Indian packaged foods. Any sugestion would be extemely helpful.

Thanks a lot!"
706,"Looking for any critiques/improvement for getting my first internship! I know a lot of people say its just a numbers game, and another way of getting internships is through connections. As a junior there is a high stress for me to get an internship next summer. I went to my career advisor etc.",0,https://i.redd.it/e79ey12cl8qb1.png,8,
707,PhD Advice needed,4,https://www.reddit.com/r/datascience/comments/16qfoc5/phd_advice_needed/,4,"TLDR; recommend a field of research which is related to Data Science.

I’m graduating with a BSc in Computer Science Engineering and all my peers are taken with the flow of “Software Development” which I really despise (I really do not find this field amusing/interesting/enjoyable, I know some of us work/study something they do not like and it’s normal, but it’s all tastes after all so hear me out).

I got introduced to the field of Data Science about 6 months ago and already fell in love. I enrolled myself in [365 Data Science](https://365datascience.com) as a start to get familiarised with the field and started the Data Analyst career path which I’m almost done with. I’ve decided to finish all three tracks (Data Scientist, Data Analyst, and Business Analyst) before I move on with other learning material.

Now I’m in the process of applying for a PhD in the US, and I want your opinion on this particular topic.

I want to research something related to the field of DS and have a good opportunity to find a job after finishing my PhD (I’m interested in pursuing a career in both: Academic and Industrial).

I’m thinking about four PhD programs and the order doesn’t matter: 

* Mathematics: Pure or Applied
* Statistics
* Computer Science (Do not prefer)
* Data Science

Please advise me on which field of the four (or if you have another recommendation) will get me well-equipped during my journey.

PS. english isn’t my first language, so excuse me if anything is not clear, not coherent, or grammatically incorrect."
708,Is test-driven development (TDD) relevant für Data Scientists? Do you practice it?,3,https://youtu.be/llaUBH5oayw,7,
709,How are you networking?,5,https://www.reddit.com/r/datascience/comments/16q9k4q/how_are_you_networking/,7,"I see a lot of posts on here about academic programs, resume advice, and interview tips, but not nearly as many about everyone's least favorite and arguably the most important part of career advancement - networking. 

Networking looks different at different stages of your career, so how are you networking and what networking advice do you have for someone who might be:
 
* A recent grad or someone changing careers and trying to break into the field?
* A mid career professional trying to move up or build their reputation?
* A senior or manager trying to connect with talented recruitment prospects?"
710,"Please suggest, what should I do next?",0,https://www.reddit.com/r/datascience/comments/16qu10o/please_suggest_what_should_i_do_next/,1,"Hi guys. I am a 24y/o from Mumbai, India. I completed my MSc in Data Science from Mumbai University in 2022 and since then I am working in a reputed organization as a Data Scientist. But I don't want to stop here.

Recently I started searching for MBA courses in India or Europe/US. I was also searching for a masters degree in Computer Vision. And I am just confused. Should I go for an MBA or a computer vision course or a PhD? Can you guys please suggest me what should I do next?

Thanks."
711,Does a theoretical understanding of time series help for forecasting roles?,2,https://www.reddit.com/r/datascience/comments/16qbdfs/does_a_theoretical_understanding_of_time_series/,8,"In the Masters of Statistics programs there are often elective offerings for time series analysis which are based on the prerequisite statistical theory knowledge from casella and Berger. They cover the the theory of time series models (random walks, ar models, ma models, arma models, arima, sarima, garch etc), and maybe some non stationary time series. Homework’s generally consist of both a theory and application side, theory maybe some derivations, and then applied is applying time series models learned that week to datasets in rmarkdown and exploring them with packages.

My question is, would such a background be useful if one was interested in data scientist roles which are very focused on forecasting? Are there dedicated teams for forecasting at companies? They often use base R stuff for the time series packages, so we often aren’t taught the prophet, or any other modern python based time series packages. Would this be a deal breaker?"
712,I have a ton of free compute... why won't anybody use it?,110,https://www.reddit.com/r/datascience/comments/16pn49s/i_have_a_ton_of_free_compute_why_wont_anybody_use/,102,"I'm working on a dev tool that automatically scales python code horizontally to thousands of CPUs and GPUs. I have been working on this for the last two months and have a few consistent users.

I recently scraped emails from some of the largest python repos on github. Most of them are repos specifically for Bioinformaticians, Data Scientists, NLP Engineers, and people in the AI/ML space. Since I compiled this list of 50k emails and sent them out I'm getting a 5% response rate which isn't bad at all. About 50% of the responses are positive and a majority of them are people saying they think the idea is cool and they want to try it. I excepted more of them to covert to user... at a bare minimum a one time user. Realistically it has probably drove 30 people to give the tool a go.

What I'm asking this community is A) what are some ideas to generate product traction? B) If you had $100k worth of free GPU hours how would you get people to use them for you?

FYI: The product was built to process larger inputs for batch inference and preprocessing unstructured data --> link to the documentation [https://www.burla.dev/](https://www.burla.dev/)"
713,Data Scientist 1 at Tesla requirements?,0,https://www.reddit.com/r/datascience/comments/16qpk9b/data_scientist_1_at_tesla_requirements/,0,What skills do you need to crack the data scientist 1 new grad position at Tesla? 
714,Alternatives to DS with as much maths/programming but less precariousness,2,https://www.reddit.com/r/datascience/comments/16q95bm/alternatives_to_ds_with_as_much_mathsprogramming/,1,"As everyone knows the job market for data science is incredibly competitive, even for roles in the boring sectors like insurance, etc. The constant uncertainty/effort required to secure these positions is a bit worrying - I like the work, but it feels like an insecure career path, not only due to lay-off risk but also given the fierce competition and limited job opportunities whenever you have to change job for whatever reason.

I'm also looking for something that offers more flexibility in terms of the sectors I can work in, because as I said it feels like finding data science work within a boring field is already a struggle - finding it in an interesting sector seems almost impossible.

I'm still really passionate about maths and coding, and I'd like to continue working with these skills. It would be ideal if I could leverage the experience I've gained in data science while pursuing a more sustainable and flexible career path.

Has anyone faced a similar situation or found job opportunities that align with these criteria? I'd appreciate any insights or suggestions."
715,For those doing Causal ML/Analysis. How much business impact have you had?,34,https://www.reddit.com/r/datascience/comments/16pqp41/for_those_doing_causal_mlanalysis_how_much/,49,Title
716,The Most Popular Programming Languages – 1965/2023,6,https://youtu.be/DmLsaumwpco,1,
717,Data Generator Website,2,https://www.reddit.com/r/datascience/comments/16q63lz/data_generator_website/,2,"Hello all,

I am preparing session about data presentation & visualizations to share with my colleagues, they wanna know what's the best visual to use depending on the data.  


I have a visual vocabulary documentation on this but I also wanna show them the visual with test data to be more practical.  


I'll be using MS Power BI for visualization.  


Can you suggest me good data generator websites that I can use to generate data and import it to Power BI?  


Thanks!"
718,Is the job market really that brutal?,146,https://www.reddit.com/r/datascience/comments/16pcdm8/is_the_job_market_really_that_brutal/,122,"After 5+ years at my potion as lead in a startup, I have decided I need to move on. I'm looking to get a job for a consultation company. 

How much pain am I in for with the current market?"
719,What pissed you off last week?,0,https://www.reddit.com/r/datascience/comments/16qap3h/what_pissed_you_off_last_week/,18,at work.
720,Loss/cost function during LLM training,0,https://www.reddit.com/r/datascience/comments/16q9lw3/losscost_function_during_llm_training/,2,"Sorry for my noob question but I have trouble understanding how LLMs and Transformers in general are trained. 

From what I understand the output is an array of probabilities coming out of the final soft max layer.
I'm guessing these probabilities are used to draw the array of tokens.

Is this correct ? And if so what should the cost function be ? 

Assuming you are doing unsupervised learning, are you then just doing multiple-class classification? Each element of the output array belonging to a class (token). In which case you would use something like cross entropy ?

I'm sure there no fundamental difference with training the usual linear networks or CNNs but I can't figure this out, even by reading the original papers.

Moreover this seems to penalize a lot on the syntax. i.e two arrays with identical meaning but different syntax would have a different cost :
Label : ""The cat eats the fish""
Output :""The fish is eaten by the cat""

Can anyone explain me where I am wrong here please ?"
721,Prediction when Target's lag value are part of predictors,0,https://www.reddit.com/r/datascience/comments/16qfifn/prediction_when_targets_lag_value_are_part_of/,8,"I'm using LGBM for regression, where the Target column's lagged values (*7 columns for each lag day*) are also used as predictors when training the model. Absence of the 7Day lag values severely increases MAE value.

Now when using the model in production, if I use the complete data as training dataset, how to get the 7day lag value of the time period I'm planning to predict? I obviously won't have the target value, to calculate it's 7Day lag value. What to do now?

To explain in more detail: 

So, I'm predicting sales amount (`Target variable y`). The model is trained on 20 predictors (`X`), and 7 of them are the lag value of the Target Variable, i.e. Sales Amount.

The thing is, while preparing the model, I had access to both `X & y dataset`, thus I could easily calculate `Y`'s Lag values. 

Now, when predicting for future timestamps, I won't be having `y`. So how do I calculate the lag values, which is required in the trained model's predictor columns now?"
722,MS in Applied Statistics or Data Science?,3,https://www.reddit.com/r/datascience/comments/16pz08l/ms_in_applied_statistics_or_data_science/,10,"Hi all. I’m getting opinions on what my second masters should be. I’m finishing an MBA and will be pursuing a second masters but I want to focus it on a STEM degree. Which would hold more value on a resume as well as providing me the best foundations for a data science career? Currently, working as an analyst and looking to expand into DS.

[View Poll](https://www.reddit.com/poll/16pz08l)"
723,Job demand?,0,https://www.reddit.com/r/datascience/comments/16qgew5/job_demand/,43,"I mainly decided for DS for three reasons: high-pay, high demand and i like it (in that order).

But recently, I have been seeing a lot of posts and comments, especially on this sub, that there is not a lot of demand for DS.

I am still young, have yet to even start my masters and have only like a combined year of full time work experience, so would be a good deciding point to pivot if I like.

In general tho, I have dipped my toes in both data science and classic sw eng work, apart from frontend, and I like all of it tbh but def leaning more towards ai related work, in terms of interest.

So my question is, with regards to job demand especially, for english speaking countries, is DS still worth it?

Thanks!

Edit: so far, the consensus I am getting from the responses are more towards the fact that the data scientist positions are somewhat scarce, and there is a need to be somewhat of a ""jack of all trades"" or specifically dedicated to either MLE or DE, which actually aligns with my definition of being a DS. To .y understanding, from the job listings seen, personal work I have done and referencing work done by other DS I know, Data Science involves the act of researching ways to make sense out of data via experiments with Jupyter notebooks, Building data pipelines for large scale projects using the experiments, deploying your pipeline to production to an EXISTING deployment stucture."
724,Data science leaders - how do you cope?,81,https://www.reddit.com/r/datascience/comments/16parfp/data_science_leaders_how_do_you_cope/,50,"In almost any line of work, individuals with leadership skills inevitably become less hands-on over time. This is because, according to the business, their time is better spent driving (and being accountable for) project success rather than deliverables.

This change can be pretty tough to handle, as you simply end up doing less of what made you fall in love with the gig in the first place. As data scientists, we get excited about tackling problems head-on and getting our hands dirty. The thrill of fresh, clean data feels like Christmas. Moreover, the tech changes so quickly that, without keeping a foot on the ground, it doesn’t take much to feel like things are moving on beneath you.

I like being a leader and I like the bigger-picture view that it affords, as well as the other benefits. I enjoy supervising technical work. But every now and again I get a pang of jealousy that I’m not doing it much of it myself. How do you guys cope? Sneaky side-hustles? O’Reilly before bedtime? Wistful scrolling in this subreddit?"
725,"1st year undergrad, what should I focus on?",1,https://www.reddit.com/r/datascience/comments/16q2y21/1st_year_undergrad_what_should_i_focus_on/,6,Currently a first year college student taking up a bachelors in Data Science. Any tips on what I should work on this early to get a headstart when I finally graduate and am ready to get a job?
726,Cleaning scraped TEXT; improving similarity search,2,https://www.reddit.com/r/datascience/comments/16q252o/cleaning_scraped_text_improving_similarity_search/,4,"Hey everyone!

Multi-part question.


1. I have scraped text (I repeat, text, and not structured data such as tables or something) from a medical site, and I want to know how to clean it. And when I say clean, I don't mean removal of html tags and such. I already have the paragraphs in plain text but there is a lot of spammy stuff like ""You are not signed in; subscribe to this newsletter; by checking this box, I agree to the terms and conditions, etc."" This text is not the exact same in all the paragraphs but there is high similarity. I would have thought there would be many tools to clean text and remove unrelated chunks like these but all I have been able to find has to do with cleaning html tags, changing date-time format and so on. Am I missing something or is this actually difficult?

Secondly, the spammy text I mentioned is from just one site. I will be eventually scaling to many sites and god knows what random text I'll have to clean then.


2. I used OpenAI embeddings and cosine similarity on the medical text to find similar paragraphs. The results were not great. Is there a way to improve the similarity search? I will be trying FAISS next but wanted to know what else I can do. It was suggested to me to use a pretrained embedding model specific to medical data. However, I found only one such model which is 20 gigs!


I'm just getting started with these, so, appreciate any help I can get.


Thanks a ton!"
727,Football Players Full Analysis and Modelling,2,https://www.kaggle.com/code/anasahmad25/football-players-full-analysis-and-modelling,0,"Hey guys, this is my first project using ML and data analysis skills
 I need your feedback on how to improve my future work!
this is the notebook

https://www.kaggle.com/code/anasahmad25/football-players-full-analysis-and-modelling"
728,PL 300: Power BI Data Analyst,0,https://www.reddit.com/r/datascience/comments/16q14tx/pl_300_power_bi_data_analyst/,0,"I intend to pass the PL 300 exam in the next days, and I'm confused how to prepare, I have created several dashboards in power BI, I also have a good background in Data science (SQL, Python, ML, ...). Did anyone pass the exam recently ? How was his (her experience). Do you have any ressources to start my preparation ?"
729,Is a Masters useless without experience?,4,https://www.reddit.com/r/datascience/comments/16pq75s/is_a_masters_useless_without_experience/,21,Is there a way for me to get some value out of my masters somehow or did I make a big mistake?
730,S3 file transfer and Glue ETL,2,https://www.reddit.com/r/datascience/comments/16pv2n5/s3_file_transfer_and_glue_etl/,3,"Hey fellow Data Engineers,

I'm currently interning as a Data Engineer at a new company, and I've encountered a bit of a challenge in my first task. I'm hoping some of you with more experience can provide some guidance and resources.

Here's the issue:

**Task**: My assignment is to transfer data from one S3 bucket (let's call it Account A) to another S3 bucket (Account B). The source path is s3://X/Y, and the target path should be s3://X/Y/daily  
X being bucket name.

**Data Structure**: Within the 'Y' directory in Account A, there are numerous folders, each named after a date (e.g., '2022-01-01'). Inside each of these date folders, there are multiple .csv files. My objective is to move all these folders and files to the target location while converting them to the Parquet format.

**Challenges**: I've attempted various methods to achieve this, but nothing seems to be working as expected. I believe setting up a Glue ETL job could be a solution(It's compulsory that it should be done through Glue ETL only), and I have the necessary permissions for both reading and writing in both S3 accounts. So, it doesn't appear to be a permissions issue.

I would greatly appreciate any assistance, guidance, or resources you can provide to help me tackle this task successfully. If you've worked with Glue ETL jobs for a similar scenario or have suggestions for alternative approaches, please share your insights.

Thank you all in advance for your support!"
731,Junior DS interview questions,0,https://www.reddit.com/r/datascience/comments/16pxgft/junior_ds_interview_questions/,3,"Hello everyone, I have called an interview for 2 days and there will be 3 person participated in interview (one is talent acquisition specialist, one is Data Scientist, another one is Director) What kind of questions should I expect and how to prepare it pls help me thanks in advance. Here is job description and requirements:

**Skills Required:**

* Bachelor’s Degree in Computer Science, IT, or similar field; a Master’s is a plus
* Minimum 1 year experience as a data engineer/scientist or in a similar role
* Technical expertise with data models, data mining, and segmentation techniques.
* Ability to compose pipelines for data science models.
* Knowledge of Machine Learning techniques, including decision tree learning, clustering, artificial neural networks, etc., and their pros and cons
* Data Wrangling – proficiency in handling imperfections in data.
* Programming Skills – good knowledge of statistical programming languages like R, Python, and hands on experience database query languages like SQL.
* Statistics – Good applied statistical skills, including knowledge of statistical tests, distributions, regression, maximum likelihood estimators, etc.
* Basic Math Skills (Linear Algebra) - understanding the fundamentals of Linear Algebra.
* Knowledge with Timeseries data analysis and modelling.
* Knowledge with regular expressions.
* Knowledge with Data Visualization Tools like Power BI, Spotfire, Tableau, matplotlib, etc.
* Great numerical and analytical skills
* Excellent Communication Skills –efficiently communicating with both a technical and non-technical audience.
* Data engineering certification (e.g IBM Certified Data Engineer) is a plus

**Responsibilities:**

* Build data systems and pipelines for data collection. Combine raw information from different sources.
* Processing, cleansing, and validating the integrity of data to be used for analysis. Explore ways to enhance data quality and reliability
* Analyse huge amounts of data, both structured and unstructured raw data. Interpret trends and patterns.
* Conduct complex data analysis and report on results and present data using various data visualization techniques and tools.
* Prepare data for prescriptive and predictive modelling including machine learning models.
* Build algorithms and prototypes
* Identify opportunities for data acquisition
* Develop analytical tools and programs
* Continually improving coding skills"
732,[SERIOUS] What are wise career paths to go to if I have a masters in Data Science but doesnt want to do data science anymore?,0,https://www.reddit.com/r/datascience/comments/16pwnmh/serious_what_are_wise_career_paths_to_go_to_if_i/,4,"IT?  
SWE?  
Cybersec?  
Sales?  
Any thing that makes sense?"
733,Data science future career paths?,1,https://www.reddit.com/r/datascience/comments/16pvzp9/data_science_future_career_paths/,2,"What are future career paths of a data scientist with 5 years of experience for career growth?

[View Poll](https://www.reddit.com/poll/16pvzp9)"
734,SQL skills needed in DS,25,https://www.reddit.com/r/datascience/comments/16p88ew/sql_skills_needed_in_ds/,33,"My question is what functions, skills, use cases are people using SQL for?

I have been a senior analyst for some time, now, but I have a second interview coming up for a much better-paid role and there will be an SQL test. My background MSc is in Statistics and my tech stack consists of R and SQL - I would say I am pretty much an expert in R but my SQL sucks real bad. I tend to just connect R to whichever database I am using through an API, then import the table of interest and perform all my cleaning and feature engineering in R.  


I know it's possible to do a fair amount of analytics in SQL and more complex work in SQL, too. I have 2 weeks to prepare for this second interview test and about 2 hours per day to learn what's needed.  


Any help/direction would be appreciated. Also, any books on the field would be great.  
"
735,Should I feel bad by using chatgpt?,290,https://www.reddit.com/r/datascience/comments/16orquj/should_i_feel_bad_by_using_chatgpt/,115,"I use chatgpt at work a lot, not just for coding but for understanding new concepts. It is like talking with an expert “ok I get it, but what is that and what do you mean by this? Can you share a code to explain that concept?”

For me, it is amazing, and I have learned a lot faster with that, but should I feel embarrassed or something?

Edit: I am amazed by the amount of comments, I read through every single of them and it is unanimous: chatgpt is a valuable tool for our work, as someone said, should I feel embarrassed to use a tool to be better on my work and learn new concepts? It’s clear that chatgpt is not perfect, it has answered the most contradictory things but since it is really good to helping to understand the essence of many algorithms, I even can understand when it’s answer is not having sense.

Haha thank you all"
736,Data Science Major,0,https://www.reddit.com/r/datascience/comments/16psswl/data_science_major/,2,"Currently, I'm a sophomore majoring in Data Science. Not gonna lie this reddit got me really worried about trying to find a job as a Data Scientist just with a Bachelor's degree after I graduate. Is it really that hard to find a Data Scientist job? Would it be better to swap to Software Engineering? (As in would it be easier to find a Software Engineering job with just a Bachelor's) I'm not really too invested in either one I just want one where it's easier to secure a job after college. Thanks."
737,A Differential Datalog Interpreter,1,https://doi.org/10.3390/software2030020,2,
738,What is your education level?,20,https://www.reddit.com/r/datascience/comments/16p51le/what_is_your_education_level/,51,"Just curious about how many Data scientists here hold a PhD vs other degrees. 

Cheers, :)

[View Poll](https://www.reddit.com/poll/16p51le)"
739,Would an easier way to scrape 100s of websites be useful to you?,1,https://www.reddit.com/r/datascience/comments/16plja3/would_an_easier_way_to_scrape_100s_of_websites_be/,8,"In the process of building AI agents, we've found that what we built could eventually be good at dynamically scraping data across a variety of websites (10s to 100s of different sites at a time)

Our understanding is that existing web scraping tools are bad at this because you need to write custom scraping configurations per site. Not only that, but when a site changes styling, it might completely break your automation. With agents however, you can provide a high level natural language overview of the data you'd like from a website or class of websites, and the agent system will deal with the details of traversing a page and fetching data automatically.

We’re curious how useful this might be for people. If you’ve experienced issues that this might solve or have already explored the space, I'd love to hear from you!"
740,Do any of you regret becoming a Data Scientist?,124,https://www.reddit.com/r/datascience/comments/16osk7x/do_any_of_you_regret_becoming_a_data_scientist/,182,"A Data Scientist is a dream job for many people who love data and statistical analysis but things are often less enjoyable once you do them for a living. Do any of you wish that you went down a different path, and if so, which one?"
741,Is running an open sourced LLM in the cloud via GPU generally cheaper than running a closed sourced LLM?,10,https://www.reddit.com/r/datascience/comments/16p6c0h/is_running_an_open_sourced_llm_in_the_cloud_via/,6,"Assuming using the same cloud service, Is running an open sourced LLM in the cloud via GPU generally cheaper than running a closed sourced LLM? (ie. do we pay a premium when running a closed sourced LLM compared to just running anything on the cloud via GPU?)

One eg. I am thinking of is running Llama 2 13b GPTQ in Microsoft Azure vs. GPT-3.5 Turbo.

I understand there are a lot of parameters to consider (such as choosing which GPU to use in Microsoft Azure etc.), but I am really looking at what’s the cheapest way to run Llama 2 13b GPTQ or a performance-equivalent closed sourced LLM."
742,Creating own query language,1,https://www.reddit.com/r/datascience/comments/16pnmno/creating_own_query_language/,10,"Hi, I am trying to create a query language for relational databases from scratch for an academic project, however, I've never done something like this before. Can someone suggest a pipeline for a beginner like me?

I have experience in coding in python, java, C, R, I also know how SQL works.

I would like to use python to create the query semantics, but I don't know how to start.

I can't use any existing terminal either, I need to create my own command line interface. How do I go about it?"
743,Database Help?,2,https://www.reddit.com/r/datascience/comments/16phdfa/database_help/,0,"Hey there! I am a digital forensics researcher. Does anyone know of where I can locate data/database on forced labor/pig butchering scam employers? I need a list of possible and confirmed pig butchering scammers to insert into a program that will allow government agencies to search scams by location. Any tips, hints, helpful advice would be greatly appreciated."
744,RUGS Grant: Your Key to Unlocking R-Based Innovations,1,https://www.reddit.com/r/datascience/comments/16plric/rugs_grant_your_key_to_unlocking_rbased/,0,"Hey community, you have a week left to take advantage of this incredible RUGS grant opportunity. The application window is open until September 30th, 2023. This might be the boost your project needs. Find all info here: https://www.r-consortium.org/all-projects/r-user-group-support-program. Cheers to innovations! "
745,What is the best way to integrate a LLM with an API?,2,https://www.reddit.com/r/datascience/comments/16pg8f5/what_is_the_best_way_to_integrate_a_llm_with_an/,2,"I want to find a way to use natural language to create requests for an API, I looked at GorillaLLM and ToolLLM but I didn't find any practical implementation examples. Any advice or other possibilities?"
746,How do I build expertise in translating business problems into Analytics Solutions?,1,https://www.reddit.com/r/datascience/comments/16pksiv/how_do_i_build_expertise_in_translating_business/,0,"I work for a bank doing customer and product analytics. While I have built a few dashboards, classification models in the past, I want to be able to recommend off the shelf analysis like churn analysis, cohort analysis, standard marketing KPIs depending on what the business needs. I am looking to read more case studies to understand analytical solutions & use cases built at other institutions  to learn from them and replicate. Where can I read about frameworks/ best practises / case studies / use cases to broaden my practical toolkit that will be useful to the business?"
747,Building cloud databases,1,https://www.reddit.com/r/datascience/comments/16pilao/building_cloud_databases/,0,"I know there are a tonne of sites where you can build databases for data entry etc but has anyone come across a service where it’s possible to build and host a template database that you can then issue separate logins to users to essentially run their own closed version of that database?

Essentially we’re looking to create a subscription based model where we build the thing - then users can pay to have their own copy running on our servers (including issuing access logins to their own users). 

Long shot but thought I’d ask. Thanks."
748,ML Observability Tool,2,https://www.reddit.com/r/datascience/comments/16pclyg/ml_observability_tool/,1,"I am looking for any advice as to what tools/software to consider for ML observability. I am looking to measure performance, model/data drift, fairness, and feature importance of models in production. It would also be nice to be able to monitor the health of the ML system as well, but not required. 
Seems like there are a lot of tools available would love some feedback to help filter down tools to consider."
749,Seeking Advice for Data Science Dissertation Topic on Graphic Design Evaluation,1,https://www.reddit.com/r/datascience/comments/16ph2o9/seeking_advice_for_data_science_dissertation/,0,"I'm considering developing a graphic design evaluation model that can objectively assess and predict the quality of a design based on various factors. This model would essentially assign a score to a design, taking into account elements like color usage, layout, typography, image content, and more.   


As much as I love this Idea! It's giving me shivers I've not seen many people do this exact topic. While most of my class will be taking a simpler topic and trying to put together a project with all the information around I am scared that I will mess up big time.   


(I'm not an expert perhaps I'm very beginner in the data science topics)

help me with your suggestions!   
1. Is this feasible? Will I be able to collect/find data and do this project?  
2. Do you know similar projects that have been done before?  
3. Else can you suggest some easier topics if this is not possible?"
750,Leetcode questions,1,https://www.reddit.com/r/datascience/comments/16pfsg2/leetcode_questions/,9,I applied for a data science internship and I was asked to do a leetcode style assessment. How common is this for data scientist?
751,SageMaker experiments at scale,1,https://www.reddit.com/r/datascience/comments/16penue/sagemaker_experiments_at_scale/,0,"This post isn't about using SageMaker to train BIG models on BIG data, but rather how to track all of the training and experiment metadata as you're building models and deciding on the best ML approach for your problem.

I have a time series dataset of nominal size, about 10GB. It's all pretty clean with nice labels and about 150 features. Ideally i'd like to get it down to using only 20 features. So, I need to experiment with different preprocessing and feature combinations. I have SageMaker Pipelines set up to pre-process my data, train and tune hyperparameters using ScriptProcessor, TensorFlow, and HyperparameterTuner steps, respectively. The model works well when classifying about 10 of the labels, so I'd like to start scaling the number of labels it classifies, reducing the number of features it has available to it, and observing how this affects model performance. The problem I'm having now is tracking all of this metadata and results. I get that I have a ""experiements"", ""descriptions"" and ""trails"" but I'm having trouble really understanding how the sagemaker studio interface makes any of this digestible at scale. For instance, it seems like while I have some metrics in the sagemaker studio, I have others in the hyperparameter tuning jobs console, and still others in my TensorFlow dashboard. The linkage between these entries are job names identifiers that uses hashes so I'm constantly having to remember the job name hash, and then dig for the results in some other UI. Is this really how SageMaker is supposed to work? I have to think I'm missing something here because the interface and workflow for viewing and tracking which experiments did what seems incredibly cumbersome and clunky. The question I keep coming back to is ""if i'm going to be doing, say 100 different experiments, with 100 different pre-processing configurations, and all those experiments have their own hyperparameter tuning jobs, how do I actually track and make sense of all this data?"" Are there any resources that might show me someone with a scaled workflow for experimenting with their ML pipeline? It feels like I should be focusing on how to get EVERYTHING into Tensorboard, but even in Tensorboard the job names are just these ugly hashs mixed with pipeline job names. Does this resonate with anyone else here? Thanks for your time."
752,When do we use the instruct version of a LLM?,0,https://www.reddit.com/r/datascience/comments/16pedrl/when_do_we_use_the_instruct_version_of_a_llm/,0,"If censorship isn’t an issue for me, when there’s an instruct version of an LLM, is it generally always better to use the instruct version than the non-instruct version (because instruct versions tend to hallucinate less)?

Apart from censorship and hallucinations, are there any other pros and cons between intrust vs. non-instruct version?"
753,"¿Does the data analyst have a focus on the area of Architecture? If so, what approaches do you have?",0,https://www.reddit.com/r/datascience/comments/16pecx6/does_the_data_analyst_have_a_focus_on_the_area_of/,1,"I want focusing in the Area of Architecture, from the data analyst point of view. Thank you for your answers"
754,HackerRank test for Junior Consultant - Data science role at Ekimetrics,2,https://www.reddit.com/r/datascience/comments/16p7ukp/hackerrank_test_for_junior_consultant_data/,4,"Hello,  


I got invited to complete a HackerRank test for the role of junior consultant-Data science. 

They said they would test my knowledge on stats, economics, econometrics and python.  
Has anyone given a similar test? What type of questions could I expect?  


any inputs would be appreciated!"
755,Computer vision (?) modeling,1,https://www.reddit.com/r/datascience/comments/16pbk0e/computer_vision_modeling/,0,"I was rage applying to lower level positions because, things... I applied for a technician position in an 'AI' lab.  I live a very rural area and didn't expect it to actually be anything serious.  

[https://alertcalifornia.org/](https://alertcalifornia.org/)

During the interview we got to talking and its for this organization above.  They are attempting to use computer vision to detect fires and send alerts to fire control organizations.  They had someone else train their model and now don't have anyone to help improve it.  I have experience using modeling for quantitative data science.  I've never done anything using computer vision before.  A few of the youtubers I watch on occasion have projects for computer vision in their sample portfolios.  I've never even considered something like this.  I can code python and some R.  

Does anyone have suggestions?  I'm not even sure I'd take the job but just seeing a real-world application like this has me excited."
756,Job hunting in London,0,https://www.reddit.com/r/datascience/comments/16pbgev/job_hunting_in_london/,1,"As the title suggests: job hunting in London.

I’m a leadership level data consultant, job hunting after redundancy from a boutique sized firm.

Worked for tech start ups, banking, FMCG, and a lot of recognisable names. My CV is a bit choppy because of contracting and independent consulting - but that’s not been an issue before.

My appetite for upskilling is clear - working on POV and solution development - and I lead on business activities, RFPs and people management. 

But I’m basically getting “no” or super prescriptive feedback about anal stuff, sometimes unrelated to the job. 

What’s with the industry, atm? Is anybody else searching and feeling deflated?"
757,When and how to use GraphReduce?,1,https://www.reddit.com/r/datascience/comments/16paoyb/when_and_how_to_use_graphreduce/,1,"I believe this article is very helpful to those who wants to know GraphReduce.

[https://opendatascience.com/graphreduce-using-graphs-for-feature-engineering-abstractions/](https://opendatascience.com/graphreduce-using-graphs-for-feature-engineering-abstractions/)"
758,How do you define/explain the state of the recession from the perspective of data science?,0,https://www.reddit.com/r/datascience/comments/16pn2mu/how_do_you_defineexplain_the_state_of_the/,3,"What are some interesting states that you know or have crunched numbers about the current recession? What are some behavior patterns that we have predictions from? We keep hearing this recession is different from all others in the past. But with this much advancement in data science, there has to be some forecast on the nature of this recession. "
759,Career change: My next steps into Coding and Data Analysis,0,https://www.reddit.com/r/datascience/comments/16p9s2p/career_change_my_next_steps_into_coding_and_data/,0,"Good morning everyone! I’ve been wanting to ask this question for months, now I’m finally writing this lol (english is not my main language).

I’m a Mechanical Engineering that wished to have done another College, like Mechatronics Electrical, or Computer Engineering. But I was at the end when I realized that, so I decided that was best to finish my graduation (did a 3D printed robot with Arduino in my final project) and steer my career towards more automation and digital skills. I always liked computers, and had that itch feeling that I had to learn how to code. I tried Python in 2019, 2020, but it never made sense to me, it didn’t feel useful.

One year after my graduation (2021) started to work and learned on my own a lot of advanced Excel tools like Power Query and VBA, doing automatic data treatment, data analysis, dynamic Dashboards for my Manager, and I really like doing that. At the same time, I was studying a Master Black Belt certificate on Lean Six Sigma for continuous improvement. I used tools on Lean Six Sigma to create a career plan for myself, setting goals, why I wanted those goals, what I needed to do in order to achieve it and deadlines. When I became very good at Excel, I knew that the next big step was to learn how to code. Then I started my post-graduate degree in Intelligent Business and Industry 4.0, it was amazing and even thought they talked a lot about Digital Skills and new tech (IoT, AI, Big Data, Robotics), it was more focused on the business side of it.

At the end of 2022 I got another job that had a very intelligent coworker, he knew a lot about Python and that was the exact language that I wanted to learn. In the 4 months that we worked together, I learned a lot with him and saw what was possible with coding, the possibilities were endless! I got the hang of it quickly (my skills in Excel and problem solving from Engineering helped a lot) and that itch finally got scratched. I feel that flow state when I’m coding, it’s satisfying. Now almost one year later since I started learning Python, I did a lot of projects in my current job: creating dashboards on Excel that calls Python scripts to do tons of automated tasks, pull that from database, compare files to check for changes, automating of repetitive tasks, data treatment, etc.

I consider myself to be have low-intermediate skills in Python. I know that I can’t compete directly against someone that did Computer Science and studied for years and have way more experience and knowledge than me. But I know that I have a good combination of skills for Business Intelligence: Understating how things work, project management, problem solving from Engineering; Improve and optimize process using tools from Lean Six Sigma; Data Analysis skills with Excel and Python, generate value from raw data into something useful for a business.

To give more credibility than just learning on my own, I’m planning to do the CS50: Introduction to Computer Science course, to give me a more solid foundation about computers. Then I’d do the IBM Data Analyst course, to improve my skills in data analysis with Excel, Python, SQL and Power BI. What do you guys think, this is a good plan? What would be your suggestions? I would love to read it!
Thanks for reading!

TL:DR: I'm a Mechanical Engineering graduate who initially wasn't into coding but later found a passion for Python. I developed advanced Excel skills, learned Lean Six Sigma, and pursued a post-graduate program in Intelligent Business and Industry 4.0. In my current job, I've become good in Python, using it for automation and data analysis. I plan to enhance my skills by taking CS50 and an IBM Data Analyst course to solidify my computer science and data analysis expertise, aiming for a career in Business Intelligence."
760,A 250k INTERN position in Data Science - do I understand the world?,217,https://www.reddit.com/r/datascience/comments/16o9sbg/a_250k_intern_position_in_data_science_do_i/,166,"I know the market in the US is very different from the Rest of the World - but THIS?

# Summer 2024 Data Science Intern

at Viking Global Investors New York, NY 

*The base salary range for this position in New York City is* ***$175,000 to $250,000.*** *In addition to base salary, Viking employees may be eligible for other forms of compensation and benefits, such as a discretionary bonus,100% coverage of medical and dental premiums, and paid lunches.*

Found by:

[https://jobs-in-data.com/data-science-internships](https://jobs-in-data.com/data-science-internships)

Link to the offer:

[https://boards.greenhouse.io/vikingglobalinvestors/jobs/4974323004](https://boards.greenhouse.io/vikingglobalinvestors/jobs/4974323004)

&#x200B;"
761,Any tips to find fully remote jobs?,0,https://www.reddit.com/r/datascience/comments/16p9fy0/any_tips_to_find_fully_remote_jobs/,2,"Hi all, I’m working in data analytics field as a data scientist. My current work is on-site and I miss remote working days a lot. Also I want to use opportunities of remote working such as being a digital nomad. 
I found some websites and applied harshly but never got a response eventhough the job descriptions matched perfectly.
So I am asking to people who has full remote jobs recently and what was your gameplan?"
762,TransUnion Denies Data Breach Claim by USDoD Group,1,https://www.theswedishtimes.se/articles/transunion-denies-data-breach-claim-by-usdod-group,0,
763,MacOS v windows,0,https://www.reddit.com/r/datascience/comments/16p7bti/macos_v_windows/,5,"Hi all. As I embark on a journey towards a career in data analytics, I was struck by how many softwares are not compatible with MacOS which I currently own. For example PowerBI is not compatible. Should I switch to windows system or is there a way around it?"
764,Operationalized Data Science model is being reproduced,1,https://www.reddit.com/r/datascience/comments/16p3lc8/operationalized_data_science_model_is_being/,0,"Hi there, I'm dealing with a challenging work experience and could use some help.  I work at a large company in tech where data science leans towards being decentralization, with a growing central data org.  I was hired to manage/outsource a data science team to build a model to help measure a specific area of our business.  It involved a relatively niche field in data science that, since I was hired, my team has researched intensely for years.  I'm relatively new in my career (less than 10 years of data experience) and the problem was challenging enough that I intentionally worked with as many different experts in data science that I could find within the company.  We received support and glowing reviews from other data scientists. 

Since being hired, I have spent $1M+ of company money and years of time becoming an expert in this field.  I've shared our results broadly across the company, and my team has built a fairly robust, automated process including visualizations that we can grant access to stakeholders or use for building reports.  This process is productionalized and almost fully automated.  In many companies, a group within my org would not focus so much on data science, but this is the life of a decentralized data science team. 

However, recently, the centralized data org has started a big initiative and have made a point in presentations to announce that they want to be the ""company's experts of this field"".  The person who is leading this project I shared methodologies with over 1 year ago, where I had sent documentation and explanations of our business problems.  Instead of working towards collaboration, or reaching back out to me since I shared insights from our models, this team has since hired a Product manager and their team has begun early building of a model in this space.  

Folks from around the company (re-)connected me to this team when they discovered their work, because these other people knew the work we were already doing.  

Now, I am below the title of most of the leadership on this project.  However, I have received the backing of very senior execs at our company that are very happy with the results that I have provided.  When I spoke with them, they suggested that I reach out to the equally senior execs that lead the centralized data team and share how we have already invested and built these data models.  This all feels very political and I don't want to negatively impact people's jobs (including my own).  However, I do want credit for the long hours and excellent work that my team has done over the past few years building this product. 

I've tried hard to leverage relationships and offer collaboration to the team that is about to start this long journey of re-building this product, however, it's fairly clear that they do not want to use my teams.  I assume it is because of intimidation or that they want the credit, however, it is also possible that this team does not trust the work and models that my team has built.  

What should I do?  Go to the top execs endorsing this project?  Push my exec to speak on my behalf with other execs?  Present my own project in front of the same forum of data scientists across the company, effectively showing how much deeper research we have done and why their methodology may not work?  Focus on presenting to the stakeholders across the business?

tldr;  Centralized data org is (re)inventing a product that my team has built from the ground up.  We are ahead of their work and are very much SMEs in this space, recognized by many throughout the company, but some data science org managers want to diminish the work that we have already done.  Is this normal within data science or is my team's work being stolen?"
765,Solutions/ Book Suggestions for Data Science in Economics,1,https://www.reddit.com/r/datascience/comments/16p6i97/solutions_book_suggestions_for_data_science_in/,0,"Heyy everyone,

  Currently writing a case study assignment on how i would change the current economic system. Read Nassim Taleb’s The Black Swan and Antifragility and it interested me a lot. I’m thinking of writing about the usage of game theory/ more data-driven approaches in important policymaking and transactions. Using these principles, I aim to advocate for a more robust system that only gets better over time. Currently doing a coursera course on game theory to better understand this. 

Honestly, am quite new to this field so I would appreciate any help in understanding it. If you have thoughts or ideas about how i can integrate game theory/ data science in economics, do let me know!! :)) If you have book recommendations that I should read abt, do let me know also!"
766,Becoming a Data Architect,3,https://www.reddit.com/r/datascience/comments/16p0l8v/becoming_a_data_architect/,3,"Currently in my final year of my bachelors in Statistics. Planning on pursuing a data analyst role next year. I am wondering the steps generally required to become a data architect from someone with a statistics/data analysis background. I'm strong with Python, R, Java."
767,What to Expect from Retrievel-Augmented Generation and Self-Hosted LLMs,1,https://myscale.com/blog/what-to-expect-rag/,0,
768,Data analytics | Data science,2,https://www.reddit.com/r/datascience/comments/16p1399/data_analytics_data_science/,1,"im a management information systems major, and in the future, im looking to get into data analytics and MAYBE data science as a career. What skills should i learn first? is there an order that would benefit me to follow? Also, are there any free online courses I can take in order to learn the knowledge of both roles? if not, I'd be willing to pay so I could learn the information. For example, Codeacademy's ""Pro membership"" or buying a Udemy course. I'm a freshman, and I'd like to get as familiar with the field as possible. "
769,Working for a company with sensitive data,6,https://www.reddit.com/r/datascience/comments/16ov424/working_for_a_company_with_sensitive_data/,16,"I have an offer for a company who has some sensitive client data and during the interview process I was asking how their protections change the process and they outlined working with terminals and monitoring things like exporting a data.

What things have you guys experienced in working with sensitive data and how has it interrupted the data science workflow?

While the data is seemingly very rich I wonder how restrictive it will be."
770,Coca-cola's new AI flavor 🍺 Would you drink this?,31,https://www.reddit.com/r/datascience/comments/16oh0pr/cocacolas_new_ai_flavor_would_you_drink_this/,22,"[https://twitter.com/PCMag/status/1702414949929152874](https://twitter.com/PCMag/status/1702414949929152874)

*Processing img spoafg46ampb1...*

Coca-Cola has released a new limited edition soda flavor called Y3000 that was co-created by an AI system. The AI analyzed consumer flavor preferences to design a raspberry slushy-like beverage by experimenting with different artificial sweeteners. It was also used to create the futuristic can artwork."
771,How do I get started with data science?,1,https://www.reddit.com/r/datascience/comments/16p4jd5/how_do_i_get_started_with_data_science/,0,"I am working as a backend developer with good experience on cloud platforms and web applications. I want to move into DS but with so many options and resources on the internet  I am stuck with the problem where I don’t know how and where to get started. 

Is there any definitive roadmap to follow given that I am a complete beginner and need to get a job in next say 3 months with this skillset.  

Also, can you suggest some good resources to follow and projects to work upon to build an experience around DS that I can showcase in interviews. And to add to it I want a fair understanding in how do I get a data pipeline running."
772,SDE to DS. How to transition?,1,https://www.reddit.com/r/datascience/comments/16p4h26/sde_to_ds_how_to_transition/,0," I have 3 years of SDE experience and am looking to transition into Data Science. What is the best way to make this transition?     


Also please note I cannot make an internal switch as there is no dedicated analytics department in my company and the work culture is getting worse day by day   


 Any insights or suggestions would be greatly appreciated! "
773,Stats-oriented data scientist and career evolution,27,https://www.reddit.com/r/datascience/comments/16oe37m/statsoriented_data_scientist_and_career_evolution/,23,"As a junior data scientist (1 YOE full time), I have a potential offer for a stats-oriented data science position in a startup. Hypothesis testing, using advanced statistics and theorems, etc.
Also, it will require me to write very good code. They put a lot of emphasis on it. The salary is extremely high, and they offer full remote possibility.

Do you think this is a bad idea regarding the current job market ? My goal is to shift towards the MLE side. I see lots of offers specialized in LLMs, in computer vision, and I wonder if this wouldn't be wiser to specialize in one of these two fields.

What do you think ?"
774,Where should i learn data science from?,0,https://www.reddit.com/r/datascience/comments/16p2l21/where_should_i_learn_data_science_from/,2,Please help me with sources and guide me with your experience....
775,Company giving irrelevant assignments,0,https://www.reddit.com/r/datascience/comments/16p2k9u/company_giving_irrelevant_assignments/,4,Recently i applied for data scientist role and i got one assignment where they want me to extract voter list data from pdf to excel file and that data is unstructured and in another language and my question is does this kind of work related to data entry or data scientist role. And i also apply for data analyst role in same company and they give me same assignment is this relevant to job role or not?
776,250 Data Science Objective Type Questions and Answers with Explanations split into 5 Online Exams from Basics to Advanced,1,https://mytechbasket.com/article_desc.php?art_id=187,0,
777,I need assistance in developing an automated analysis system. Can you help me with that?,3,https://www.reddit.com/r/datascience/comments/16osusl/i_need_assistance_in_developing_an_automated/,3," 

My company's data analysis workflow relies solely on Google Cloud's Looker. Currently, we manually export data from the company's main system into an Excel file and then upload it to Looker to demonstrate the charts and visualizations. However, this process is slow due to the large amounts of data. Therefore, I have been tasked with creating an automated process from scratch to analyze the data and display visualizations similar to Looker's interface, but with more advanced data analysis tools like Python, Pandas, Jupyter, or SQL to make the system faster.

I already have experience using Python, Pandas, Jupyter, and SQL in previous projects, but I need suggestions on how to utilize these tools for my current project. I am also willing to learn new skills if it will help me complete the project successfully."
778,Data Science Question (maybe?),0,https://www.reddit.com/r/datascience/comments/16oyehm/data_science_question_maybe/,5,"I don't know if this is the right place to ask this because I don't know too too much about computers/technology but is there a site that can collect the engagement metrics of certain influencer accounts and rank said accounts, essentially in terms of how impactful doing a promotion with them could be?

Or, alternatively, how difficult would it be to make this possible from scratch? Like I said, I don't know much about this type of stuff but I would assume it would either have to utilize the social site's API (if it is available/had the relevant information), or, in a case where the API wasn't helpful/available, I'd assume at that point it would have to be done using web scraping? 

Any help would be much appreciated, and if this is a question for a different subreddit I would appreciate direction in that regard. "
779,Thoughts on Masters,1,https://www.reddit.com/r/datascience/comments/16oy5sb/thoughts_on_masters/,2,"I'm going to be trying to apply for a Masters program, and I was wondering if I could get some opinions on a Masters for data science. 

  
Is it required? Obviously it'd give you the foot in the door but is there a way without it?

If you have seen people without it, what did they do?

Does it matter where the degree is from? Top school or not?

Is it worth it? 

Should the Masters be in something more quantitative like Mathematics/Statistics rather then DS?

&#x200B;

Any help would be appreciated, thanks in advance!"
780,Podcast / audio courses,1,https://www.reddit.com/r/datascience/comments/16oy3i7/podcast_audio_courses/,1,Looking for recommendations for audio book / course / podcasts I can listen to on long car rides to start learning concepts of AI / ML.
781,"In light of the recent discussions in this group regarding PhD, just curious to get a better view. What's your highest academic degree is in?",0,https://www.reddit.com/r/datascience/comments/16oxb94/in_light_of_the_recent_discussions_in_this_group/,3,"

[View Poll](https://www.reddit.com/poll/16oxb94)"
782,Designing a Data Architecture,2,https://www.reddit.com/r/datascience/comments/16or1vq/designing_a_data_architecture/,2,Any good recommendations on learning how to design a data architecture for a data science project or an enterprise?
783,Tool for collecting data,2,https://www.reddit.com/r/datascience/comments/16oqzxo/tool_for_collecting_data/,2,Does anyone have an experience creating a mini crm-like tool?  I’m looking for a tool with a nice design that will allow me to create dynamic forms and store that data in a database. Ultimately I want to be able to visualize the data from the database but it would be great if the form tool could visualize as well.
784,Preventing Data Leakage in Time Series Forecasting with Feature Engineering,1,https://www.reddit.com/r/datascience/comments/16ow5qm/preventing_data_leakage_in_time_series/,2,"[Question code on StackExchange](https://stats.stackexchange.com/questions/627036/preventing-data-leakage-in-time-series-forecasting-with-feature-engineering)  
In a previous question ([linked here](https://stats.stackexchange.com/q/623313/233659)), I sought guidance on forecasting thousands of time series. Based on the suggestion to treat it as a regression problem, I used the LightGBM model with extensive feature engineering.

Feature engineering involved:

1. Date features extraction (e.g., month, year, day\_of\_year) using [Pandas Date time Component](https://pandas.pydata.org/docs/user_guide/timeseries.html#time-date-components).
2. Lag features with various lag periods.
3. Rolling features with different window types and sizes.
4. Exponential weighted moving average features.
5. Expanding mean features.
6. Periodic features like Sin and Cos waves.

The model performed well until I **discovered potential data leakage** in the testing set. I realized that using actual hours from the testing set to calculate rolling features might cause leakage because, in real-world scenarios, future actual hours are unknown.

&#x200B;

[Current Calculation](https://preview.redd.it/d44e6tqyappb1.png?width=1453&format=png&auto=webp&s=3168068443d1c709725abc409bac002071e420ec)

&#x200B;

[Real World Scenario](https://preview.redd.it/ls1fk9szappb1.png?width=1408&format=png&auto=webp&s=9b149dae5bcddd7ed1e447b16058350e636e8f11)

I'm seeking advice on addressing this issue, especially when forecasting multiple months ahead.

How can I prevent data leakage and ensure accurate time series forecasting in such a scenario?"
785,Implementation of Reinforcement Learning for an Autonomous Drone.,3,https://www.reddit.com/r/datascience/comments/16omiw8/implementation_of_reinforcement_learning_for_an/,0,"Hello there,

I'll provide a quick introduction first. I am a mechatronics engineer student who is graduating this semester, I have been also privately studying ML, DL, CV for the past year because that's when I decided that I want to make an autonomous drone as my thesis/graduation project and oh my god, little did I know.
I have aquired so much knowledge in the data science field and truth be told I love it, it engages my mind like crazy so I've decided that i would like my career to be revolved around electronics and programming/ data science.

Back to the topic, I am working on object detection (I got it figured out), and reinforcement learning, so what I would like to do is to train the model on reaching it's destination using collision avoidance, I have a PIX4, RPI 4B 4GBs since I'm also building my drone from scratch, so let's say I have all the hardware which ofcourse includes the GPS + Compass and 5 ultrasonic sensors, 1 at each side and 1 down to hold the altitude accurately. 
I was thinking of HITL, making a virtual environment to train my model there because this is what logic says, ofcourse( I could also fly it using the RC controller and for example test if the obstacle avoidance is going to overrule the manual drive, which is also my objective).
The question is: how can I make sure Virtual drone is going to be equipped with the real life sensors and in the needed positions? 
How can I feed all the sensors data during the training?
Which type of reinforcement learning models should I implement? 

I just feel like I dragged myself into an incredibly amazing and complix projects that's going to end up fucking my semester and I won't be able to graduate, it's just that my stress now is skyrocketing. 

Please feel free to throw any advices or opinions my way, and thank you for keeping up with this long post. 😁"
786,Can LOR be sent through personal email (Gmail)?,1,https://www.reddit.com/r/datascience/comments/16ouifd/can_lor_be_sent_through_personal_email_gmail/,1,"I plan to apply for some MS degree colleges in the US and need a letter of recommendation as part of the application process. The problem is my previous manager does not work at the same company and my professors have left the college. They said they would be able to send the LOR through their personal email, but I am concerned that it will affect my application negatively. Any thoughts on this?

 "
